{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ff00a218",
      "metadata": {},
      "source": [
        "https://github.com/NielsRogge/Transformers-Tutorials/blob/master/LLaVA-NeXT-Video/Fine_tune_LLaVa_NeXT_Video_with_HFTrainer.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6fc10208-7733-4000-8adf-2019708b2c2b",
      "metadata": {
        "id": "6fc10208-7733-4000-8adf-2019708b2c2b"
      },
      "source": [
        "## Prerequisites\n",
        "Before we start, make sure you have the following:\n",
        "\n",
        "Access to GPUs (preferably 80GB or more since videos require high sequence lengths).\n",
        "Familiarity with Hugging Faceâ€™s Transformers library.\n",
        "Pre-install necessary packages by running the below.\n",
        "\n",
        "From video decoders you can install only one, the one you will use. Below I will provide helper functions to read videos using any of the three libraries, yet the default is decord which I found to be x8-10 faster."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "3b4c3ad0-0753-4474-a916-042a4b04746f",
      "metadata": {
        "id": "3b4c3ad0-0753-4474-a916-042a4b04746f"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q transformers accelerate bitsandbytes peft dataset\n",
        "!pip install -q av decord opencv-python"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5be98cd5-0546-4938-894b-0a3128beb7f8",
      "metadata": {
        "id": "5be98cd5-0546-4938-894b-0a3128beb7f8"
      },
      "source": [
        "## Fine-tune LLaVa-NeXT-Video on  dataset\n",
        "In this notebook, we are going to fine-tune the LLaVa-NeXT-Video model on ShareGPTVideo dataset which is a video captioning dataset. Note that video datasets usually require a lot of hard disk memory to download the videos, but we'll try to not save videos in memory but rather discard after processing the inputs.\n",
        "\n",
        "LLaVa-NeXT-Video is a new Large Vision-Language Model that enables interaction with videos and images. The model is based on a previuos series of models: [LLaVa-NeXT](https://huggingface.co/docs/transformers/main/en/model_doc/llava_next) that was trained exclusively on image-text data. The architecutre is same as in LLaVa-NeXT and is a decoder-based text model that takes concatenated vision hidden states with text hidden states.\n",
        "\n",
        "\n",
        "<img src=\"http://drive.google.com/uc?export=view&id=1fVg-r5MU3NoHlTpD7_lYPEBWH9R8na_4\">\n",
        "\n",
        "\n",
        "LLaVA-NeXT surprisingly has strong performance in understanding video content with the AnyRes technique that it uses. The AnyRes technique naturally represents a high-resolution image into multiple images. This technique is naturally generalizable to represent videos because videos can be considered as a set of frames (similar to a set of images in LLaVa-NeXT). The current version of LLaVA-NeXT for videos has several improvements:\n",
        "\n",
        "- LLaVA-Next-Video, with supervised fine-tuning (SFT) on top of LLaVA-Next on video data, achieves better video understanding capabilities and is the second best-performing model among open-source models on [VideoMME bench](https://arxiv.org/pdf/2405.21075)\n",
        "- LLaVA-Next-Video-DPO, which aligns the model response with AI feedback using direct preference optimization (DPO), shows further performance boost.\n",
        "\n",
        "\n",
        "In this notebook we'll use the [LLaVa-NeXT-Video-7b-hf](https://huggingface.co/llava-hf/LLaVA-NeXT-Video-7B-hf) checkpoint\n",
        "\n",
        "- LLaVA-Next-Video [documentation](https://huggingface.co/docs/transformers/main/en/model_doc/llava_next_video)\n",
        "- LLaVA-Next-Video [checkpoints on the hub](https://huggingface.co/collections/llava-hf/llava-next-video-6666a9173a64c7052930f153)\n",
        "- LLaVA-Next-Video [project page](https://github.com/LLaVA-VL/LLaVA-NeXT)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4d2f666-cbe6-4556-a5cd-2206c27a0028",
      "metadata": {
        "id": "f4d2f666-cbe6-4556-a5cd-2206c27a0028"
      },
      "source": [
        "## Define variables\n",
        "We'll first set some variables useful througout this notebook and doo all the necessary imports."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "eae9f053-d1f6-4baf-8b08-756329942eb1",
      "metadata": {
        "id": "eae9f053-d1f6-4baf-8b08-756329942eb1",
        "outputId": "25bb0810-84d3-4af3-f997-1cc7596706b9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import av\n",
        "import fsspec\n",
        "import shutil\n",
        "import numpy as np\n",
        "\n",
        "from transformers import Trainer, TrainingArguments, Seq2SeqTrainingArguments, DataCollatorForLanguageModeling\n",
        "from transformers import AutoProcessor, BitsAndBytesConfig, LlavaNextVideoForConditionalGeneration\n",
        "from peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from huggingface_hub import snapshot_download, hf_hub_download, HfFileSystem\n",
        "from datasets import load_dataset, concatenate_datasets\n",
        "\n",
        "\n",
        "MAX_LENGTH = 256\n",
        "BATCH_SIZE = 4\n",
        "NUM_FRAMES = 8 # more frames -> more VRAM needed\n",
        "\n",
        "USE_LORA = False\n",
        "USE_QLORA = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "609a55b8",
      "metadata": {},
      "outputs": [],
      "source": [
        "DATASET_PATH = \"/share/data/drive_2/sharegpt4video\" # path where to save the dataset\n",
        "OUTPUT_DIR = \"/share/users/shehan/workspace_pointing_lmm/MolmoVideo/sharegpt4\" # path where to save the checkpoints\n",
        "\n",
        "MODEL_ID = \"llava-hf/LLaVa-NeXT-Video-7b-hf\"\n",
        "\n",
        "REPO_ID = \"RaushanTurganbay/LLaVa-NeXT-Video-demo\" # Change to your hf-hub repo"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11dcfbc3-46da-4413-a3f1-095469fd147a",
      "metadata": {
        "id": "11dcfbc3-46da-4413-a3f1-095469fd147a"
      },
      "source": [
        "## Prepare dataset\n",
        "\n",
        "We will start by downloading and processing the dataset. Downloading all the videos from ShareGPTVideo might require more than 900 GB of memory in hard disk to donwload zip-files (unzipping them will require more memory), so we'll try to download mini-batch of videos in temp directory and delete after we're done. Note that this will stil require some meory to hold temp dirrectory and cache the processed dataset.\n",
        "\n",
        "The datasets in the hub are usually a [DatasetDict](https://huggingface.co/docs/datasets/en/package_reference/main_classes#datasets.DatasetDict) where keys are data-split and values are `Dataset` objects. We can inspect the dataset layoiut but simply printing it and see that ShareGPTVideo consists of video path and a set of captions for each video."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5da82ca2-e1db-4a7c-878f-aeed972ba9e6",
      "metadata": {
        "id": "5da82ca2-e1db-4a7c-878f-aeed972ba9e6"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset(\"ShareGPT4Video/ShareGPT4Video\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ebc5ff9e-6685-4e1d-b2c1-b360e5888fe3",
      "metadata": {
        "id": "ebc5ff9e-6685-4e1d-b2c1-b360e5888fe3",
        "outputId": "3f33ebf8-d577-49ab-bca3-dcc3dc78bc25"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['video_id', 'video_path', 'timestamp', 'keyframe', 'captions', 'zip_folder'],\n",
              "        num_rows: 40178\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "e147c649-f8aa-4243-b228-6f7aeb761cc9",
      "metadata": {
        "id": "e147c649-f8aa-4243-b228-6f7aeb761cc9",
        "outputId": "9bf4c8a1-5488-42b0-c43e-5ed3b65d419c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'video_id': '02bd228227979a5663a155011f5e3740853f729d68bc12f8fefc75eeb7630379',\n",
              " 'video_path': 'pixabay/02bd228227979a5663a155011f5e3740853f729d68bc12f8fefc75eeb7630379.mp4',\n",
              " 'timestamp': ['00:00:00.000', '00:00:04.000'],\n",
              " 'keyframe': [0.0, 2.0, 4.0],\n",
              " 'captions': [{'idx': '1',\n",
              "   'content': \"The frame displays a person with a complexion that appears fair, as indicated by the visible shoulders and upper chest. The individual is clad in a dark tank top, the straps of which are slender, overlying the person's shoulders, suggesting a casual or athletic attire. There is a conspicuous contrast between the subject's light skin tone and the tank top's dark fabric, as well as against the background, which is predominantly dark. The background offers no discernible detail, thereby isolating the subject as the focal point. The lighting in the frame seems to be directed from the front, casting subtle shadows and highlighting the musculature and contours of the visible skin. The posture of the person is upright and static, with no movement evident in the frame. There is no camera movement discernible from this single frame.\",\n",
              "   'time_stamp': '0.00'},\n",
              "  {'idx': '2',\n",
              "   'content': \"In the second frame, the person's posture has changed slightly; the upper body appears to have leaned forward, causing a subtle change in the shadowing across the skin and the angle of the shoulders. The tank top remains unchanged in its position. The person's right shoulder seems to have moved forward, while the left shoulder has rolled back, indicating a potential initiation of movement or gesture. The dark backdrop continues to envelop the subject with no discernible features, maintaining focus on the individual's upper body. The front-facing lighting still accentuates the contours and definition of the visible skin. There's no evident camera movement, the angle and framing remain consistent with the previous frame, indicating a static shot.\",\n",
              "   'time_stamp': '2.00'},\n",
              "  {'idx': '3',\n",
              "   'content': \"In this third frame at the four-second mark, the subject has settled back into a more neutral position, with less of the forward inclination that was noted in the previous frame. This suggests either a return to the initial posture or the completion of a small, contained motion. There's a slight shift in the lighting as well, as the shadows cast on the person's shoulders appear marginally softer, giving their skin a more even tone. The tank top straps have maintained their position, and there's no significant change in their appearance. The backdrop remains consistently dark and featureless, focusing the viewer's attention solely on the individual. The camera's perspective is unchanged, further indicating a static setup without any panning or zooming actions.\",\n",
              "   'time_stamp': '4.00'},\n",
              "  {'idx': '-1',\n",
              "   'content': \"The video features a person with a fair complexion, dressed in a dark tank top, against a dark, featureless background. Initially, the individual is in an upright and static position with direct lighting accentuating their skin's contours. As the video progresses, the person slightly leans forward, altering the shadow and angle on their shoulders, hinting at the start of a motion or gesture. This motion involves the person's right shoulder moving forward while the left rolls back. Shortly after, the individual returns to a more neutral and less inclined posture, suggesting the completion or reversal of the small movement. Throughout, the lighting slightly shifts, softening the shadows on the person's skin, and there is no camera movement, maintaining a static shot with a consistent angle and framing that keeps the focus exclusively on the individual's upper body.\",\n",
              "   'time_stamp': None}],\n",
              " 'zip_folder': 'pixabay_videos_9.zip'}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset['train'][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91b716b0-716b-43a6-b80d-da11d416a7ee",
      "metadata": {
        "id": "91b716b0-716b-43a6-b80d-da11d416a7ee"
      },
      "source": [
        "Below we have three video reader functions. We'll use decord here as it's faster than PyAV. But I am leaving PyAV as an option in case you encounter errors in decord (especially windows users or in decord-gpu kernel) asit's no longer maintained."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "0026027f-4a75-468b-bb15-f067824d04b0",
      "metadata": {
        "id": "0026027f-4a75-468b-bb15-f067824d04b0"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from numba import jit, cuda\n",
        "\n",
        "def read_video_opencv(video_path, num_frames=NUM_FRAMES):\n",
        "    '''\n",
        "    Decode the video with open-cv decoder.\n",
        "\n",
        "    Args:\n",
        "        video_path (str): Path to the video file.\n",
        "        num_frames (int): Number of frames to sample uniformly. Defaults to NUM_FRAMES\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: np array of decoded frames of shape (num_frames, height, width, 3).\n",
        "    '''\n",
        "    video = cv2.VideoCapture(video_path)\n",
        "    fps = int(video.get(cv2.CAP_PROP_FPS))\n",
        "    total_num_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    indices = np.arange(0, total_num_frames, total_num_frames / num_frames).astype(int)\n",
        "    frames = process_video_cv2(video, indices, total_num_frames)\n",
        "    return np.stack(frames)\n",
        "\n",
        "\n",
        "# @jit(nopython=True, target_backend='cuda') # <-- If you have a cuda GPU\n",
        "def process_video_cv2(video: cv2.VideoCapture, indices: np.array, length: int):\n",
        "    index = 0\n",
        "    frames = []\n",
        "    while video.isOpened():\n",
        "        success, frame = video.read()\n",
        "        if index in indices:\n",
        "            # Channel 0:B 1:G 2:R\n",
        "            height, width, channel = frame.shape\n",
        "            frames.append(frame[0:height, 0:width, 0:channel])\n",
        "        if success:\n",
        "            index += 1\n",
        "        if index >= length:\n",
        "            break\n",
        "\n",
        "    video.release()\n",
        "    return frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "2833775e-ff3d-4311-a357-f22b1e7b033c",
      "metadata": {
        "id": "2833775e-ff3d-4311-a357-f22b1e7b033c"
      },
      "outputs": [],
      "source": [
        "from decord import VideoReader, gpu, cpu\n",
        "\n",
        "def read_video_decord(video_path, num_frames=NUM_FRAMES):\n",
        "    '''\n",
        "    Decode the video with Decord decoder.\n",
        "\n",
        "    Args:\n",
        "        video_path (str): Path to the video file.\n",
        "        num_frames (int): Number of frames to sample uniformly. Defaults to NUM_FRAMES\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: np array of decoded frames of shape (num_frames, height, width, 3).\n",
        "    '''\n",
        "    vr = VideoReader(uri=video_path, ctx=cpu(0)) # you need to install from source to use gpu ctx\n",
        "    indices = np.arange(0, len(vr), len(vr) / num_frames).astype(int)\n",
        "    frames = vr.get_batch(indices).asnumpy()\n",
        "    return frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "c4396473-fc50-4ad4-85d5-33cd59fee938",
      "metadata": {
        "id": "c4396473-fc50-4ad4-85d5-33cd59fee938"
      },
      "outputs": [],
      "source": [
        "def read_video_pyav(video_path, num_frames=NUM_FRAMES):\n",
        "    '''\n",
        "    Decode the video with PyAV decoder.\n",
        "\n",
        "    Args:\n",
        "        video_path (str): Path to the video file.\n",
        "        num_frames (int): Number of frames to sample uniformly. Defaults to NUM_FRAMES\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: np array of decoded frames of shape (num_frames, height, width, 3).\n",
        "    '''\n",
        "    container = av.open(video_path)\n",
        "\n",
        "    # sample uniformly \"num_frames\" frames from the video\n",
        "    total_frames = container.streams.video[0].frames\n",
        "    indices = np.arange(0, total_frames, total_frames / num_frames).astype(int)\n",
        "\n",
        "    frames = []\n",
        "    container.seek(0)\n",
        "    start_index = indices[0]\n",
        "    end_index = indices[-1]\n",
        "    for i, frame in enumerate(container.decode(video=0)):\n",
        "        if i > end_index:\n",
        "            break\n",
        "        if i >= start_index and i in indices:\n",
        "            frames.append(frame)\n",
        "    return np.stack([x.to_ndarray(format=\"rgb24\") for x in frames])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8205ec9b-803e-4aad-9851-116b5d1281cc",
      "metadata": {
        "id": "8205ec9b-803e-4aad-9851-116b5d1281cc"
      },
      "source": [
        "## Custom Dataset\n",
        "\n",
        "In the next step, we'll define a the necessary functions to prepare our data for fine-tuning the LLaVa-NeXT-Video model. We define a \"collate_fn\" function to handle handle the conversion of dataset samples into the format required for training and evaluation by preparing a prompt and making array from videos.\n",
        "\n",
        "NOTE: LLaVa-NeXT-Video accepts videos in one of the following formats:\n",
        "\n",
        "- an array or tensor of shape: (batch-size, frames, channel, height, width) where batch-size is an optional dimension\n",
        "- a list of arrays/tensors of shape: (frames, channel, height, width)\n",
        "- a nested list of video frames, where each frame is an image as PIL Image/array/tensor\n",
        "\n",
        "Here we're going to use the processor to turn the (video, target token sequence) into the format that the model expects (which is pixel_values, input_ids etc.). NOTE: We do not need to do batching right now, so that we can do dynamic batching of data during training and evaluation. It ensures that the data is padded to max length within batch.\n",
        "\n",
        "We also decide to limit the length of the text tokens (input_ids) to a max length due to memory constraints, feel free to expand if your target token sequences are longer (I'd recommend plotting the average token length of your dataset to determine the optimal value).\n",
        "\n",
        "The formatting of the input_ids is super important: we need to respect a so-called chat template. LLaVa-NeXT-Video processor has a special `apply_chat_template` which will help you to use the correct format by simply providing the text/images as input. You can also have a multi-turn conversation, and the template converter will take care of the formatting for you."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "b9491299-d12b-4f8c-8dc2-fc12b477ab01",
      "metadata": {
        "id": "b9491299-d12b-4f8c-8dc2-fc12b477ab01"
      },
      "outputs": [],
      "source": [
        "# We collate to save everything in tensor format to speed-up dataloading process\n",
        "# Saving the whole video clip (array) along with caption (string) will slow down iteration\n",
        "# because unprocessed video clip will take up more memory due to higher resolution\n",
        "# The processed video on the other hand is always 336x336 in size and fixed frame count per clip\n",
        "# see: https://discuss.huggingface.co/t/slow-iteration-speed-with-and-without-keep-in-memory-true/33587\n",
        "\n",
        "def collate_fn(example, path):\n",
        "    video_file = example[\"video_path\"].split(\"/\")[-1]\n",
        "    video_clip = read_video_decord(f'{path}/{video_file}') # change to the video decoder you want\n",
        "\n",
        "    # we'll take the overall video caption, not per-scene caption for each frame\n",
        "    captions_all = [caption for caption in example['captions'] if caption['idx'] == '-1']\n",
        "    caption = captions_all[0]['content']\n",
        "\n",
        "    # Let's use chat template to format the prompt correctly\n",
        "    conversation = [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\"type\": \"text\", \"text\": \"Provide a detailed caption for this video.\"},\n",
        "                    {\"type\": \"video\"},\n",
        "                    ],\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"assistant\",\n",
        "                \"content\": [\n",
        "                    {\"type\": \"text\", \"text\": caption},\n",
        "                     ],\n",
        "            },\n",
        "        ]\n",
        "\n",
        "    prompt = processor.apply_chat_template(conversation, add_generation_prompt=False)\n",
        "\n",
        "    batch = processor(\n",
        "        text=prompt,\n",
        "        videos=video_clip,\n",
        "        truncation=True,\n",
        "        max_length=MAX_LENGTH,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "    return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "7b1dc2d4-0e2d-42fa-8db5-b31ec6ba6583",
      "metadata": {
        "id": "7b1dc2d4-0e2d-42fa-8db5-b31ec6ba6583",
        "outputId": "46413325-a4e5-4834-bb42-d7072d01b621"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Failed to import transformers.models.llava_next_video.processing_llava_next_video because of the following error (look up to see its traceback):\nNo module named 'transformers.models.llava_next_video.processing_llava_next_video'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "File \u001b[0;32m/share/softwares/anaconda/anaconda3/envs/molmo/lib/python3.10/site-packages/transformers/utils/import_utils.py:1863\u001b[0m, in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
            "File \u001b[0;32m/share/softwares/anaconda/anaconda3/envs/molmo/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "File \u001b[0;32m<frozen importlib._bootstrap>:1004\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers.models.llava_next_video.processing_llava_next_video'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# And we also need to load the processor for collate_fn\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m processor \u001b[38;5;241m=\u001b[39m \u001b[43mAutoProcessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMODEL_ID\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_fast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m processor\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mpadding_side \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;66;03m# during training, one always uses padding on the right\u001b[39;00m\n",
            "File \u001b[0;32m/share/softwares/anaconda/anaconda3/envs/molmo/lib/python3.10/site-packages/transformers/models/auto/processing_auto.py:315\u001b[0m, in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m elif processor_class is not None:\n\u001b[1;32m    312\u001b[0m     return processor_class.from_pretrained(\n\u001b[1;32m    313\u001b[0m         pretrained_model_name_or_path, trust_remote_code=trust_remote_code, **kwargs\n\u001b[1;32m    314\u001b[0m     )\n\u001b[0;32m--> 315\u001b[0m # Last try: we use the PROCESSOR_MAPPING.\n\u001b[1;32m    316\u001b[0m elif type(config) in PROCESSOR_MAPPING:\n\u001b[1;32m    317\u001b[0m     return PROCESSOR_MAPPING[type(config)].from_pretrained(pretrained_model_name_or_path, **kwargs)\n",
            "File \u001b[0;32m/share/softwares/anaconda/anaconda3/envs/molmo/lib/python3.10/site-packages/transformers/models/auto/processing_auto.py:134\u001b[0m, in \u001b[0;36mprocessor_class_from_name\u001b[0;34m(class_name)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mAutoProcessor\u001b[39;00m:\n\u001b[1;32m    130\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;124;03m    This is a generic processor class that will be instantiated as one of the processor classes of the library when\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m    created with the [`AutoProcessor.from_pretrained`] class method.\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \n\u001b[0;32m--> 134\u001b[0m \u001b[38;5;124;03m    This class cannot be instantiated directly using `__init__()` (throws an error).\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    138\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    139\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutoProcessor is designed to be instantiated \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    140\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musing the `AutoProcessor.from_pretrained(pretrained_model_name_or_path)` method.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    141\u001b[0m         )\n",
            "File \u001b[0;32m/share/softwares/anaconda/anaconda3/envs/molmo/lib/python3.10/site-packages/transformers/utils/import_utils.py:1851\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
            "File \u001b[0;32m/share/softwares/anaconda/anaconda3/envs/molmo/lib/python3.10/site-packages/transformers/utils/import_utils.py:1865\u001b[0m, in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.models.llava_next_video.processing_llava_next_video because of the following error (look up to see its traceback):\nNo module named 'transformers.models.llava_next_video.processing_llava_next_video'"
          ]
        }
      ],
      "source": [
        "# And we also need to load the processor for collate_fn\n",
        "processor = AutoProcessor.from_pretrained(MODEL_ID, use_fast=False)\n",
        "processor.tokenizer.padding_side = \"right\" # during training, one always uses padding on the right"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e70f960-3ec6-425f-a149-6a8753f9e797",
      "metadata": {
        "id": "3e70f960-3ec6-425f-a149-6a8753f9e797"
      },
      "source": [
        "In case you don't have much hard disk space, run the below cell and skip the subsequent. It will download and process each zipfile separately and then delete videos after processing.\n",
        "\n",
        "If you want to download everything and have it saved in memory/cache, skip the below cell and run the subsequent.\n",
        "\n",
        "Additionally, you can take a look at how to do streaming from HF Hub [here](https://colab.research.google.com/drive/1suYlqG6gyjeslUcXbWAn6EsiFqJXqKns?usp=sharing), in case you do not want to download anything."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "9d092b5a-7306-47ea-b0b2-710165f1cc97",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "a0d643ea45604b069b79ed42c5cf3e9c",
            "b36b408d2efd45e0ab64fbc7a407232d",
            "9ff13e9445d64049ae80c73df348f4d3",
            "5d30f09cfe564251aaab321598975c8a",
            "a9f0b3c9ac84443db782622a92b12a2f",
            "f85fa66f27d943ef9cfcbb5d3297642f",
            "a7718d9cbec34c4a96f3a1bb65f1ceff",
            "d7d807a1cbfa46f5a672af952c7c88ce",
            "98f75e1d64b64f5fa365fa1d1d5260c8",
            "b94b2e5cadb447e7928b91eb64858ac4",
            "6ae35f2f29894f4991f4e68b7a2b937d",
            "8f57dd0c46eb41a2919eb88c62de3502",
            "01f6f0c529674935a3c765655e50a860",
            "a892222614354d5ba1939d2b13e582ab",
            "ff09f5f6e25a4ea5bd67fe6dc9b60c74",
            "88129a7cd62643fcbb646db737cb16b6",
            "c1e38eb751334310a276240a7fe5baeb",
            "92d22b151e974581aaa4c01a2604df3b",
            "7f65f8a7b1d04dc19d409af9ffc074e5",
            "49614c51591b4797a5ebf6c2d239969e",
            "6f0f0b0e29924ecc920be195bff7d090",
            "6063b60044b54b558a3097f9e5a7531d",
            "882cc9f03a8f4a4397e8d1c69050d109",
            "51d82c8b0101411888a7078777e3720d",
            "ae64e8f0116545ceb53277cb975ceee6",
            "ce3ab0902a9841f3b2b47515628a574d",
            "3761f82ec913474d9e4dced49f549951",
            "72fd1827ae8046fbae86e99ef3ae3123",
            "1e8cf72564774f1693b3a426accb4ca6",
            "e44952d8fe014f569865848105540153",
            "1e3c5427f11f4a3fbe0ad78586319cc6",
            "603c46e311984810b09ae1b290dba174",
            "5d7b7f510b454cadbe5c4c05fbf4ae39",
            "bc0cc368dd9d475ebe710e9735df7cba",
            "e14c4bfd33124b4891c99918659f22a3",
            "84a6c34cbbea4bb0b78af5b9af556c76",
            "cb5259006e0340e29030fc75d0dc88bf",
            "fce34c170d85418799cce377b048e9fe",
            "8df560a27b26482eade3033af9d8ae25",
            "cdb400f9f9724d3a8132f75a98ca3a1a",
            "46a5d1d7a21044dc88e1f4e693922b49",
            "e5044f44dec442f291cf4f8cb1263595",
            "7b9b12c378114b208f5f9ed2798855c4",
            "f36aa23581a5464f945744248f7bef9b",
            "7e1ad8fa12bd439fbc0a6a66ce4d52c0",
            "f3471a6df347406484869af0c7b4be00",
            "95b4d69b0e044274aebaa4a29feafb3f",
            "57e2f08f1e774657a9520111a6fc10b6",
            "780d3bce501d499f942fd03f92933101",
            "4fca4d63ffdf40ecb6daf5ead354e10b",
            "1ad08d8a8efc4204a43c59953ce2be24",
            "8c9a685cf179407dbab4814fa6e86ea6",
            "2349320c41a04a26b7d426f4f17f49ff",
            "fb1c3d7680c94439a96d9936acea7d1d"
          ]
        },
        "id": "9d092b5a-7306-47ea-b0b2-710165f1cc97",
        "outputId": "064a869d-dbe3-4e95-f230-4c7589873037",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing folder: pexels...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "976fea77bad64e3a8bf1788667aff7de",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pexels_videos_1.zip:   0%|          | 0.00/14.3G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "23a4c9ff01e847299636b7679602d927",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Filter:   0%|          | 0/40178 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "97ae44837e5d4248b57d34bb9c701e82",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/196 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ff60ebbd2f43470699aa18ffc0cabfab",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pexels_videos_10.zip:   0%|          | 0.00/14.3G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c6b109762e4b40beae7a1dc32e8d97f5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Filter:   0%|          | 0/40178 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c6d9f7e28d5f46959c9a1fedb9cc32b3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/195 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7435d95131f3440aa66152582c5a66c8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pexels_videos_11.zip:   0%|          | 0.00/10.6G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ff4516a4947044e1bf1c173893ee9f8b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Filter:   0%|          | 0/40178 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "99e5bd2ede07443982d1385334a344c3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/199 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2737c856e827454aa9abaf80ab4c800e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pexels_videos_12.zip:   0%|          | 0.00/15.6G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[12], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m zip_file \u001b[38;5;129;01min\u001b[39;00m zip_files:\n\u001b[1;32m     15\u001b[0m     zip_file \u001b[38;5;241m=\u001b[39m zip_file\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 16\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mShareGPT4Video/ShareGPT4Video\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzip_folder/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mzip_folder\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mzip_file\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mDATASET_PATH\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mzip_folder\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# save in dataset_dir to avoid caching\u001b[39;49;00m\n\u001b[1;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDATASET_PATH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     subdataset_name \u001b[38;5;241m=\u001b[39m zip_file\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(directory): \u001b[38;5;66;03m# create temp dir, remove if it's not the first zip-file being processed\u001b[39;00m\n",
            "File \u001b[0;32m/share/softwares/anaconda/anaconda3/envs/molmo/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/share/softwares/anaconda/anaconda3/envs/molmo/lib/python3.10/site-packages/huggingface_hub/file_download.py:840\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m    831\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m local_dir_use_symlinks \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    832\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    833\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`local_dir_use_symlinks` parameter is deprecated and will be ignored. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    834\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe process to download files to a local folder has been updated and do \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    837\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/download#download-files-to-local-folder.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    838\u001b[0m         )\n\u001b[0;32m--> 840\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_local_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[1;32m    842\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[1;32m    844\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[1;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[1;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_cache_dir(\n\u001b[1;32m    861\u001b[0m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[1;32m    862\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    876\u001b[0m         force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[1;32m    877\u001b[0m     )\n",
            "File \u001b[0;32m/share/softwares/anaconda/anaconda3/envs/molmo/lib/python3.10/site-packages/huggingface_hub/file_download.py:1136\u001b[0m, in \u001b[0;36m_hf_hub_download_to_local_dir\u001b[0;34m(local_dir, repo_id, repo_type, filename, revision, endpoint, etag_timeout, headers, proxies, token, cache_dir, force_download, local_files_only)\u001b[0m\n\u001b[1;32m   1134\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m WeakFileLock(paths\u001b[38;5;241m.\u001b[39mlock_path):\n\u001b[1;32m   1135\u001b[0m     paths\u001b[38;5;241m.\u001b[39mfile_path\u001b[38;5;241m.\u001b[39munlink(missing_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# delete outdated file first\u001b[39;00m\n\u001b[0;32m-> 1136\u001b[0m     \u001b[43m_download_to_tmp_and_move\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1137\u001b[0m \u001b[43m        \u001b[49m\u001b[43mincomplete_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpaths\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincomplete_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43metag\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1138\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdestination_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpaths\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1139\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1141\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1147\u001b[0m write_download_metadata(local_dir\u001b[38;5;241m=\u001b[39mlocal_dir, filename\u001b[38;5;241m=\u001b[39mfilename, commit_hash\u001b[38;5;241m=\u001b[39mcommit_hash, etag\u001b[38;5;241m=\u001b[39metag)\n\u001b[1;32m   1148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(paths\u001b[38;5;241m.\u001b[39mfile_path)\n",
            "File \u001b[0;32m/share/softwares/anaconda/anaconda3/envs/molmo/lib/python3.10/site-packages/huggingface_hub/file_download.py:1543\u001b[0m, in \u001b[0;36m_download_to_tmp_and_move\u001b[0;34m(incomplete_path, destination_path, url_to_download, proxies, headers, expected_size, filename, force_download)\u001b[0m\n\u001b[1;32m   1540\u001b[0m         _check_disk_space(expected_size, incomplete_path\u001b[38;5;241m.\u001b[39mparent)\n\u001b[1;32m   1541\u001b[0m         _check_disk_space(expected_size, destination_path\u001b[38;5;241m.\u001b[39mparent)\n\u001b[0;32m-> 1543\u001b[0m     \u001b[43mhttp_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1544\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1545\u001b[0m \u001b[43m        \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1546\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1547\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1548\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1549\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1550\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1552\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownload complete. Moving file to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdestination_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1553\u001b[0m _chmod_and_move(incomplete_path, destination_path)\n",
            "File \u001b[0;32m/share/softwares/anaconda/anaconda3/envs/molmo/lib/python3.10/site-packages/huggingface_hub/file_download.py:452\u001b[0m, in \u001b[0;36mhttp_get\u001b[0;34m(url, temp_file, proxies, resume_size, headers, expected_size, displayed_filename, _nb_retries, _tqdm_bar)\u001b[0m\n\u001b[1;32m    450\u001b[0m new_resume_size \u001b[38;5;241m=\u001b[39m resume_size\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 452\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m r\u001b[38;5;241m.\u001b[39miter_content(chunk_size\u001b[38;5;241m=\u001b[39mconstants\u001b[38;5;241m.\u001b[39mDOWNLOAD_CHUNK_SIZE):\n\u001b[1;32m    453\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m chunk:  \u001b[38;5;66;03m# filter out keep-alive new chunks\u001b[39;00m\n\u001b[1;32m    454\u001b[0m             progress\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mlen\u001b[39m(chunk))\n",
            "File \u001b[0;32m/share/softwares/anaconda/anaconda3/envs/molmo/lib/python3.10/site-packages/requests/models.py:820\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    819\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 820\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    822\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
            "File \u001b[0;32m/share/softwares/anaconda/anaconda3/envs/molmo/lib/python3.10/site-packages/urllib3/response.py:1066\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m   1064\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1065\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1066\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1068\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[1;32m   1069\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
            "File \u001b[0;32m/share/softwares/anaconda/anaconda3/envs/molmo/lib/python3.10/site-packages/urllib3/response.py:955\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    952\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m amt:\n\u001b[1;32m    953\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer\u001b[38;5;241m.\u001b[39mget(amt)\n\u001b[0;32m--> 955\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    957\u001b[0m flush_decoder \u001b[38;5;241m=\u001b[39m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data)\n\u001b[1;32m    959\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
            "File \u001b[0;32m/share/softwares/anaconda/anaconda3/envs/molmo/lib/python3.10/site-packages/urllib3/response.py:879\u001b[0m, in \u001b[0;36mHTTPResponse._raw_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    876\u001b[0m fp_closed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclosed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    878\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_error_catcher():\n\u001b[0;32m--> 879\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         \u001b[38;5;66;03m# Close the connection when no data is returned\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[1;32m    888\u001b[0m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[1;32m    889\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mclose()\n",
            "File \u001b[0;32m/share/softwares/anaconda/anaconda3/envs/molmo/lib/python3.10/site-packages/urllib3/response.py:862\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1(amt) \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1()\n\u001b[1;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[0;32m--> 862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread()\n",
            "File \u001b[0;32m/share/softwares/anaconda/anaconda3/envs/molmo/lib/python3.10/http/client.py:466\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[1;32m    465\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[0;32m--> 466\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
            "File \u001b[0;32m/share/softwares/anaconda/anaconda3/envs/molmo/lib/python3.10/socket.py:717\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    716\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 717\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    718\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    719\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "File \u001b[0;32m/share/softwares/anaconda/anaconda3/envs/molmo/lib/python3.10/ssl.py:1307\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1303\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1304\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1305\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1306\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1309\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
            "File \u001b[0;32m/share/softwares/anaconda/anaconda3/envs/molmo/lib/python3.10/ssl.py:1163\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1161\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1162\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1163\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1164\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1165\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Download iteratively and delete after done\n",
        "\n",
        "datasets_combined = []\n",
        "fs = HfFileSystem()\n",
        "directory = f\"{DATASET_PATH}/temp_dir\"\n",
        "\n",
        "# zip_folders = {\"mixit\", \"bdd100k\", \"ego4d\", \"pexels\", \"pixabay\"} #TODO: Uncomment this line\n",
        "zip_folders = {\"pexels\"}\n",
        "\n",
        "\n",
        "for zip_folder in zip_folders:\n",
        "    print(f\"Processing folder: {zip_folder}...\")\n",
        "    zip_files = fs.ls(f\"datasets/ShareGPT4Video/ShareGPT4Video/zip_folder/{zip_folder}\", detail=False)\n",
        "    for zip_file in zip_files:\n",
        "        zip_file = zip_file.split(\"/\")[-1]\n",
        "        path = hf_hub_download(\n",
        "            repo_id='ShareGPT4Video/ShareGPT4Video',\n",
        "            repo_type=\"dataset\",\n",
        "            filename=f\"zip_folder/{zip_folder}/{zip_file}\",\n",
        "            local_dir=f\"{DATASET_PATH}/{zip_folder}\",  # save in dataset_dir to avoid caching\n",
        "            cache_dir=DATASET_PATH,\n",
        "        )\n",
        "        subdataset_name = zip_file.split(\"_\")[0]\n",
        "\n",
        "        if os.path.exists(directory): # create temp dir, remove if it's not the first zip-file being processed\n",
        "            shutil.rmtree(directory)\n",
        "        os.makedirs(directory)\n",
        "\n",
        "        if path.endswith(\".zip\"):\n",
        "            shutil.unpack_archive(path, directory)\n",
        "\n",
        "            # get small part of dataset with curr downloaded video files only\n",
        "            curr_video_files = os.listdir(directory)\n",
        "            small_dataset = dataset.filter(lambda example: example[\"video_path\"].split(\"/\")[-1] in curr_video_files)\n",
        "\n",
        "            small_dataset = small_dataset.map(\n",
        "                collate_fn,\n",
        "                batched=False, # false to read video one-by-one\n",
        "                fn_kwargs={\"path\": directory},\n",
        "                num_proc=2, # set num_proc higher to faster process\n",
        "                remove_columns=[\"captions\", \"keyframe\", \"timestamp\", \"video_id\", \"video_path\"],\n",
        "                writer_batch_size=400, # reduce writer_batch_size to have batches smaller than 2GB\n",
        "            )\n",
        "            datasets_combined.append(small_dataset['train']) # ShareGPTVideo only has train set, so let's save only that\n",
        "        os.remove(path) # remove this zip-file after we're done"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79825057-c53d-4221-82c0-62def12723c9",
      "metadata": {
        "id": "79825057-c53d-4221-82c0-62def12723c9"
      },
      "outputs": [],
      "source": [
        "# Download in one go\n",
        "\n",
        "videos_path = snapshot_download(repo_id='ShareGPT4Video/ShareGPT4Video', repo_type=\"dataset\", allow_patterns=\"*videos.zip\")\n",
        "\n",
        "# uncomment if you want to cache in specific folder\n",
        "# videos_path = snapshot_download(repo_id='ShareGPT4Video/ShareGPT4Video', repo_type=\"dataset\", cache_dir=\"PATH WHERE TO CACHE\")\n",
        "\n",
        "# Now Unzip each file and process\n",
        "datasets_combined = []\n",
        "directory = f\"{DATASET_PATH}/videos_ShareGPT/\"\n",
        "zip_folders = {\"ego4d\", \"mixit\", \"pexels\", \"pixabay\", \"bdd100k\"}\n",
        "\n",
        "for zip_folder in zip_folders:\n",
        "    for zip_file in os.listdir(f\"{videos_path}/{zip_folder}\"):\n",
        "        zip_file_path = f\"{videos_path}/{zip_folder}/{zip_file}\"\n",
        "        shutil.unpack_archive(path, f\"{directory}/{zip_folder}\")\n",
        "\n",
        "    small_dataset = dataset.filter(lambda example: example[\"video_path\"].startswith(zip_folder))\n",
        "\n",
        "    # set num_proc higher for faster processing\n",
        "    small_dataset = small_dataset.map(collate_fn, batched=False, fn_kwargs={\"path\": f\"{directory}/{zip_folder}\"}, num_proc=8)\n",
        "    temp_dataset = process_dataset(zip_file)\n",
        "    datasets_combined.append(temp_dataset['train']) # ShareGPTVideo only has train set, so let's save only that"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad0351f0-f241-4afe-8c53-5310fb733b1b",
      "metadata": {
        "id": "ad0351f0-f241-4afe-8c53-5310fb733b1b"
      },
      "outputs": [],
      "source": [
        "# Concatenate the datasets we have and load a tokenizer\n",
        "dataset_processed = concatenate_datasets(datasets_combined)\n",
        "dataset_processed = dataset_processed.shuffle(seed=42)\n",
        "dataset = dataset_processed.train_test_split(test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "983d486b-1251-4775-82f8-5f5d20c31ea4",
      "metadata": {
        "id": "983d486b-1251-4775-82f8-5f5d20c31ea4"
      },
      "outputs": [],
      "source": [
        "train_dataset, test_dataset = dataset['train'].with_format(\"torch\"), dataset['test'].with_format(\"torch\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01b90937-2cac-4858-b31f-c4c71ccc6974",
      "metadata": {
        "id": "01b90937-2cac-4858-b31f-c4c71ccc6974",
        "outputId": "ff81d4ee-e156-4ec5-93aa-1cd25586d3e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(Dataset({\n",
              "     features: ['input_ids', 'attention_mask', 'pixel_values_videos'],\n",
              "     num_rows: 2851\n",
              " }),\n",
              " Dataset({\n",
              "     features: ['input_ids', 'attention_mask', 'pixel_values_videos'],\n",
              "     num_rows: 713\n",
              " }))"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# For demo purposes only a small portion of the dataset was downloaded\n",
        "# The whole dataset has 40k videos\n",
        "train_dataset, test_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89bf62f6-cd7a-430f-bf51-831ad93c3169",
      "metadata": {
        "id": "89bf62f6-cd7a-430f-bf51-831ad93c3169"
      },
      "source": [
        "## Create Collator for Training\n",
        "\n",
        "Now we can create out collator which we'll pass to the trainer for dynamic padding of the inputs. The below collator is basically the same as `DataCollatorWithPadding` from transformers with the only difference that we also add \"pixel_values\" to the batch\n",
        "\n",
        "Labels are created for the model by simply copying the inputs to the LLM (input_ids), but with padding tokens replaced by the ignore index of the loss function. This ensures that the model doesn't need to learn to predict padding tokens (used to batch examples together).\n",
        "\n",
        "Why are the labels a copy of the model inputs, you may ask? The model will internally shift the labels one position to the right so that the model will learn to predict the next token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "e3f2fd13-b5bd-4de6-a8a2-c6e0626f89ad",
      "metadata": {
        "id": "e3f2fd13-b5bd-4de6-a8a2-c6e0626f89ad"
      },
      "outputs": [],
      "source": [
        "class LlavaNextVideoDataCollatorWithPadding:\n",
        "    def __init__(self, processor):\n",
        "        self.processor = processor\n",
        "\n",
        "    def __call__(self, features):\n",
        "        padded_inputs = self.processor.tokenizer.pad(\n",
        "            {\n",
        "                \"input_ids\": [feat['input_ids'][0] for feat in features], # each element is one batch only so we slice [0]\n",
        "                \"attention_mask\": [feat['attention_mask'][0] for feat in features],\n",
        "            },\n",
        "            padding=True,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "\n",
        "        labels = padded_inputs[\"input_ids\"].clone()\n",
        "        labels[labels == self.processor.tokenizer.pad_token_id] = -100\n",
        "        padded_inputs[\"labels\"] = labels\n",
        "        padded_inputs[\"pixel_values_videos\"] = torch.cat([feat['pixel_values_videos'] for feat in features], dim=0)\n",
        "\n",
        "        return padded_inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46c49a5d-31d7-4b95-b611-503f68328160",
      "metadata": {
        "id": "46c49a5d-31d7-4b95-b611-503f68328160"
      },
      "source": [
        "#### Let's see one of the video clips we sampled\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "562760d1-4a8e-46b9-bac2-c78da2e9ab6b",
      "metadata": {
        "id": "562760d1-4a8e-46b9-bac2-c78da2e9ab6b"
      },
      "outputs": [],
      "source": [
        "example = train_dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71015567-a4c6-4d35-a1e2-a6eb9aae9a63",
      "metadata": {
        "id": "71015567-a4c6-4d35-a1e2-a6eb9aae9a63",
        "outputId": "a2699ac0-f36e-405d-c2e9-acb207303d9b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<video width=\"640\" height=\"480\" controls autoplay loop>\n",
              "  <source type=\"video/mp4\" src=\"data:video/mp4;base64,AAAAHGZ0eXBNNFYgAAACAGlzb21pc28yYXZjMQAAAAhmcmVlAACIEG1kYXQAAAKvBgX//6vcRem9\n",
              "5tlIt5Ys2CDZI+7veDI2NCAtIGNvcmUgMTU1IHIyOTE3IDBhODRkOTggLSBILjI2NC9NUEVHLTQg\n",
              "QVZDIGNvZGVjIC0gQ29weWxlZnQgMjAwMy0yMDE4IC0gaHR0cDovL3d3dy52aWRlb2xhbi5vcmcv\n",
              "eDI2NC5odG1sIC0gb3B0aW9uczogY2FiYWM9MSByZWY9MyBkZWJsb2NrPTE6MDowIGFuYWx5c2U9\n",
              "MHgzOjB4MTEzIG1lPWhleCBzdWJtZT03IHBzeT0xIHBzeV9yZD0xLjAwOjAuMDAgbWl4ZWRfcmVm\n",
              "PTEgbWVfcmFuZ2U9MTYgY2hyb21hX21lPTEgdHJlbGxpcz0xIDh4OGRjdD0xIGNxbT0wIGRlYWR6\n",
              "b25lPTIxLDExIGZhc3RfcHNraXA9MSBjaHJvbWFfcXBfb2Zmc2V0PS0yIHRocmVhZHM9MTUgbG9v\n",
              "a2FoZWFkX3RocmVhZHM9MiBzbGljZWRfdGhyZWFkcz0wIG5yPTAgZGVjaW1hdGU9MSBpbnRlcmxh\n",
              "Y2VkPTAgYmx1cmF5X2NvbXBhdD0wIGNvbnN0cmFpbmVkX2ludHJhPTAgYmZyYW1lcz0zIGJfcHly\n",
              "YW1pZD0yIGJfYWRhcHQ9MSBiX2JpYXM9MCBkaXJlY3Q9MSB3ZWlnaHRiPTEgb3Blbl9nb3A9MCB3\n",
              "ZWlnaHRwPTIga2V5aW50PTI1MCBrZXlpbnRfbWluPTEwIHNjZW5lY3V0PTQwIGludHJhX3JlZnJl\n",
              "c2g9MCByY19sb29rYWhlYWQ9NDAgcmM9Y3JmIG1idHJlZT0xIGNyZj0yMy4wIHFjb21wPTAuNjAg\n",
              "cXBtaW49MCBxcG1heD02OSBxcHN0ZXA9NCBpcF9yYXRpbz0xLjQwIGFxPTE6MS4wMACAAAApEWWI\n",
              "hAAQ//73gb8yy18iuslx+ed9LKzPPOQ8cl2JrrjQAAADAAADAAA/yP425VR62BLgAAAE7ADZy//E\n",
              "Y/K4ACvgUNItcrm2vXdyPQ33PzKkTM7xM0rqAWnHDJhVFhbietpFdEks1PY568bNHEoLuh9lt7ty\n",
              "aQiWK80N46Y9cAmWgSM4PmP5W9/UH3J0ixVO/SrVz9gwBgDDgitOUNFIX9094CvQ8SsPBND6Z3e2\n",
              "0hS+xK12Um4dHqf/SRbf+thlyIyhFSuv2DULaj5bm3IKWrMxO0R/jD8//Wh9HMtpEVmTgXPz8dED\n",
              "ILprBjL4bhuLTYMekSFt76Gv3PHwmT1O3sV+mNFiwjLE+8Nf2z22ykw3sLqHdMCMk5FmbFZjQ51q\n",
              "vmJrBY1GU6WN3TMRm8StyN6A/6sbeIURfrm4AELQ+/nfBfVQ09HiJuAJcPsZp73xpC/8aLfuhYVZ\n",
              "lEPcjMeFwwnlsbfXBUBXtA36ppC1Z1Af+KrJUfC+ytrj2ors1ovQKLLnOGX9Xr2Gg3lPCiHgbZ8O\n",
              "zg4m4WArJTN38J84biHfhldZwjgZffiz2MDfUCsO4CBRpXPOp/4FgRVPmTcLU0zT1Gf/RCSIFTmo\n",
              "683uWt2InRwGou0vZ6ziylVQCHuK4R5np5ikDEDeCmzvHrIT6WYpUzp8mmUyBlJ15FBMhEjffa1J\n",
              "sugSL5sFNA4D5rrlcyn9S15nGONPw3f+eAwEV6elOJbBCK7L1wnunNhRb9Ut0AtqWSA6U28nKj88\n",
              "D/1eDE8IpYxOnTbMWS5dwYwsYnB/Gea0R8/Hb6CGIhcH7PqV1ZaTXRWikGjewxf7Hpgu451sTko4\n",
              "69q4dgalrz7H819uGOkVwZ0kjLeT7gWlO5eOmH4i5hoGTfG8on0b1x1wLwqoERfc3DFTwtlvAY7s\n",
              "xMHrkt+0d7DreIS4RoooMjJ2yXRI5M6xKi+UMBXrf78CBIcFstP0DraxPlOymReIXHNYsat8M2J2\n",
              "mAWl1nA7IuCfhXnOhWiVPJW8C2lZpA97zuPmhz7KYP1XzjlSNspMxsWFGfWHtcs8wCUfxUq9BDe8\n",
              "itcS5yUGxvoJDQ7ORdwWIPyEPbnxrTU8K/YqiLLFWhRBYwm8Cdwh4KT61XtXhs3rcf2X15pfjGuM\n",
              "2o52ClzRNfV5EhjYgJRGs+UOaLGJ1R/c1qx8h1symrD98DppFll0lB1MP6QyBrWXpPE2hZ1q6grB\n",
              "8wGe0MwTqGiteCwr3kCwMFHByEFBA2KAXt8uS7pHZSlGc/wQ1LcSTMInPdwVKk/ytvg1Ddz8GqkP\n",
              "irBrqVAIXYQAi6qVd8HpK/bSPOPRCcNSCBcBa60QbA+pLeRLL7NPcqjkq8Qa2407//vLNUeY0+6d\n",
              "UneYW/B2bEhggjA4++EFoLXQVI7UqnmHVEiqhStDu5QyKPo5nWyAD/DlCsFOxroGWwYXt7uCNhnj\n",
              "4ieeHYNoFMrT0Kmz/IBylsUTkyY+zE5fRhf32c7fMWNLJO//fIY789RgC/XZvBp4KCOhm06wMA4C\n",
              "cxlXpHQFp9dO0h0QwvcDv+3kjGqFvP6li0W5f+EGyOw0cGeJSAWwLFdiQi8YWcGFB7beRW2j/HNj\n",
              "Ai6v2kIv9Ixw/E/NYDZM2N9R6SBFdSIGM/6C0Hw06k8zYhC4hIPy117dvdXroY9giWQml8CSGAgU\n",
              "hvW2akbZI4TUbiKMC4rLNQVrD8iGqknMkRc8QOPTueCRvWEY3vwaYQZeckmvbyoKnbtSE48fUY6+\n",
              "ilag2rm4Az9x0w37KUODOLLarFfue/edFAiPU+vZfkhiv+nNXCgI1pzr8opBmHPe2K0BQvhxOo+9\n",
              "Ki3N0w1xKHmo4J0P3PsDnuQPWae0RZ6vijEJ5xolD1coZvU6ytR+x2yR3/UhEkLw81/SuIV5nLfj\n",
              "bqrpy+Xw7c6gzQCJ83CuFY9qkJGYGPKDDrL/RAgaN8D21qsXcvM0vklAmho79d2Z2iuC2B/rOZYY\n",
              "l4nhn/SsrcIxH+oR7JDEDCd0CXVXfsuBnEK8mObsX+xO+yxmuaR3IgNgs7grqclVED81dXSURVpC\n",
              "a6Xt/Y48hR+U2FTH6kEWtGPROwWHwAMTqjHTyE4iC4jPL5WTdxT7IuVVcJeLWkmrZ79Xi1RW3Yj7\n",
              "7qb4FBBHCS7oyZNfM7atdx/K9qKAHUUNDMS/1GSht4FDR46Kkivji3hwLs9lkWsm2tz62xB/A4mB\n",
              "y0r4o05kveXuwDbmzVoqrOOtNnidBIHoKs/1mvoxnXUyo+pW8YKTjZB9/3n38rg7OHpU+91YNveY\n",
              "OgbI7pIqaLNKoC6N8d3rPWuzjFbfPIsd5RUXJ6klXfxqAALpS3WWpsbEsPI4jV6eZTjGiPrsEaN2\n",
              "SO91GRs7//KWYnlwh+P3+60jjGIhzf5D7ET5sC7jcv0lvLMuqNwghGBdCixOJM5dNvrprl6d8xCA\n",
              "TRn0+ypmFQIu55j+vaYutM1OQOeF7FuGlddrTmO3Qyilc/uW4u23JJJadRGSlslnq7rETcz3vTfz\n",
              "1gDf16tQJ0JnsozqpPciW4o1qnFyVoOsM20LCCAJH0Ljm1yaLSzZb0+zlspPzrfUOunJUcsnt2Mk\n",
              "vXUoUP38yFDLAS/JdrJfbA5QPSMtqbtmPv1nWEQOhRYZznuckhzEtZYgZ5ufG1HaLzBOyMj3QdmR\n",
              "OShyTGduyoy+UeG5rdqP3zcn2HHwklSnOlRsRdF3sADmOEZTNhfuC2KFXNtXkoDKMFi7AmPidjm7\n",
              "A1Dkb879YTaZsPNGHyAYbx806zw2XTMcM2IB9PWBsnFtZY84Da82+Tpow9dpMusjRgqAxKdGLnuY\n",
              "Vnqm4Qhn8Zj5oIN8T/foiDLITIswjnDsylVGTmFPEVBIWOPKtR5+uweLOxkXvFwh660Mbo1xFA/F\n",
              "gX1HZIVgC+aGXoG5mqZUZNX+Nv8Lz9FNfHJYOQKg6Mh7ZgjWhus2A6+9DxpUxB1hIHXGF4TjQaKz\n",
              "IQbsGIaqjBKB1nKnEHuhHMJFmmJfJ1uZw3jd/XUi1eM6lcM9miZI2wVutaSl2bo2xg4duAWWNyBz\n",
              "y+mzVv7O88WQgCJADtk9I6itz/kcfhWMXlilV7mt0IHRkiqp5JovAWX/BZV6E74vZFgcLocrk/ao\n",
              "vzv3iduVtWzSWE9Mq9P+xtgG+JyhsL/m3J8RmDaGs6HuXLkVB1/8mr+edYBZiFQILiLqQKcrBWDQ\n",
              "IMtpss0i6jtlQ/vRAereoG4QcXVqT9KeiwBjiJBoxXgHq1QHwLnERni857stCoyxlwcnbjNUSy7d\n",
              "2GesDm/jXVaVDsRBtkV3aTPqFrzzlnAlgfYHii6Fnl3F2Ctf1t/45koxkxApaQFt1dFjEn5tUfX7\n",
              "xj9Goam2P80ANNS4JLEoQxCNqhcfuA4AUkjv/2wzpcZTXK9V8ICeC9nLrQMQ3/nJSBRPXMK4dg1c\n",
              "1TGfyukjg82G9N6WHjFO490ZcMZed2M4fqY34WHMWEDl90RXNqESGTe6tQEf9W3K/oSiz3mg0VAY\n",
              "r4EIkM0rnBQfqx/QXMPe7EfOKMbdRvbabpM8jZzj6yFAXDMiqfw0tQTnDgcn6LnakariO4xY2d66\n",
              "XOE4ltTyErQMwUWvc210hvokuPCCgUrRzNurBSUPNxIgBao5Ci6GvczgapUQgJ0nuA/VfxtXUEK9\n",
              "12A/igcDwZ3OmEN7fcLqlcc4tVitHYad9dmiFzz7YQbrs6WTUafu/vJTvbFeYuy1DHbPpDupNYnA\n",
              "BTG8rfjhr449xhHv5bHDZhneGjssKPydJYZfcwIvzAgo6gCrWSYtoIFvbZWiNTxmp9wEpCmQvBKx\n",
              "mu/lWUllsFrVejR1Np1e68XHQD+q35igPRoJz0STb6MC/rP2SA2NSOK6oOg7vmqTXi0qIST3VxUy\n",
              "AqN7fpf7sbVHUgexa8cleQorcYjwNklprllJoVlelpljOyHaQJuNZzrs6zW/qkTc+WCN0lsUsV30\n",
              "Bv4df+C0/40MHXlqroErOeaI/xHkurAbsIzIfugxP309iYmnkJVDaxBmn5aE/kIiG4yIa03DjiJY\n",
              "gkXVCn3YaccSFDG7CBagE++KbV59Rnfj6y2KotHcaZyITe3arWCB/2yv7f05mUSyOBQsdyg4hqlf\n",
              "5TukV8FX5iWnIcQwRxoGEvwIolt3Dt/3fFR/hyVFZOi9yRLKSqt25hYCzHu1kHnTzoWn3FAiHhhs\n",
              "n2iivesVkghR8CwcuUvUYdYsU0cZmLS0jSfZpRAmPiUT0e+ytsOinvJjzg+P8NEfguXansjzQ1RI\n",
              "3w1Iu96jHlrdGV4rK8Q79wL+5Xi8N1BNgYW7rTiRezSQCcv9GfLq+I7QfLHoMs7VsvACXWhwuPqI\n",
              "RyKodgBPYw2L5HOA+9Xj+n1/+GFIKNfvGVRfdT8tzjtOUbfSdCELZ6oFDrdbs6JOCjkLszgwl2+L\n",
              "gHIbmkyDfGXDJTJaomMLpV+3Px2/sXko3BoacP/Y4QVqo1OuBKrZY3bmnOQJkW6J2zVRtqXVUFvq\n",
              "mkOQRp5Ia4vIp2WN4tmVRu+4kU5xdDk/fBrSs1jyWqcKCr0HY35pL4MkfnvY11WNaIZK+ky4llrS\n",
              "7lGiahFs7l2R/iDDo8DnbzmBlo/+hRlZQ9RLu7LleexRUcl9hhJAXQXCqB1IM+POaRoXsvNUtprh\n",
              "it68sddjtVlArEUqWPpEpQgPt/UM1OW//MeuT6VE1FUDuWmf/eFNfy/6L7BszVvvviGChZIIejMl\n",
              "/Kt2h2kjeAFAX6Ci0UdxG/QqozzVS01ESgmguhi3q4aBg/f6Bgv2tx5iaLfDBUVBkiDvpZfESgv7\n",
              "8s5TGLWDdEjw+cCvlrCGB3kqo2kyrhRQrIsr68LKUKfJVtEEOVqA1YWjVCvLP+PaISYIsXAIPYU3\n",
              "QzWpIiW0rEN++9dVfcm58YbHw+Qv4yrOVyPnB1OpTZm4kJofUaTRefauGbEzMgy1cj5S0X3b5l/y\n",
              "cl1XZgNe4vrFL6FgT70t+82iC2TRXTqARAXntg4+TMGV/L4lq6Hy/lHYOnhXLwIKqWgsuBvisBaC\n",
              "rIMRnxfcNHGZTNRwtZlfZgcGb4vfh3BUrXXeN4bnOnBAQDgqcFpLd9/Js/+JFKMNJD26PIut2HZx\n",
              "1vwaHH2Bn6v+H4MxibudLtvixrC6Bvatra5GjHLt94n/mbOJs0avk9tePiSpexltaXfv2cFW0gcU\n",
              "AzTwtIC8bXQy6/DufnK2yqOY4Jk1F33wDfVD6SFEMjjMZ9vlA2Hs4iwoIm8YacoqfIBG8fQl6yht\n",
              "jlYtuNrK51H/7+oqDMKIChRk7YO41XQBUerbF4vyi+bdHdJIbBJUnMp0491r7m32M5gs225jSlOa\n",
              "IbeoRdWb9tsx+V6P3/llShOV1IHfqFKjwkNFoG4Qf+bmDK+Is8QU6ffFSfKd4HxyshVV2c2DAHKN\n",
              "sRr5/cHxoBJWVgnlrQjS4tlMF5aKPUlj0Q5O3FiYCLXnbRaKMV+gOxit3aPx5Af4KRqTlS4IX3po\n",
              "4wUYFHGnakkfrQr9IS8tJUfPssqyYAXa3QhI923PwU6qoa3/b0fqf9xhRbS0mi42+869NAc7HdIF\n",
              "ttrTO0QQQV4hedsBUQ9a9T/33vxGryjb/Dok5DNQU+AY5iZp7B1mx3MeziHPMrvHmxeZKoG0Ttlz\n",
              "C91TDz1Vk5RwRfP9l3qdl1D2rNaWA2GWgXWjtPJF22LjEMTFUUbfYmpCiC2dv5CcjVV6G+tyublI\n",
              "MQ7/chW91izmIUlSJUN5sWCd/AzNysQ37JI2v4/45Vdq8qEWAglBVTAhe6X//Ldm8l/QRhEV/T2t\n",
              "8SC1GyBSf/L9hMHkmdptH3/ldpsde5OjkcEO2/lj2v6untuhfDlDuhuqgjifrIIqLlSe154JAOYf\n",
              "lCwdaRKaj39OUPyS/iqRQwwjVsqR/mWECh9D9+qF8Q7k7L36TtTPUbC5N1W8f7AvPeNeA93ynh8R\n",
              "lu76TCwS5UxnS7KaSrlGl6P/I8mMNwghU3m64HMUfcrD5BuxWre//v4hzQh4PIwBi9BHLNJUCkBl\n",
              "fcPL666xD92TY+8Fqsx676jlPx/O4b60yCLG0w8jaT7Po4ZVhI2EhKKYt2MfYYeOpgBKpJYxnGN+\n",
              "IHFB109rMwFNoua4TY0TM2DAXJ4oku/gwFz207iMpjmCE+MzjRgfm0zN1dAw1hxy1R9HADyr9824\n",
              "HQ9hIKpKIf9gVHtt8hpTFk+l6E/pMxwA09F2UjIjdTT7ydsii9ozIiT7UlrdBIN1/DJ2JqzIlUCe\n",
              "g82bfupVcdL86o2cwRSPKHGAJDyAh3WdW8m0juYvNSmSxejyNgy8LZw/guvtxmDcq1CpDHPICyxa\n",
              "LcEvzNhszQpXWaLZrdkjloG0YKefXtqqY5FzMombbAe6A1imJR4riU4YlvFj2UuOGgJWrn+JCnOc\n",
              "VKR2j19wPcYwiiTuKRgpEN2rX2ZoZb425I31opBca2XAxrTfUioQ/vhNkCRpgen2fB0HqnrHdnsQ\n",
              "gTuOmIftWeZ99e61yyJC3ZmSsPCtG1SA2veC5ACUpu0CdpLcDm9utkNZ4QZM8fCWDdS+hJUALdPj\n",
              "xASfqaCBO7y1hZSaFAp65TZcFkS9wp4y2YiJReroiSJOfKXSo9mOptFoXdO8VU31LvT7pnbd+hZm\n",
              "L1PfOgD9ASSVQHPob5AKAovK3Lpmi+MeN8W31Q++Oq/bZ9A8fzT6PTDdxbIw7X0KdJNLC5Y0lpyw\n",
              "zztmM/UzdrBjoDQHPAmVPx7rTJFL/C8X6Gj+fYQKULc9zqfvdOS0MxZOq5u+AYBqZ3CtDngeWMNM\n",
              "gjg4R7CTQOQXI6Ab52BEFCzwRQkYC+awe4jzNeMFxBsXHhvYvH7vfAHrAOAN+GOsLjCoWpEZGMye\n",
              "tb/KDyvRn/YmAch9vIaHDhKjSh7uxlmVvh7xYVovBqmvYFHkMvfgsfpig9feUcVoAzky+MTtjlw6\n",
              "iqWYjIFkrTF8A1yqNSi6o2fw0kV3fiStKhCLheQNJGFrDZQyqb0n9ja/xPS97bN5Gro/iiILdIPw\n",
              "LIlfsSbEd6C0c7IbxcR72sfDUy4SsvJx5B1snfH1fq1nhVmCCSgnoKiZiizJf9qPMNw8v1stWYBi\n",
              "7bjiajzbQYhXt0n5NFLv4iSSXAZOjE9HXo1F9YJbAAL4xszH6v5OgWrhuNF6UfmgyezsQnUVdl/s\n",
              "/4c76Y+QZIMB3f2Fdv5zj7QriKc/J/tKgVgwIalTxmh0A2Vtu83d68wf4blrETm0xJ5m7c+85dnC\n",
              "cFiXpZ2DUGOoGL46dNgS1aBVbTJo/FiewIswLVaiRfkbkbHTBzM9bXlRj1zRiDz0NC8hvKv01oC5\n",
              "QrMYmnbYm0AXOmj8Lt1gt1J7ukXdv783FOnDmCUi4R5+klGZ0dOQV4ijIFtTnUqCKIA9NzCImVSw\n",
              "+ZqSKA9iUlb4qUGNOgYk05DY1FDikNJoD6ZjPXboSrw0lnmfng2qEtRyzWlvfKDu0miElgorQ/2Y\n",
              "8X0pp9P0S1EjYtFXJX16mdix2/P6rrGdzgs7Ddx115hoAiy/tPwgvbzeeLUQE+zrIM9lUNcJ8YQ0\n",
              "/2SQo6rggR7gz4PXPPwBiP7HT6fRP/DAeFQDzy5SvSjI6mWubr0KodsXWzxG7qbZx9Fui9j18pxv\n",
              "/GtCbckeFdwWB32W3qnVchUT5lIGlUrvX+akZhjGguL4cDtF6mDLAExqFDGrphlZ/qa6a3iyDArD\n",
              "7L+oYv0pb2lg0JQV1iWTCXkkVn9SNd4yNyHvxmItt0txieq9B12oxCwF+niB232ukVi71KsqoMXT\n",
              "McJvfta/e/CD9xezqkeFiKk4AEJgfVIUeg2z5QFrufEhH54kr++UtYdBBuGUwZxX5vgR/3qUZ9Cj\n",
              "PLqTahA+E+jCOG8azRQZM2KXxlytc/v6BOBaGEcdNlPjq09YcvucR61GeX9Hd2AJ+SoK6Rjmtmfl\n",
              "pRmxONMAGnvJNhctXJ2Piv43fQ33K9NuEK4NvOyv4OeUVagFMCI+tKsi1kD8C1NnO52oweya42XN\n",
              "gNZiE539ha1N50q7Wu8M31xZfDCiI4EtNDnBZYF3+cNy4uxLFWY+GUuiQHkS9ek7Y5k/DHKBw5Qg\n",
              "ySfc8Cb/N2xSq///7qxiRM6oE3LV65Ohxmnm4NXNqyI3k2fkO32QknX5IwR9mxn5y7wXLbsPoICo\n",
              "x+XQ19gMFI991KMW2YWSdtEiU4VRy3S2PaY/q0kylh949vPF3ThC7P7S9cniH/HdK0lk7699zcpK\n",
              "9WdTSG1t1glq6rWQPjKbwhrs9KQhbv4cA/D2a9Jpk5124KKn0ilpUbzGTDFKjmF8NoaFKLYJuvaC\n",
              "PyKxKYi4QhC2VQ8lcZj4IMKBBOp03BKlulUIMbd02Pb7486vzu0wNq33VlEB3tHHe7aHeeH48Nw2\n",
              "Fo7s4e8ffm4ceTuISLKcPmLwMQMMOSufKI0vZHoz9+/LDWJZ0Bo7cWMV4myvQJeRNXTbyL/o8BqD\n",
              "nltBq3fDejzu61J3XyDxUgEuLbMkASnuACtf38Q4AM0Bz0tfPVAHNNRmi60vn3DAVb5Paz3rh/ns\n",
              "TQ/GaZEf9JuoPvwOxu8Kli5SbB0pbpyTCNZ0FoHdnduCLqO1VbdcCSBFSzFslTyTi4FpAO0+M1w7\n",
              "/wouph+AGWqnHrrl5mphJg4+sANhGiz/qS6Y0gTmX/WSDQt0rtsjFTQxOFz7NGc+sHYvRcaGNcvi\n",
              "ijqW6uoGXx/pUkm9Kfzvm1qZIWJsfiCBsi3Fv0VXZjl8vxso8KQ/Yat/UPp/AqZt7cHOqFfkcMKS\n",
              "b/KbZ9Jn0r+Dp+613nTVuyAIDNb7i2k40F+zZ3gi1N1AGYSAk3U6EVs7KSJBfo5txxETHczFeiDS\n",
              "Avz27djQavZ1g99BcsnfRQA8ky1Ld/8IzvY7WsInj2XLf/Ghrv5x4WsnNe70sSll9rrmOZFgjN63\n",
              "P7e/ut+ExpMVFFlQCr5hnEIpqaVUD8sLgZ3ssHRJrSwLL6Phbd88Gkxd5k+GrRB1UXAIrw59j1KD\n",
              "cbQjr8ip1KaWzev5NRf6PsmyvJkWDlb4C+X0lP2h3cNAAiUnTZi7OAJmxZFjwJmfFfLW61Q/DXGl\n",
              "mjchTOK3R4UEiLKkqHjor300TvLFcluB5abLEe7Qc3SCYhsCPVNBAtCtrB2l6vlb2KOxf+jmlmuX\n",
              "9tCUjkQYeN3MwqMcRL71DqnIaMXFpn0cB541kgyWxBJ/j3fjWpDnMPB+mHTwg4x1pu4aVbt1O3Zx\n",
              "c09PJ4QjLbnjbQA3HFWuoX6yyREwYyyc3J1uJ1kS6YmkC4WepO9oPDWTu/q/fWybB4CSrzwIoj9z\n",
              "bIvGGDWESfvwRquovhGeElKfAxd1WL4xCBOeXh5RMYDDZ9l4xPi7/0lBp8jv0KSwhj/CxLLkNr3b\n",
              "tXy8rQvz5DayUBraYfbZMx2uKhOaAydCk9fLDnq06UeAmywNr08AsozAosmu4B1wFR4Iah8QJ0zF\n",
              "Zn2uwrTP7mMymb7/k4wj7irJS4YXKLU2XScCqDcANGqBbYpxtlKzFlHqEdMjbKps1sgLbclaXu2/\n",
              "HsFAiXeFRa2IjgtOjpiRnm616d9ktcclpadSky0EE47d3unS1Rku32ithgTPxIhaHd+mOPa604MJ\n",
              "I7+GuPe20BRky0O+mesT5ylGWuGlAcHLkWmOPQ9Prlsed5v8LYCsZ4R/K1dNglHZ4PypX/chtf8u\n",
              "GLreI8v/tA2dpTssiLSWoaslbdrgRbQHAnO3tX0U86a5plkAW0TsA1qt5qzx6zT8QdZMSG/DkfOi\n",
              "/ClGo97J+LWV5VhSiJgXuEGwtCuEV/d81/Gdb+PzQ744galQ1Wo+0sI1ENI9qhm2+2Pw0Mq+woM5\n",
              "+fni2xXZ7qRB506tE1G/B/C8yN/yDTeLsuchPY38WTSysQh1zDVz9OtauNE/VcqWNhg7+vuD2atA\n",
              "/x9m05hl+eeqt/vB0pvK4xMY9umFxmLmN1MWKiLZs84c8TfzS9ASe0AVXI7pPhdAd1Xv8m9dQ3Cq\n",
              "3QfHcR7chi5wcBkDsCgjESSJnywp2H+Si2AEwKyE3sJh7XX6Cp1haDPI3pwkycbYqt5nPUOkxa8+\n",
              "7pJUgKkznpFW5nmL47K3bMY/JkGAoCxvt6cOPgPmJwmBG7Ah98fzrJ+68828LVoQ7a8EqTfeYNcG\n",
              "YZ2DHlshseeNLrElZpzKhy5dFqUSNkKSHJ0PG0M5Mq8wM8rCbkpZbnwO2WfTcjlOwuuWmuSWoxdK\n",
              "RLjQgksr+FB8LnlqYfNhB+Igq2PqNYeNgQNJZhnjMAC4HBPI2cVTGcYStzdIdcL8+UyKxsV4Vyp8\n",
              "EMjZQZ1NsPXcXWT2aYyeqvBF+a1MuGl/044KOYL5BfPKTRwWzcshpB6BxRjcgY71vtyVtNMEkgGd\n",
              "EdxcnsP42WR74dUr1xhSUvyWwOTF6UV16RO5buSwDg99kf5T0GnfSqAfVddBjaL29VQFnyzK0Mk2\n",
              "OrF03EdK9pSpNSajjMsVnGFRW+KnZSKKQpTWYYZNDFc8J6jOlHIJZ+Ddh0js7VageX/AdxoE0dJ1\n",
              "8sPMdWa3Pz8tjdMYAviFR6nVSFiFFc0Z4kSrI3vkaK+lJWot8kIlU1+QgHZN5WbKaijnhFG6hQBB\n",
              "EUW+LWwNgRYU3LWOimZlMi3hBhFtDZtFGirnj29DqRXv7ark5FZrSVSLrUveWnC5DooyCCcXB+QU\n",
              "yZ3IQd4/uRdzneKTZPzexgFuaw0VyRFPkNO1dW/qs14z/cR+FkNd73Bsc3VEd1jdWmPMaT1/UVar\n",
              "7AO/7CiKNE0mpLWpP53lqq++3JT8viZns4o9tl+jekWNvq3j66DWYHSU2RUjCPe5BIeqIoiPBV9Q\n",
              "yN/PpaFTyBXDtHdMVx2FgzNZ3rxG3hmwwrK3VWCg8yRDF4hoXugb+CB7uqXdntPP5YhcTBPnWa01\n",
              "tY+dCthnSBMC5R1HXeq8Iq2InuGCeTIEUqNm4cUb7Nzl0IKUI5jG/5Y7GfhdfRhRvukwe1dCCAtB\n",
              "tReBVIOjVovTyDADH4AAfWuNa1E2TqF5eOisfX3A74I6MIU1PJa+HfKGbA2zwCcv4n9Ai5dAe1Gc\n",
              "jh9fF0kU0AAtK/Yn3ix/qifZyi/0UPiLFHOxkvnhXMPJNaNY6k6lcrPup1bws9OF1aH77eOIJLqs\n",
              "F9JDbkZPJph/J0eCcUSszqf4nTo9+7nQ4/hBatMLzO/1AFrvEEVB1eZ8YCEAYZkNX6TytzI7Gn9z\n",
              "jYmM1SV15xlv9gTlpWQ9+k3wksiWSeI/hzLN3rYGBcTAd/OQxWOLygG/lc8+7NQXXp0kxtJCocNs\n",
              "OduZPE/58S9/plPhCsT8GsHmQUtEQ5PonNKMKEwaeFCOZzmvC8z1spA74C5BUpanRhEX/bv3bOQj\n",
              "LTTnhfQO5uEDrf3Na0yUJyahOQ4meETQyYrhjX71cwCwxciwWxyTVK/HPJvi/LR3/4ErLp6op5T+\n",
              "T5gS+s8uQUYGovQQQYIJP2iUe6pNvxCIwwlTM7E5F5YWBkhPZLNZmRXUDeXhc5mD+VzOd808I1ok\n",
              "0a1TAxH+075U5xdfpYdPWcKyHfmjKNOpltcKBzhjJfW9R3t9qJMKFR8SrVpdgzuHGRQ/HXGnmDbd\n",
              "fyjthNHryl1+Yp+CfAbpbQxSQ9OljfxMiJBqbcuJNWCeCrqP/m+mNxtHJwa9vYU2PMaYPsd1ewhE\n",
              "BPW9bY66WnJXm/vcmF5XSCxcoCdzoy8wxK9Y+cfyu2czHss0MBRi1GB4IPjHCk14Qq6a149/DOIR\n",
              "yDc+x8v45HRCvV0u4P4pnNLMdi6My7OGfaYrrFx1eFXZJyiAsM3KEG+6QDfJzKHYsQX0ra1K3aE3\n",
              "dObPTE2VORP/qrYi3wJ5a/xojeHOjNGx1I5d0WOrpRSfUruobZ2QLegtv2RD8yAK1tslakFN0zdf\n",
              "u3r//drplq5y4oj1daey/o+64t0fVALkR2v24AkayYIzfDLGT+RVnpa175IiphFYyRW7F08hAThv\n",
              "jNvq3K55KFw5DO1wLPVGyTnkUyaiyouHslUVTBlUl2SErTvjGA+SItO+2q0Tuxlyxuzkr5Jczk+i\n",
              "X8cn8qvWWbJNRjU2ivMZNIhO5zV8ZgrtBKOWXn9rzhfKHCsccGuHgulKNVeJmJ/ge7h0anlLAiga\n",
              "fAASUMd/5gKRCDd9oQMQ9IMFVzIJQZ6PSzqEvgP4XHDnvdHZRZMr3MFNfnRMHr6JVeT1LL/pNDOS\n",
              "1FcEgMfQhUj5Ag5Fn2L8KnyUkQ+Q5H/rCicFcvo6WeoGr7rrYMCd1/yCb5/sEUHQg06k4cn2WsYO\n",
              "6Hd6K6FTmepmMRFDn1P/35aKQ5xuBWLkPQCMLb76vplTnYOV3hybdXjGRg2W1i28A0vuFjyXMKw+\n",
              "6R/AM20jXgvy9g+lsw7rF2ncWj7bIENnsvIAAUPSZs/W9p3hfYqVuXLlFpMwqRunRD1bQuboSKrx\n",
              "faSFZ1lpPXhmnkCsAFbjtKRk35kxWvVcOeXfHLt2+YIIriSjxy+8E4Q3S3MAf2kO8ABAPrlPOf8n\n",
              "SeHTIZrfZl6XQjaK4unC2tmDBL+yaSsGRSG+FNp98PHjh01njvmuSwf3q8groVP+fikKBgnw/7u+\n",
              "yZ2nQ63B2CAkhUC/RbiBorldg6C1qpeq/Ue9BjZ2rEtR+cOHBYVx8toFqMYClS9Faa3J1eLuF93v\n",
              "IRuBw76oUNkelDpOscAdS8IQbmVTsFXSLQEqUgyNRB1LzV2RUKxKmRqgcPIRhbN/DnsKgE7cJA69\n",
              "yFstSaMlfTZEkV8H9tMGMv6uLK5vezuCbdzq0AjkJfPMMmIi/kK/pUMXsWXNwdz0KPMbaxEJhgC0\n",
              "3igYud1qccUalMxZ/LX0QpLWfQORw1aVN+Ozf8lqLzq/oiNGFu+Bvf3PO/xZIvGJdU890w+C9+he\n",
              "5EjyJCcsoEJaQuZq4trANTuXHsowRMEALXIxWNCwtWf0V6IWmJUJtZofRs2PShZh85l46yMMRfSp\n",
              "q3/7112sSEOxDXDOabgo0/s6MRSElq43aFabpYKrPvFxlX/vOUOhJH4YmP6bcFwHFVezJxaTE8RZ\n",
              "60qoKNPSjMyVGQ9P3KSUoSm22v35aUwhzykbW0V7UXZ+R9/8UvEiUYIrqzkmCZ1cUJ9c30nEdb/N\n",
              "N6+tPVj18aHB1pbw0ZkAWFpMGLDqHAHMyT7PrqAiXIpFd5IlPiLeCf7SsT9whl4NQyxG+6K2HE6N\n",
              "Qinm0T8whFW/v6dRhlGX3ygKP4KKHhEq4We14tfF3rFvVrbYB00BVW5Ma6mkAq6AYS/Bs9znBPnA\n",
              "QoRTZiaKbJqXp+KAkgH7Uf+rP7CHbWHlEpbqPbVY/8IjCHQ1GqGz1iVucKiKsbwGOCbYl3bheiK+\n",
              "mNWCKHIbhMeRTjJnsB4+pdnr2+zvzyVFnFfcyrF7Wi5NBxlc/vpL9qJ45wMVCxbGS7CD+jqL8ZxC\n",
              "8xSzKRiAm3J7Zxck8w1gyrhyo3vhwN3G8G6BLj1+fcvstMrq/HW3gZ0JY8zde7xgC1Ovw32BW9Qm\n",
              "dAh14tKfx4nwZn3pNqP8H/Bv5b/wrcYD3Hbb+HJEehQMzhnwkQ21jqbitnS6y5tPDNKjCU4tF4Ze\n",
              "dcO6de1HzOAIndYGaNd1jYsIFz7D6dwi/DpXk9XaxOZVJCYEzv4wV05Zdw5HUBmZZbnwql3W14mj\n",
              "qq+As7TZ6pNEFAPGReMw5UPCPD0yRR4xI76FEC6J3LJ6zmkNOaPJEUC57OMGmAon86U2hi0N9FIC\n",
              "pF9IQJSnMtNOF+METaMxqCId2A16vCIWQBn7kIHgGjn7IRE2xtVHfqITzxSkNmKdu3nOIDS/DImW\n",
              "PdfEmEQdvLtsqzlQEGcR9dVcZRVhlFqcJQSn0D/3zXds9o5gLk2EQQTeVq05Jt/fCHmxliFdBKEc\n",
              "X2aKT+c8ARBkhC2UWgWDFNK9xkuh1iMRmjE7dvCnIxnXVVxcqcH1iYZ3HuLsAIOnd2523NUzYDkE\n",
              "kmeVAhxzP5fGsIKvBwitv4DJegwNS/KsdGAgPSPpCMbhdJufRDtpbnlADvmKa8y/6LCBhPJoGP7G\n",
              "jtpHb8M930Y8AAyV6G3hPxhZAAADAgsAABSBQZoibEEP/qpVAAkPLn2NcYtbAAt5buF2Etlre8g7\n",
              "vi3g1D2Y5cK9LaxghIsJDd9TUodp8n8unBy1Q6jJL215/8XR6/qZxvSQOyTp8SwV6DTfZoPxup14\n",
              "ut8LX8aEmM9Wprjy7LIDlW+GNaFh2VMy2NUz//0fvnjJBsVLd9+dR7UKMjo7J6aSenJi/Mnq0GWr\n",
              "/ic6Yq7Seme6q3vIjvKUth7TczezmWVXvR1lFIPSeAl6qfGBaGmSz8ZjoAUQb6ncZKyvelid98Ad\n",
              "9OxjYFc5TF0ARRE/hy6btFHLHxs79Yz9ekK6vHKgaZPYs/MnW7GBYcTSQBeaijAdJxZqxgbXEFZm\n",
              "6QyqVk1zMgoxvsWEXwmGsHtMbLNPr1rsL//O7Msp1Zr6/aItj2czmlFRhRUvB/+hicGOZk4kBeoL\n",
              "9ERKsyh+O/8jsesaIHDbnCUEGN6fI4W3Tjp/Rc9E4bns/vq9yX8iK0tmCc6tpWD1jnuYow2dqIsY\n",
              "mtEJ8esS1cFImK7PcaCfRgc8kbgpy2Wd/LasPhb+Q1rzT8sdEc4zO6zd7a8qXXq749SKR8Omqx3z\n",
              "tEqxvGj6/CEwThu8YLK3AKnrbaZgsiG6GRGmVO15gDUy+JvvF4JXfEbXtmyYuyo9pQ8kxJVFMdFf\n",
              "6IqTMdDM+IXaP1+nbxfxck6zjjnKaHip+HocSpFMedxszXfvzw0qxfJEC5sCvYbJFx2SBvwdqPaK\n",
              "hwp6kiqXPI0SSbM4UdLIfQyVKxPs/UcVrpk5U6cUEqUpPhwBKLCgcZX8Tm4XZ1GrWrft+TiNkLEp\n",
              "W/6ZT283LwvCUmEPMtYUxnHqJ3NmGw2XQ1Cd2pvzqGqDSdTWx88kUacJqGEt18kq47X7vvHFIrIr\n",
              "GbHQ4ovXLD1q+sggbRlqxqAPs5IukgnzYJ6bnb5v3E3YQTMj8KAjKhZSKn7+f8POs8cmYssk3J0f\n",
              "aRicq4l68n10dAIgLiIv6ODccGhIviNIETyYrfkBUcn8isZsWaZSIGls1NgSKHO+r8cYQzXNI7j1\n",
              "N4SbbHa6e8OFsu3AzMfQ6hZOWr7vdWgeN8pjcZ9f3Rs82mOfQ/Sd0Yqq78aTLvKkj1IP5dt5xkzZ\n",
              "patdPJRP+Aiu65fl5p9LSR0mOnNn68Zd8sJA7zehRKObhSBcb2ud+uEOhysNvQOaMovguMZeD9Co\n",
              "aHG7LKNUY6MbmBMwltcYxyEnO11JVbXhzSdrm/ZNmGNLo05Woe1dtS78r+uml6+UWOw/t+yFJBeV\n",
              "o6LU6h4BYgU3ygCqLZRII1RCZDiYZY3PyD2u9kCEeWKac8i70JDXFUrIyFnih8MGrt+K7AVYUSJi\n",
              "V2NoNMj+AwXRRa+JHrFoxYK2G9lT/lnkwY+YXmKhx+P1EsGmZ3I+BgFGHBkZglFmdEGNrCX7pp8U\n",
              "xEZUBGy1/ligrG2RV6UEGVjEfqpoHlljVB97txKPFuSGwY4imiSTcy7TqHshOE+oHq7zT+j88w5c\n",
              "+Rt7KQejprnX9xo7subBdemD9WhJZEjWWFB9XwdYao9ajvRnnIJgKggqFt1+Z85qXZ/dAFZx9wj8\n",
              "3KcHj09AbMTSYFjU+fFrTd0zfMBFsqXjyHnXueh7soa+F1YorOJdOKwfxqrkZ997GNFB4vTiQwW2\n",
              "0oaI/bocDOgoBB6FkYK014/9WbRbhHbSMB8x8KqGBq7H/KYtsxLigpa3F7K46UQWSv5AqcwBBse4\n",
              "N79iL8KKkZXMJN/AMtuh/S7rgEOelLYLdyIGBxwtbM1zilOA7RqSeFcwujzKJ/oFIwOE5a8JAhi8\n",
              "3MZfjU1S26H5CEiOWjLvWmHYziMcau/DCjI01nJqhcnRPvCOVwJvx9FrqdneYzfCN/t/gRfiPTpe\n",
              "T8FxN273L8epd9AwF8D1ih+3WvHRUJI/p2VmqhlZjNDnpIJzC98wRv/qRn0ts88RIx9F67vILgZ/\n",
              "nAFSYFISE7yFc/Byb8vFFK8DXS+lyAFXrzzbOUbglriSGOBr20ZodyLuBP3LeSEvfuObW/rBzbds\n",
              "/uSWVvfpjC0vtRz1r7Aj1KwF9b1a/VAowKJNQo/euJiItLZlo+0atHFeZhpxzl1D5wjBvOLv5eLV\n",
              "wNzzZN5B2csqwYBCBvY779/i/bMIlWlh1EIkN1nbzCWKVw2k10RPXIQ0ZXLP3fIN5wdx7eo1avcG\n",
              "I+Fp/gsgk5nN60UcnvT1WUggkd32VksByd8Ia4YxERsHeKmfrq4c9o+zm+stu66L9Zsnk/famECp\n",
              "RA/0G3MfsXHFzT6Ic2SYbehFlrvQBeaPTaDj9h8mATlkTf5mf6hO2Yj9yZyWh8qQ9CRdvSsvm9Gu\n",
              "5xqZ8vcJAe8VLWBUwr5RN4B34D1iFCMEbkw9qSEwfg+GOvR4mt61cg5PjvPvt+oAQ4+GhWNH0mJV\n",
              "rO7ekWn+LlGZpT1IjZhtkMZqAmbtqaGPnjRtir5ftVNhgOcgOL6HoofaCeylHp4/l5atvov1+SJ2\n",
              "9T6oqORagUx2jf1t6yPK4KRCCSMi65f+UVXOaU7OLNDBsWCDQF/STfgS7wl+QfidTOBPV7nSygVP\n",
              "LWXiRQgAWJZzHR650IVzMzhIP+f4icfobVG3LWm8dEfJJs0OFsBXbRL3DRLZP+plHs+FoIqb6bK7\n",
              "y0P4vipQgSFJs59ulUud90CupY7qNnaFdIW3wYvXLRGX7QA+1vuJ1CcG0gG6/NcSTYj8ceNSJzfr\n",
              "1bYzzZSrXNMWqlRCJJhVBMc8iZmE7qNic7pj/VwIgg67v2uY+NUL2joq9cF96tjONLAdoFA/VmBK\n",
              "MvIAm48D15rKomZ3fRPXt9qvwgmQhJIYs/VoKy3DV+rJELW/oCNLC7r/9apntk7cCKlFLPGtFkVM\n",
              "eUmCRskaGj5+cq3j+8qs1EP/fD+BHVTAjZTVK+lnqkgagCRv+tkdNlemSAlGTfntOC/osRGcwfjs\n",
              "lpclVTavg0GZpSwD6ai6KdIPsastEGF3mqtrE+Hlw7NmrY1LxkB7EAVDeiZVVScia+RqWqe2Yd/R\n",
              "hDc3D45QyLec41OVqoV/Iz2AkIFoQrfrWGx8fYScn5U5muo7xCfMLZWKz5OBvxuncakzhD+nc/G/\n",
              "+gTL/9udHUCJkOCAxqEjjMSKH37tTSp0GiRwwCl6OlPxMobdvHYc8CifMYCgdjht2c2zYA37P6x3\n",
              "/wmCdHzOMQ4e1m/tFV/3ktJyFaiZYlpR+KJj2TmkGHSopIvTIuqXxhNAv1h4IzE4LtjsdSG7LNq7\n",
              "P9icaKgPY65ZRxmwy8nTkjRKO2RVj9Ft4yP8JjuMF23Obsr502LSkh89snK6ttljyH3cK3UScKo3\n",
              "6hUC3Qzxu6MHh1/iqsyKQkdsNHuwgnLkN7MtmZaZPUhMmD7ym3rU1dljYkgGoay7kj/P8whKox9I\n",
              "n2tfl6VkggQ47Xa8RICs0wpHK0tvMnQsn7rNlt+zeAiLINPC5tm2ONrSvcROZi+nGfBol0cmUjjW\n",
              "NWoUtjdy3PzilKrVgg4aZ52Uuq6zAXswKw/HbikL8s9eMDpqd+v2XhphfMtuPvGiOZtyxNqX7UIA\n",
              "8K6YiLEx3poUWMeBzyfC+4z1JYXZWMYlxBLoi14BjZEamInV2OowCCM2BskJpeGlT7A3prS+tw8n\n",
              "g0pjLHMceXMx9n2k784Kg9QxGsAWLvIOlUDms9jwxdlHg0kLyhyUmp3RO2RAmJoOCmFfzfr/3Ato\n",
              "aNJymJiKWtHvTklWMtXBF6YwPOltey7eMZJJMD8rbLFrettf3CETHU7FT/6fXTxRQs+UIlV3YyDf\n",
              "yMz7Xu9aNPmYO4IGnYUcpmH3VSyo530kv3TsUAxU5W12Mqpo/Z1UhohWufitDCOnIJFgwdJBElBW\n",
              "lvr9tDztexYaCNQXgCqwS8u4mcQYgNPpcK8iReKzMUxblS2LXHqpht3TbUne7WAne/XPK+BA2hNI\n",
              "3hGYr+54H6nW90aoVLtSF+HK2qX9p0ByoKC3zavtUR/AQO7wO5PvqSmEWxfSg6ptWy/mxof20ivL\n",
              "p8D1VLcGBozJ9LkD+UInxQgXHM8BscCmYA6E0dIoOPFac1uRQTCNoj+9iadZ1IZS3DFrthf/cUCM\n",
              "qSjpAY5LBs/wvLW1b6luxbfGQMWqTtD6nsSgZNyZZCoMQeFWvuXTYnRpgS4ZMSPewImPPLRquY9O\n",
              "lr0IIV3zqcT8zlsQFqnnA3e0CoLAYmkQ36sURtxnLGmUSVEDwM/oNEbWbNCzT0Ta1XmgqQ2M4nXj\n",
              "ZgkH8A3vusa0bt0ydG5absiD7Rfg7ZSpVLPzmgbm/kPgDfY325oTb7GDjy4c90a4eZme7ZKgZ6Lm\n",
              "t0wmfaTasnFJRTjYyfvOlXCsNF9PhsUcRFDhQl8a/Rs6H0VJxngo3dG8Solz+F+Gzzqkry4gdq8k\n",
              "xwxd8W4B1y4e2Q1baH+4t18b0HsQaeNCAAwIDxVfIBQwosSf1i2pKiBFh81Nz+/5Hy3HnPO0/uRS\n",
              "fK3M38OwFc+1VRIrQ9QPFs0cYy2KwB5UiJ77+sdf8yFwdgDp0GW9fcMYFUjpO4mCZc7wa2gtePm9\n",
              "KomtF5JDYhO+thzHPoODF0ksk7wD5MyVeNhuX1yUONg3fEzMR2XK8LXH36nyp9LoBIUzpQsoso06\n",
              "rnwKbhe353AgaMGTgVdtUgRDp5Wum9nLdwUoIeDyOHPJoarpyF6rIXi4AXwmatqI/TE4zjKyURYd\n",
              "X3uSmNARCbNf8ciyljjka9qBpRoYbadOGhNVHQdAfKSHUAziC0oTD0pdbuR2zcGq23mW11pFY7eV\n",
              "eS8unpzA+Y88yRwVu9g9sZo8kpZYFucWf8O1Fz18P9N3YUoct2qu2SZracH9yw0nhOgFmOQWgjrp\n",
              "RP/wna03bC5730j2Mzml7cJdtv/IMkVR8ngi0vc++klNKzwfEy8S1r3krky297OzLh+L/0O+pDHg\n",
              "u07dEwSqsTtD8BY36YQn5oQvqLnFUKAyhzrp36UTePvXbhdrCTSBYdNXMlPKinJHFnTBC0f8hB1O\n",
              "8coJrTzYj7LljJZorTCerwm9k6tT2nHPFFwnbd8cZ1T4vjjzbGITFG7Ywy5wZciRcvwKWxKXlDqP\n",
              "pe2ItBolcaqDm3lXUNcFEyKCEgOWOOyItN3Ob1H6UwIgZOvkq57k6P4Pe2IsKp2L8sS4AcvZhOFQ\n",
              "1le+BvE/88tOYDJWgGTFWxUfAiN92yTTviPIyhCQf1ihUCpdcQcVnuX8AD5fyeRhbmZFDqzCehJE\n",
              "zVboFbCLxAca6AKXWXS4ss47HgoPeeRJ21Vv7EDi1qtpm4dOOdxbhMXqwNtxAYVBtA8PiZkGjI5v\n",
              "H2Em8+oB0mmfJZGxvSACdaxJeuN47k8WJgENRLiZgoLWNZGrEC24tmzNK6+bLqgLgem7ATONJhLx\n",
              "5H3yyugmdd19vj/QzS9ozM8MnYCmkQL/KJuc7lU7LaMxFQQuGFZKqr7dJ2/hGh9br/vGEFRoc1pn\n",
              "XN2bNGJGwZB2RRnYfuO0JM4CV5nZ0dyShvgtEPfYJ5vWypwdtxgD3k8ZtiD1IvU5uiCmyG6aTzwY\n",
              "B0W3f6cqtca1vfLxZLf5Qg2la+wJAySWkUNztBQ5ufkdGEUAejSYqLSF996hNRvqVak+HzrHcPdd\n",
              "xu4AbF2rsC8P+AzyS+/gMvAA4ZMvqEmauDE3fhWyBq4RXFgmVS6fjGtPCQYD09lhKy9btH1rR17v\n",
              "kgjIblnM9khT0WHP6x7dJsihtHMXdWfJCe0KhPLFfy80fMt739Sp6R+RiGkeULwBxAl4HABhLj95\n",
              "XvybGpGdv7XaFwMxtQ60ryKfnt4rIWcfxANUoGCT/BwG6f3OQr4ymurQeJ/msBp+WwOwNEv42tmd\n",
              "rSi9Kon36ifYJAP4ptJlbxGJpwhWimYV0mc+9m3Trr1sNOjCcCd5uViD08p29TRrK0VxTyCIOmhV\n",
              "EEWPmLxfbSjolZPfkEKa0tJQX9L8SCMv3JaG0MIWZcjklubNEfRrVD78Cnav0vt2BDZbJXc7xUBD\n",
              "M+pgYXig4gZpiovryfUTOc2Wbnm+7JyMYk0T3Lwqrixg1rJabRz/sg6igjIGwqNdqtenJVHAafIn\n",
              "LtxrDeejTxZURff8WxMP5rmwalvwrI4ye8t3+bG/SC220rRSfG+GT40RbSe0IDgFwkiU+T2dyOl+\n",
              "BMLLrM2LEtRrK9jeKQvw4GKmEJ9OGCtOLj2LygPnaa+hLF4S0HrgkpSbkO9KYfifgACYpJnAS59H\n",
              "vD2pbMS6zkonfITL38Xcy/1aNHWRpgLQSss6ho3q5bzGpTzhWhJX1KFpALIeteCVasxz+WdRTLlN\n",
              "ZDVaTZJkr0HcTKwJPFyAfbDsK2t+LfjYxxbVE6lOrPR5C1oRK0UHWpAYboO1bXpyNYUP+ghligGA\n",
              "0vDGGf+GHii4F/rejCrDMOyrGSYrhRmfG04DY56+WDBb3Ib9RLt4vZXkM5l+oWYL4qFs2kbvJZcp\n",
              "ydQnP+Heog73cTCv24pACFTn/Lj49CSJZhLwlNW3gWnix8j0SP9TG/HrlomWj0bUAibwqX3PKB33\n",
              "YsfNMY75KyTZe6S0At26uFY8r1jVsj+0DOTaDXFmHUV1ALmVru/OwNZG4gv95sDAJxZsMCjKQk/l\n",
              "+mE+2/+XtNIFw00fvRT5Y6RQplBV2UEDdVcB5Yk7piyebOcTmuKlHQZzJuWPMxb/OHf/G9UTxTmE\n",
              "tt0snU0uaOxCsOEWrY0D1zqjebisH2CLR/8BxFL50LggC24PWAVGb4ZEi/NVY5SaWz/oVU29OD/7\n",
              "uDUS9RpkekKnOl9fA2fFQwn4q0Kp9NpeXnxD3F8RVE6FLVGTBABC64It0mnttJu4/8cbMdvctIyi\n",
              "JtWyoreFzYbQEbqD7sN5ozTSEuBRN6lG6H3FmyMToVK7Cy/e2E9kEd6YoZ87yrayH8Lro/yTMNuz\n",
              "T14PreYh7stvxgdDV8uG8r/+aZWCX0qq3MXeib4qwq2QW2O16ko+fle/XI38QKzBBkrrQS3U8v6F\n",
              "Wm4xd95URNJ47swiuojNYxfEXRdwU2E/lR5ERkk+pc8AAA2mAZ5BeQ3/ADzHyaGX6AC1Ib+l9APs\n",
              "G5+XAwbAd1/9/3VLGOPYU4jzNTWZMCc7tR9PuoT5xt56RcNo57YqwnoSqy42KA0i4HfFi5JqV8BV\n",
              "Gs2lcYlt2/1nX02LH5tc+xWDC0A3XdinbfrA+Y5BEcm45Ilcm7qse+SPSM2sJSvP8O1JQnE6grtA\n",
              "ddobDq8V6BGebV7AQs9KE4/GKoVBnjgATwjImF9/HsWGiOL9wGPi+I0Qv8bfmdma1C4PjVxXhDRS\n",
              "lvYx/c9KsebmjIKlgPI49TOOVAIoa0UdKuJSrqU15D6DYAie4AlE9ty+arMnAxp4ICpycyE9c2q7\n",
              "t2Bqa4lZzXOUC5Gt3CjW7i+PG1n8kwzqTfGVZkJPULIAyU9aKZs67J7zCKD3TuWItxIJdZzzz4Fk\n",
              "GKeJbzE6tIADQyv/ZhIgY93ebQRjfgkyp6reDj5xQbXfb96m6Pl0/TfcNpKNhsxRBSVjWKzECJ6j\n",
              "P6K5znnmN5nkT43xQKrnxCMPSQVm1Bu98Gijy9QEuye0fVU3XMru6YE9LmTaBy+EoFYasrKZ1VMZ\n",
              "r3eXM+SaiFe3zkeIzpOcOlMyHyJNW/fUSTNNj2ul2iEG6+7WIrMTvV9+dmAPNSgizaDjuYw2PvNX\n",
              "mE7/h35wTrK6IT/L7/nsCMB+SSl4FDar+XebNvT7+5tmynyuuyivry/tN2cdabVqGZDQkvVMD709\n",
              "K82KK6hLTjeHMQY9bXLy73psWbX17TS2MpVZQqn9fi68mVT5so3IVDPUpIILFev7T9ANBn0gebtr\n",
              "hTHIOIX6K6a3D9QJIJjdf+vVKIeR0bq7rYDDxN5PYdApB82KGiOwc15P0Ylixa+c0Lrl1x4NHAuI\n",
              "6RlaY9NSYoYzPxqF7Dc1c0bkb/rGnIZaIAuHj7YxrolVEoj+F8oLBM0Fjg2/OD3RANE6kFFJOjQQ\n",
              "la6dsSABp3e7y+BEHnBO8GTrCdNT3QOroomDpl0eSddsmHVYw/cN6po+pek7jk+HE4RM0xQ5PpKG\n",
              "HH0Ott8OOOQ10KoX9912df1J8t6cLxsv2Uwu4WgGc7PQElQ719S3/UuraN1fuRf84dtST6zcQ2qU\n",
              "mzWaFpgYwKic+TYTc5I+HqpNx4gT9pLJaaZ5O8fyZ/l+KBKUXIMCP7u8Hid/QIGUorTO1IIoHPrj\n",
              "Gta8aAbOvbeRUme6bucRQtmslN9qEll5sKen6eFr7iZ6eTIBx72SZXcVaOncTVbUV5WF7cpjXI8a\n",
              "UrPOT/aukktlAKF3TALIUkgNH72UNQ/rCqQzXBnoolPorzJSUMnrlY2fHHf9axIILImWizdDxUYP\n",
              "XCnRhflx9qpE4qTiobxSicWFhdnPK9EK9V47hRkgOB7Ed6o+i0YAJmhr6akKdLI5G0k/krwqe7yb\n",
              "WgDhARqSot5p9BIJTmRBfCb2N95Or7Afu7bWWuvOQ5K9zQDEqn0ROo21XqN9zEdQY0bbKTiqx0bZ\n",
              "SKXUKqi9HOxtJPiPcO5Bms94c6ht9whCNctjPoOrtvINCB50tF1MCsWoOfQIiBJDIfQIM3lFl1eS\n",
              "2fKCWC/I2Y9pfr3zF0Yz4URSyMez49G6vQHUhZe2t7M6jvr6tF7IQ/7qUeDjloX8kdcjYHzuAROf\n",
              "0rY5mk8Tz8DPWRkQhVRQzb5WBBXKmOitJ2QVnVeqh9Pb/Z6Hp2AECCrt9w9ILkZhAN6vir0sq1BE\n",
              "8/mU9Qgt4f7vUqbHGmgVHv/YkMaB0oeFSS1h8h2MefWZ2HHawF0FPxqkzXw4uAGxV8jXi1vP3KZR\n",
              "NBxxOIeY0YH9lKe2uiRCFKuuwe/ik+cbT+lyq8dyLOX9fbt8io4BHc+rB/r0FyQiKsWgZS1NYiY+\n",
              "QfqBNQOYVRKXRft0i9es3sD2s+LAwZID6GsyiUlDS5rwJzvATJqRe7j0scLFuMDUwxXJTXNrluQK\n",
              "Z0UxLiTSndYfK8rKqxVIkiiRMOekd192Bhuu9I6C33naOv8tMnxDj/Z/IucNFFCgYZ4cZqx1FhBm\n",
              "BLF8Qwr0D2bLewj3u4ymm5qrww6pNs0zRb3mZLprdmbHByzWkGmZxyISoI/lxIxW4G8SLa3/ywTh\n",
              "+Xyh018CRL8Mku4Dc8JwSFUvjlX6ccaArX42lBVvocY75Of2K6268wC6+JALQHd58LADHAlkE6pl\n",
              "vLLIqxa+wK9DB+oIxtXahln5s5J5LZatQGQWlYuY6yN1Ri3mggVm5lAXxPEEn7YmkfJtABcE4ZSl\n",
              "R/DQ1OfJ6IiLCvqilAWMek8ytue152w88yoZmnyUo+R472iE0ffxQcr1Be5tJE42hg/R21AIeKNr\n",
              "DLKKSl9Sb6GUkVIwGTnFugbZnd2vv9JA/V+fADTE34v2EaYqYFO1AjBuQepAoGXL/3zdMC5HeUTv\n",
              "Gd16S9iRRDzwNlMk7IrSvWATc9HSgckYTfV3UZRkR09zKLA6oRmn/n1eskrM0mRpBXu9MnQopIVt\n",
              "PtNMRQ63yOmZzS2jqR7VIqHhehhdObiWv8NjbAQaKJLiq+JwgNOOSUJK2K5OGKPl9LABX7bDztaM\n",
              "m1+f/eVa12SDlk+iA8tjf8teecVPGRU9CtEaE/5NX34SymWlSbJ4RFpVyN89YxAcXChxZA5rLbq2\n",
              "kA/K098JtTEZRrhxXkKf8ZAHRZoJlP4nK3BpEDP1OuWWnK5c2E5Ug1G7inr41u2IWlL/NFGnL3kp\n",
              "1Eug1B0wgKYUq6RtphuLxPBVgOr1/8FIVP3FtnozC3YekYyCRJFCIpRqNJ6lxh4qqiVUNxJ+pvwO\n",
              "w3X7ZMX99LfC3MYLesKpZCx/40uoTFsuvNQNB2p39U+/mv9CGfxCkCvakMvHI7+97DHgWC5mRd+9\n",
              "jSpCNw/yB8cucxCkRKPfMarLjk+Czv0YLJbyZamYCwLgHIQ/H3+I0QcbpDPja9+oysVcxZ0AeyS8\n",
              "D9xrHrSV9zEGE5ACLandait2K9a498QmBV0nYGSZPyo2tcugsdOOAJVxt9cm+v8JBkqWUAxfyDFP\n",
              "65qckGDR5umOPnJCNN0rD2U4QNUjrRQt5skuY3+nnX9JLXQn+ucE4kYGKKYv3iJtq/Ba4ai+Ki4+\n",
              "JRO1SAkO5ZLzr9uW8xEV+tTXFfl4Zj8L4pX7IHeEmRu07w6k/QB12m3Ig+nXOnpoI7v2EYXohT4n\n",
              "9SpQtWT7UlGzzsTi9pP06S4khLNRgStUlj3x+oGCD30v6ygo2Kdnp7qsm7YDu/43CGJeextAppGA\n",
              "7uf315aT423E1DNpJka5GUbQD1hbCeqG4ZDZ9nQGxiiDPi6xh8V1QyNRhXqKc3wGwVR3VCRMgsM5\n",
              "wqGuwEpzAnkcej7TjDM4ar0dnRaOZh5eGqv7hj7MKam9aivlCL6RNTLk0Rrd3LoyUMZ37FMUA4Yh\n",
              "NmcR+hLr0wDb3heg6TSuKuqQGkYEst1uK5OwXmt6HTNFSbh4RbxBElnCbARluChx1zpJC+uGnLGo\n",
              "vT4olVrcVjfHlEKf6FQLEQLmLDvfmzf2mTkAGQjIbd+wZWyEEgHy70jzy/uCwrPPztKFxmVSZ3Dd\n",
              "hNfSZJhS6lqzLNikWnOxerQEUQ7Bt5Fm80LsNeAY+axL1U2PIFt7H5VaGBUvlFGQoY8W1bsgYMh5\n",
              "JlPdT00wURWcEz5gsrjrktgBvTxmLJiT06FO2uUza+hxn7ClP1WiIOrJBgTNOfMp4BMbRtdCtQ8L\n",
              "+q6gtBVSVg8ScyAdF96tXiFhhiGxwN2jvk5MBwqKn1WE5rwRncM054PKR7XPC28xtdHICq1DW1GP\n",
              "LpvdXIzOhZqBl7OtAyLSZJIvsGuxizQPCFy3TfVpAMll9Oah65zkloN6ZQuGXJU1+rWSB5093I5b\n",
              "lagsJ4EdqiRdgO35mMe+DAX2Yt8SGaktpA3foYrBdt66jAG1JeqbnOohyukOXmY6i5Nj1vP+Urte\n",
              "fx0Y14s9WL5PN+2vqVLO7aPkzANgb0RHSvErFgAu+AE2GMO4HQWbQO2k8qi6+ijcr2bj1njTUNJc\n",
              "evVYCZCly8rfmnrCwcyhnLanJ+7BfVMpAgcHl5HoNtFxO64ZxxxQhhwddWPB6KQhzNWScMHdd52k\n",
              "OUBQY+R7UzP5Lneqq1Xcj1mHk6/Gx9SJitOLjoOfQI31JRoVIqVckNWUISXBaHr5W4amvU+Ey94a\n",
              "qSIUK0VYmTwnYkIrKg0THL/+8Ik/AboRqVNH5gnPICrFQWQ5YqMeZkZVthR9INsoneOMXjbl+bjF\n",
              "k8hhV3R+HJDfuUzgchFjZ8BqChHiOzNyH7fsSWCjGH+YLXSXlvjyT42vXskeTGhNiRhSybUKbrOD\n",
              "2/FKUIOCYYbfp68l5egHHGJ95uruq9ITkRYITnwp06lbbvTlNe8CUgo6d9OY+BThJam+cHMo8r5o\n",
              "DZFhv+EkuTnYWYFK++RPlrwd4eiRjIDL556Oa/DMkJe/PvNZNYi5bbG8G4R36Cu1kWxFVY/vBu4r\n",
              "HPwYVOp81GD664K7v5AfC9bOaDFGt57MwRdkXIX6FYH3XuvMooIgu+sOg8GlOESoKvUeQVUzuXMf\n",
              "XTnv1c/DU7XuadSDVN47Whyac94wFV6nWGk5rCvwAga8CbEbDzffkkkXEWQOSMP4dX2dmGqFPFgW\n",
              "ejsuT1M5403UGmnLg0VUf/UZkSeVX6OQJkXFyPYK4/q+KZx9NW9ZJ98/+HgkouPCmTof49EAAAxw\n",
              "QZpEPCGTKYQ///6plgBXfhXFi7NtxLUoU+1OcExASWNQ+8jkDpg7DE4FSm+lAmGghfqDqUpkB3n8\n",
              "M56acnYBYtLmXudx6j83C5ARdDtwwt/RoFP0NpsFmhXlM/g3tQ+yYX8cvn2LStE5kjPqTmQ80K6y\n",
              "Kvaqpi+uj5xDEBawURSZAEl7RJeFX/Cv/dGqtjUDBLWS+r+pArVg1hBqtKmmSbvLiFI4AHNO0vVC\n",
              "81eqydWfEnpyC3kOngBBySQGxODJZnfI2QW1oiRREjq2V9xigDuX6VFd+OM2x2Jx8xWjmyx4t0fh\n",
              "31mEoZ5Ek3nWBeWyaZrrQU46PInGXKGJgTGJOTxcllI5uOXv8o1+yUti/Bqnp5y5RfqdWSsebviv\n",
              "H5G1HF54xnoOrFlL4yekxwNGxOB7vZxvEO81Xwd5qCNlg0R3LYNbWA6m7IWOmnkB49Wzlwl+sxK6\n",
              "ci+dl+XdSf7Nzc4p2JKebS+vf9p1sriHGieTbBcYZ7D6AkpEEMt0xIxFKEnV90B02TCajJ7M2NX2\n",
              "lFt9as7OF+GHlJw/z2kDFz4T3qrIeGYVqo9HkXFl1eG3ZsZrzNgJ7XdVJIm3T5FAfDIb+sKsK2Cn\n",
              "DFqxO0CMZhLd62O5XEgKfnF85waSKH3DCp9maDjh2rfBJVgzS3KbUarIheXTwnmXNBokBrloFBny\n",
              "oebT24uz0+nlMpl4H3vgldNbC9Amw6tj99yLGHthF+PEehiu6eYvsw3xdx0isQ8K/GWnLmBA7Gt8\n",
              "Oh/Agr9IGaiJTbG3au+c9UEF6n8DGvZWjWrEE6cA2b+Vg0/tSl4axADPhXeUVovw+W0eGlsfbB3t\n",
              "eioW2+xYn5epUf4hrgmp9TPcVJrqF91toC9zOlMnjl+uLUSTfOEsabarWVL+ZDsgj9uhFMdAb7LU\n",
              "ZaXAsjXzr4EFUSLE5Rg5hAtOQSdf4bv/uu0xB32RkaOPJZ+fDAzmyagAyKlijEvVpEOvzdsqaYDd\n",
              "ItH8o0qZOMOHpAQyjjyY6rKjfl35hlU6TlIQu1FqNOJjfZt+sJtVHwnx+EdNko8LJOqH7KwlVUfN\n",
              "Dwf9mjp/4Uc8UIR2t+0UJEQWPnyKk7FxHPOYPURuAArjEnfZc2njGtvkzvfbrpDwoULA7Qsg3EMd\n",
              "GHJLb4NzO0n5CuUKcPu0Jua3jGebsBIdSdXj35Uftm+GkqDBD29ZQ1pXicNKs14KYS0ytQs5aFd6\n",
              "AVG4iIkwQR8+eIOEZLxwngru6jMhRFVmSrrn1/LJAjiKJXdhx90TtjvCX2Xtl+bJZQLgGtw0OBGt\n",
              "MXOQXH7rDXKcsstAB8cd9CZZH/UEEOWqJDE6sIM6/VJ/l27xA39TxfHwe8CGAg+mlUptM7SmI/MT\n",
              "wSN+PNu9ilIW6W5qOvyDe8iPQrEfSX/5aqKGhspP3FCvVeKPsddJWM0DXgxlfZK9Flyeetc7iS8y\n",
              "/Ja2q4F98+CCVTE0hEp573CuzFPHuiBgv9HCQG5U4mexkcHpF509pdSL65z+39t7D38Lxw2CWKSj\n",
              "2x/0VMtwKHf6TSYKqNPpYwxb7XnVYhw1pARyu8P+QX4XnHwb0rdFcsT7U1OLLVFTvRIbWW0vgFsw\n",
              "lIgNxhcWXsbX6lWZ5N61slH6Bx71gS8W6X07N8Up59pHqUSeGDD14IQb7rEEJTgUHzm8bTbKUF+h\n",
              "F/5JlI9HnsnrR3qs/bsb2pX9Ca81HocsjAcVlkCZyKyAAD9JASSUssgnXxS/QjINExtaX3RApzAf\n",
              "m40fGA6+LlfTd17uZNH9xImtYjcgZDEQjggnvU6Lb2sfJXxhSi2k5yMsRU44+zf5HvopFE6dl1Ax\n",
              "Cjgi1kJ2OsgepnzJ6xpllbC6+cTYZ59VQl8Y6zePJBQ+mk79PCvM0XfAXYDKq3W6XgDlFPJ2lepy\n",
              "TdeDqX6O9SbPp80mVjEsx/WH1lWstvd1tteDOQjP2GG/DS/vq5xpNNgnczbeQeKvN1Vh2gkFRgCy\n",
              "thS69zvP/E3X5Ws7iQFKRoIYopJ95sB5jJwpZn7J8WWgLZOPiOiMJayXLMMzGc6RNLss56cEKiMj\n",
              "jKm8fa4Zq9HuZFdLzu2KSmHKPDVMik8mFqggkeIOj7FAV3gvpSsB1YjOQWo2iER27m5aNzQrPUyA\n",
              "m1UP/aiBgtUT+noqRDkIlZbrigiM4BYciKMuplQw3TlS1rLpwF6oR/rF95CLkjSp7jX1WCJGzVD8\n",
              "JOrDlY/0Le1Wrdb4AsItWu47UmeKdxQCMOz4wsuCuoCzLEKfjt8xLe+lIJ6jKOAgAG1FPjItbtX1\n",
              "Z02hXZaJCzXXZb0ENoIjCIed62fle7sf5YGMY47D4/bU0QrOW8eAJRtxN79lsHdsv2RBJoPPCX9t\n",
              "u64bhHa1WHabJVQSxa0R45siMQ0RiKszUJHYAunn5T9qL6HZ2XDjkr4ILz8ZfO/BEn4x/6m4e7Gf\n",
              "Yl3W8gct9b2WmHT1MqSb3gC+Sc79+7j3WCyULbV0hRLgLZN/j2/N101f+s16yuw+RnvwJKxLEnwx\n",
              "q7sETd4QEvLm9/gRvcDGgf7G2T+Nbf8JHfPyOr1EeyWpbc9qS/1Kxv0VWE6TvfZ8UsaNqZhyh+hX\n",
              "uAuy1ArPvNPpf9qEgrdB98Du97Jr1rqwR4/qWbT8tKYgznVMO1i0+Z68t10zRJFvqnpPa3Zs8iuR\n",
              "p31WU/cBWQlTn3FTuCE/EY+vkW740u6l4qrDoQKloaVIn+dtr+z1148cL/pv+34ugqV/EIugMRJz\n",
              "SAk8XkN5QGV4hIucPubG4P8qcVrUqdO3qDrNCmcGT6GWLHAw3pAUVWnCwKSW/z5sQJVX8F/6dPQR\n",
              "+OkCQuntObaYQ2WIuqZB3+FiPRcQIQUSH5k26AJZilQeDorVxtrhvWZrRo2xXeJGcv1OJTOih6EZ\n",
              "tiRaA5Ges/usgAbkt9aZiC6y9AU7ZUUMMME2C6UWIbKusOtjKAVriqvXpXoZ/xR0k4Bf3hpo0nQ6\n",
              "fRMrsOkEn+gELbVqt/LXL/XX+o+rBE9jMuNOlzdFbLOulFUPnw/fclZq54dOSUItJcnWA+T5LFAp\n",
              "/Gu+m/zOUEPYFtVxh6o272S4R+8CHgx7XF7rDT/UI2K2XpSUluyEVo8uLr8sWcXAkdb9Qi/M6X7O\n",
              "KcnmE1GjftvGSKD6hUyhXvq/pXWbm9berSbeKPRis19k6MYraaJyfwngx6CE+yifez+dTt1bNM4k\n",
              "NRRxjsR7X1t4oy5mJd49rPOsVdDPedTFvhhSU51WdARPBhr70S5p1Ub4ccf07skkQDN+/ZagMgs1\n",
              "ysUx9WHI8DyPBHf9/gsVNVV36lz0AFTQh1ctwMNd0zNEF/PaeQe43R1nSloAFTPUYfTlx+3insuC\n",
              "8ed5+nJnPT80Tv/pmnHlp2HAbwJBrQlS5meIZgtwEsawNZUDQ6jGKG9nQ4llRJpvt94FnGoFi9Db\n",
              "z6Sk9RGTd16AZzvxmiOqjUBU3vjmau2Y5gm2/hbXRIKkxhlD1DmTftLdJ7AzykCnJvBFQKHhkooq\n",
              "z2o80xYJGMJBkB+oXoP+cYBFZ7wlEqZrOFdcvSMcLfz113sfl6g9q+vX15eePPY/KJhUpKQ/aCM5\n",
              "QvTRs0DOWNi4BEXki14f99t2hU1ISL+5MmTNKIjWyA4B942vpwqiFdKkRkk/lPUxldvT5B1eEo7e\n",
              "NRcglqGijqGm7jvfoAsaHts5SZAfliwBDxGTFoX0uo2DnEgXuZkIySha77YLLZe1c07/G69psnhe\n",
              "FeKdOFmFuxgGCJwBorVopu+Atu76jWHuzuTuZTHVr91wal7yPsnVrevzYjZhENj1YZY/xjzJ2PQ2\n",
              "PyQjFMM454CzDUk8EXq7B50lvPQeVYKEhoGdFA6lM6E9HfxD2YseYoc5Fv+DJiaRLaf2K+qZjIsT\n",
              "OXncNgHpNT4JU9ds08yfF/MEosKl/3ZO1dHLGGp5KOJ8gjfe3MS6OQ7cEa2uYES6OFqi/0Xfhy2j\n",
              "rnrIhE5C02Or9+FPmXOFEaKoBsuWXMFVJ8WV/nGwFJowkJ+7WpR+66IZjrp4RyMyNJ7NdqVetfCf\n",
              "oZzjuI3kOQsv6Vq+Y6Ak9B6zWOyvafQ2y/c9GkNok+JgTix2XRo8jPYYvtlt7jZ2uJbPj21Hlvu2\n",
              "8ezqp1kFKYdgywYsvYnUzAD3xSR7tS+jc59hvO9ZhHBCuSBOThJcSYD0cpbCr9b4TOo636mX9Wfq\n",
              "9wQBhaEqAazhilHYTdTkpwJ4HcAhDW2jcJ5xeenF3yuqUKz27wgSJCG1FNmQ5vgBrAAAB2IBnmNq\n",
              "Q38APL3BB3dcSAC+vgon4/6dKE+eR5lgEG/nAcTUyyJXoxGkwBvk2gHgKDNEQQCnwZ9bih2DnOMr\n",
              "SJeQwHd6bYNCvWFouhXeWK3ml+yUPFjfUcN+hV+8dHVUBZ6UwZdqhiQBNXYGh10C1kGEhPNrYpf9\n",
              "Wof/LlTyKurRrMJ3basFDxPya0W5uZg/1+66Czs3GoZ3mbS5LveCRmpnOm4OJmQw4THewGD/k2N6\n",
              "qpwd6LCARVHbLgddVhwVaUu9cxX1teoNgWk4qeDPadeb5uyxwwVnRv831nOot6Oorvc4H8mwxcoQ\n",
              "wuVy/Xe8DqypDbUS9g7JkS0s5yrbpqFyRo9nSQx7idz0f6JDYz6wkuIQigKwQaIziMaw1fY+JU0n\n",
              "Z3kbYucxG0TGJgfS5Uu8YQPStL6j42wjR8EKHZj6du7SkoL1YORP61ajtnSvZlxJUJIxqjcjvmIp\n",
              "7qj8QbrXIIHF2kp0dMZZ1dBVCRhkCZkKc8S0HmNwonaCfbX21IScHJd23lu/z4SKAcLyCmqQYeF1\n",
              "40ziGDDMEC11VYhR2uRxCsjWV8yFrxOkiV1IQpICaKivSt35P9SxWgAmmLtI7jlLh6lsBn5z2ugQ\n",
              "j4Wpfwry2uyPaMC9ROhZZBqpHiw/xbNvlvJgEmU29Fi+8mxhcLPm+xGhcUJxCqRoNgs+NJlYIq50\n",
              "AwfR5JEkw7Hu4CZGKDFffg5Gwr1aKfq1eHDZUYbl+3T8cCJbTjBthHsS4gn/UNeBUVx2CqkVreMe\n",
              "mQYU6aDZQb+iLdXzYI+qMz7LO0hEmcjtMhvZCIsI/nBxVAkCufW0VmbATm6tr+mQbOLu2uHotwTF\n",
              "zgKtzr7DvuofVbF5B0xASsrFpoZTYJH++xSyH8RO+lkfi6iKBPk6VLICNABCrNK+BJPg4W80loEq\n",
              "SDBRfVoy7Lhlh4CkxQl4kemI7o1nysQj9Q1zgpbDUPusNSGlyvHBlDkrDYqk/w1DdV7P1cMqwRw4\n",
              "1YwIRkPfzIR2xX551SoB1cNhOg14ohj3iJSYzNBBWNWPX/zJAsCFcyis3xqOfXPisO0SNWBpB4oN\n",
              "UBI7DDveGJXMGybapAmJE+f8/DIh1zDL3dBdUJBWjChQNP+/n+cOAd7mFafE7EdIs/cR2nYhmvHD\n",
              "UZyTsqPtwdlxlJAOKefFElN6rRbroosbCoZjQ2lsNI5hK3cmv/CK24dNYiAx4FO6w3o05grrYnJz\n",
              "7+wKs+pRDy2e9K853bnASw68erQ/hT/GcMkwHWLcgmnuZYkjH7hkMRFfiHTvBExFHreu9YkDMzuq\n",
              "FEz9o8XlB0Oxm/jfaxXtZC+LfQDYbRSJPqCsLuYaXtPCFBFodh032EzJNbC3NqwOe+0q0qiMAT2u\n",
              "g/sNCwezNgrUV1tfyKEcWg6ba9Yn+bA81nkJBHj4huobllvscE7jxjnJ0BXznUtcnQKcAOXKr/27\n",
              "x4AxNcG/5vHpaYQ/vBP2ql2aU9Q8awEh1gz3eT0+FfpLhxA1WzA6ZSuI+IgSV9tF5wlXVHu5O/EM\n",
              "XLtjFte47ES0qmGnIhbZcGYj3YTI8Jv5cJd+9Y9LGwxHDTrF0ECbFfSkDK1RJSAUc6Oz5IoMsEjX\n",
              "WB0e2zOfXC6JgfCmZnIbfHDavhuMNkGVSa70Jb8SzDuczkte7GJMnyCdcI8te0uuVLPKagrR4ZVN\n",
              "sc0JcMd27XjkNhLxWAM7bjZMrnZ8ReL9kou+PlRnXDBnHHf9Tc7pynC0kAIjUD/7DMuxA/GThjG3\n",
              "aGdUgp5sFXfPwyHt1kYgVr4KB2cBuPkd5/YQv5aOV3BHgbTpXSIOY0NGw8CXl60uMQhSOQS/Cgni\n",
              "h9azLD8Grfa6J+voQX1zLaLBv5go//6LGfja0otrD+Ur4CadlKKfPzTBp/Agi5ZOKk1Qe8Qtd1Ws\n",
              "Wxr//nCxuUs62TFGTYQDHBtw0x/thxQZ1w04qROSjt8x10ve4St9r8niK5hzDdwConMeeYp9YYTP\n",
              "PVEPbkGSHT3YgnJRHlkCvI3BuPTM3PGQKHSrO9xJEYaYok/yAeV/b9VyawlGqrh1kVJwshBXpsIg\n",
              "juXAqIANAFEXuzfvuKjpU6n9Rp6eEoMd4sVJqGZKtCkoyRW9CXgfvSno8EIsM+4HeqZfuyn7MbAJ\n",
              "dSbTJgIKMI/KWw4ueg4KIWZ03LrYlR+oYOyQa0BOYPrrcvqTJKw0AB4wDoC00tjIB1r26yvi0mue\n",
              "je0C2id30Gr5ME/ggzClrTUkx4S4Nw67dWHDtItKv8h5LCJFVpei23AiEBEZmIksxqz9FJPbKmbl\n",
              "IB+l9POYKsPQ9LUvbDyJPHMcD/05AhZPLBi7CdxvqDKV6kYi6hXN3GLIia21+l+cdAbMP3IQPnrr\n",
              "ZrtPWFLa6ktxN9CrsT2hESpNiZqDIOw0aDEtgKm2BtIr+jgAjghYI7+Iz4RSWWMQ/HJUvxH0+msK\n",
              "Qftp7p9DFG/ksyGmbMNUjv8h6DU+ca+TxnMrb2Uxttc3tFb0FF4dmX40StZDOJT0kTacWYeayM6k\n",
              "cMbAw8EAAAwDQZpnSeEPJlMCG//+p4QARUfc9mupfBLIep4AL5V5mgcv3QvUWlDogYW7Ye578uJj\n",
              "kzXah7kHxi4MNwFL/9LBJIQLyIKTmGgpGbIMuRnnW8/B4Eme0his5yDItXtGQz3AiobLKDwUzyQz\n",
              "dXz4wqO0CJIDP1VEtfZk0EyBD5obmCuzrMYtb6DlJ2NQMC6S9tsZT9whaV5fd4Jor8mwIUEjS8Nk\n",
              "9WA9oSVia09G5YW+7VqINehgQxtN6uZ+AFo+TTvg+szbh1/D6ytFVspJcXXI+QLuqovayUDtsuxu\n",
              "I88A9KCcSI+XdCjiLOXHMQdtLPQ2Zb2lhc0JtOCIiYDJmzCDL7USsfHlugKDTjVs+h/3iEwWvF7C\n",
              "7Vp2f9/gfcKbNe4bxgfioC8jEjXcpmiHv3b5pT/GfRSTnFm04/kBoY+qgtYo7XUO859dvCNSSGPN\n",
              "7P7F+66sBVTWuZxqLJMvQZFxwZdejrNtR5GXYNRH5B0tBNTOkVc18Cd2Zk+0SLe9ueTP7oklFxAt\n",
              "EnbwMGKN+EURyckfFyho1o30QTNV+2BRgPwekuhd2xJ+iFc/99McIFRjI/SiaXhw6uWW7aSpnLey\n",
              "cdTEKMz316jnv+IuNEVgWio2mPyvVVO4LrsjOnhsAbu7+mWVzNvOFrXSFHpYjsFGpoGWStAo/MYu\n",
              "I3B1miQjbqaVxgi7KYxL9PNskx+iOFRijqxWwNzLLKOlkVzDk4yBTPpIG/LP4RyGI1/iLlVfQZgM\n",
              "deQpo2vf8gdQk7dFMJkwLuWT0OCryAXVAmFdtPk0P7u7vCxNwh5h6OaH7MLggxS6RZ51iI927dpr\n",
              "sJyz2xFAwsuTVBvZ7nNY86ufPTXs/9jzUR9nDiN7CwSLI1zzzV0OliiZ/bkYmrV5tq1oTqhhX9ar\n",
              "AgMnln4LW02wGYPHWm2kEp5hNQFfKs4P8P1YHX1BV38XKSSwDZR7kWJWd4a/P3a3k5pFiXxAQK9g\n",
              "3QLaXPMi/oQOP2wtx8EpbhOExd2Y1HqA2dAn1ulT9pTWs9bB+zMdqqWxS/qHIxxaTZEQc5I0vi6e\n",
              "KHcf3rf2ir8PPdhFw1Ct832eYh6eOAMyzwUC9arK4X9j3ZZrU4Cj1US+uEZ2srW4ZVas12qlPhM4\n",
              "haT0LjWAKnWXBjfraa4iXsnKvM5OHFqhrNjKoSIOH15pz3M/O6jJy4pm+i8/oGkURqe9imdY3J1f\n",
              "HZptoVDqx1gqFGLpYMgEOHzyD3FzgLoiryPWB9QKggeo4QHhGJHijXcyT13hPvuegT+n+D3VfBSd\n",
              "AQqUSVYl+cpMvVwrAwe3QWYu2+/ltT1n1LXBE8n2xQoIqyqpY86ColES5QhPsdx+qS5eWAvlJzBv\n",
              "Y/XWrARI0COYZMKErFPfijphgvTWwLoMP7rIILwgi21V9nZD2h+PfeD2jyC3WBMEyu6uKRGt4X+4\n",
              "e4AQ1a+Npt9YrZUOx8JfTENpcXhT6seYZNil1sfbSlwCFGmN3QtRlzUUTbdej5M0hpWcZ9wTAs0C\n",
              "Ef1x0lC1alWTNZ7o2CMmKXbFgGrYnQViI36xcr8RN90MN1x4jw7auK7g1DP8670i29mbHmhX9PbD\n",
              "TSrEHvRFaSv2xfsv2EkCb/56bwOnQYQ9gT/BvsuwPK4W/EDsZSD8BOfNeSk/Ru6SR6A1fnHi+5oV\n",
              "SvXDp3vfXoWF0NwYHamtzwdbICtF05BfyJozTSJRgEx5vWIaABPxdaiq7Zcrv7bJgMTJwnrRugCg\n",
              "z59Uu10kD9AFrIgBK102GHMGjWZn8QiSR4r6yBwZS3ts6VNc5l8krk5sLZA6LZz16T5ZGLUTLXem\n",
              "uiqc8t1pjouYdfi36xFr97sIl6QM9J9Z2URfssqcCY6b8nIrTLUlZbOOc60Dq4utQCG/X+n0i1gB\n",
              "DfkcygIlhU0qt+gDtJ75xsxbaIEhM8rEGnLJd8p58wvoxSigdByyA7c291B5U7T70W7h/5pHdROn\n",
              "rTA21E80CtXpVCpOX8u0Q/UtBDyfdVlsBgMSszm7C/+nLUxwbePWe7bnl+HGcVfbjCaum1rpCml9\n",
              "UZDbgiHGNwRAKH5IAhmalgSxa4gw5uhwcbbHjz4a4mKaiEOdPqIPKhA4a7iySlTKypSI736pGqSM\n",
              "KQ81JX/EiVUhUYLuEEMIKVXO0V3e1mK2IxwjWjjBFA43RLCCKEkPbXYPuqwVthnE91NH+n9TWPhp\n",
              "AW50tyFll/uxEDtmbi+1LiU9w0ZbpMpEeAu2YN1I8y1MJmtGTRuaJI8Krdb/ywatCylkNAKorqgz\n",
              "oJS15D0R7wMPYYPFEJDE82/ga3HTLoPEDNiM9THU1ERirZhWtmH9bnwaynJkYUZxRgxg5Eu71BqT\n",
              "P+JNQVsM6rQs9uBP2MYzTge21FSWlaWvAtY6+J7OG4RwTloivfFWDeV9udGsqIkvoTewEa6mFvN+\n",
              "1mvN3DhNvTb0xQWrKifV1PdYIGhD2pvL6kF3FS3XbU3WCIGTHNGvWzT825UAom1fLyvdANqV0xZa\n",
              "iB2b8ZietfbFOtRrYn4ptKFCB7yVToxUoSvI7YsAcdJqCWGHPdxUoJyo8MJIRm1SZ8vVK3TBjWrn\n",
              "FLLy63XFvf/QdGwlPltaIVKsJGeMFOwyv1f1UeTwLhOqcKBeM6GLp1yvAGRKEpm/FFyTzsCgqkci\n",
              "TicW0M1nLUngTfgmucOUfMTT+cYcydUPvfoIX7B224pMcecgfYCb6v4yBUiwncTNbLgqBzLxUGcA\n",
              "0dtz7Y6v5nXe2gDfXjkAgfE4jYDKBdwTs7cyR+Dx5mI2JK6BN+61lRaRMCb0Eyq98QbQSFZSgYaQ\n",
              "L1H5LXJUPmCTz+/Qq3WFHukJ7eybBDHIaQNKtVx/A3E9cW/+i6mHXsA9SuMzmGY3kj4KshVp+zaa\n",
              "dCuiDP5IluMWUctA6gj2NFPHUufyWowU0urKL38MCM+R8KeNVu59W750GqIQdqSXSQJrC/gWot87\n",
              "MnXw0/bSBELpQ6+KR6hMImBgKPunuRRS4YR2ZBEOc75J9jJVQWDDX9NnV9F2/L7fPaRC96BDnerH\n",
              "K8dbzXfGUc+ICghFZ/uetfPaQl+RrlZJNGAEMZ2UJS1E6fcPXVAv8Z/ZkIcn54+AuB4JvxED1M0a\n",
              "blgOM027wfGD6XJBhYCZyh6VQYv0ppCVBD3p3OXOyfd9YVc4HOW2x60ivZWDX6AVj1Q3WgHdEoEc\n",
              "7/WjU/IaHnVvUsCnI6vaOgy00JokhTAc/s+/X+zegKK3CMDeUfGweyKZfkkrWBT1E4DaJmoS1Jii\n",
              "5PObCKgjiBixn5l1T4kXgrE34E2kqAr9/jv1NjAZjlcSisBt+FViMopqNUwQOD7rApPewvTEXVfE\n",
              "u4Wi5AlhWiBrhIF3IAg4yUv913hI6ZKWX2mpv9FeiiopE5nBA1q5WTNJgUNzVAaM9HLgH+6UQdOv\n",
              "brX/9CgCIquocF5Fee0wZAOFMTKKffqqxCazC79a+mZZhswKOYrjv+FeczETGmmhTXAWwELpA05i\n",
              "nzMP6jumAy2LG6DxXF+A3YCqegdBEDPYxdPTTaNkvDdJ5TTb07C0mNpRMFrRxMCe0FFwlPMmdDSG\n",
              "rCV+VeCcektr8HM4OBqFNHzYx3DinRA7332HMzc7mAN8dGJJ2SqbPJz9YCCV2ZSonvsRBLav3Su5\n",
              "WtgQ8Hp0gqEvZXkDkzF4NGw/KLUSVHuzhUSQYQExu3p2j61qzGBMd39KkNoEVwu808fT4F31nEvM\n",
              "jSGN2lRZCVSItLM/mK3VdLPaXHFd/dqjJaDyp/1jiz9IRA+b4z3rjvcCRDoFR9G8g8GAKtvTBuN6\n",
              "rZ+zclYt5c0m2fjGGw9pEIL0sQscN03/9w2RZR6pWunsQKFvyIaQO4B/7gzUABaerl8XVAy+PInI\n",
              "GQZdVelGtdLk6TlL+QOq3giP7IoM1HeuV9vSuSG8QKJaXr+gohhjuIHIuwVTw92Hbj90/JQ07tb0\n",
              "NHXUT49XMy1ngTRNn7Gunx4q1V9G4HHA4gxGhgP114bm+SnVvIf3X25FoK0Wj8Q8Mkr2aXvVWnAH\n",
              "h+YVfDLknCxtRdHN1AdqmuVVLvQ1vXn9XhrTD8HG3EXalff0emMUlZIHx231wZhZxN0LrLg0Xr6n\n",
              "x6x98peBAAAOukGehUURPDf/ABh6Uzg//ohwAE3wRTUwgGd6SyGTHKGuly7jL7NCIuc3ia9qMrNS\n",
              "RPnu4FKbvCsfbNVSVjyAL0jmo2ISrWKG8y4r2gM5paB96vSav+y8fBqcnrhA0EqQH6XIKdHpsH1Q\n",
              "NpM/22H/dRcI/AFDQ3JCjmNMhErJu3GHtgxmDUOrqELhvpGCoST0+xXDhA3Q5QNwgsYe1OohTSoY\n",
              "0Q/JoxGDaXr0N/DcJOmylYZuf0CnOV4D54aVkBrCcH8Vdf4Mgsnz3vDDHYcyKochr0btpwulFgSx\n",
              "SR27CwprHTk4GpbIA1/6W1tBBT9mnfWwIMGYC+BZ6IoYyWi7+90SFRhSlGiUvZnUuZRxan56nlEj\n",
              "I1wR4eZmCmOzvkSSJxffX1S9LYTFMjL3h7gXcD9PS7P5Zyfh3tyq7HuyQBy8zJOCxRBHiCJZrXDh\n",
              "qwAHA9P/CAf/xe88ysTD6YdoNaXXzDvuYf/1m9L3pI+PIY4j+NZv3IAevEuvRGMkorHNTrGS26Ak\n",
              "yP9XzsiB8gEqvUfvxqKhvqkhu9kH32y+P67szju3ZD9acAirf21fveT+MoCOqazsN29lCxXmoG24\n",
              "1eml12c6VEIDOIHfewkAI1Kc4UResefRpRXwKZ8IW5DmrcvwW7w/+DbCIBhEhWjit+9McxX0yvHz\n",
              "1aEmG7bXMf63f1akoVdgJNaWm0RvhqqWv8rdc36gt6ZR1oEI734Z/5TscgdlvnYzY+rZ1pGtbosR\n",
              "w8bbZpHIaCaQM5vJ3Wal3k7xWOyjoS4/iaXR9HauyKqp/oyRJAUThGeDkZiknDm5+fHmaas4QDh6\n",
              "1ts/3h7mvVzJKT6du2oQKVJarW4r8g+DNPJF5qrD4R84D5hcHklhmRaGYR4pHDnNWab/QglQZAnw\n",
              "43D1Czqfly/jBhb/gJfjXLHio3KMdTu2vVxxCpa9ZBed4ow2kTP7N0RdIvQyJU0TqjcZZ10QciQB\n",
              "q8m5AaNYggP0wAeX9vJ0h58C7t3VDVfurtNjnYgL9tB9YYe+ej+4mVL7rWoogbx7bUJlmXo6Q9qj\n",
              "jV9b1LzsnHYuMWCHlwGs5N/XmhsNQ8UexcAwKnhk5068xx2tKD058JOSkFtCh5DMSYwo1yZVBb09\n",
              "R+RKG9ptunDvVSkwjDCNWd788jRsuREsLfGXsZ9h2X5ZCIGZR/D7UH46+9sVkJ5fntcqwm7IlrES\n",
              "cIhJEi7bfkbuyMIw/4Ky3MnA7qxUHscl1Waul26SOZD5A5hi9qnsjkhXg4pSqIHrbZLd/l6nypr5\n",
              "JLYebqTeExSUWV353EGPz9bzWn0vOWwK51KYIf+iAVzppMl7r7y5kL8SUA1cg1aOVjB0733YUV7v\n",
              "Ryrktdt6Xg55/aWczKc6zqeVtXOn2fzjTVyE4wGSt1w/tYiNtXkfdqFfeuDdSRsQEicUpAjGlRLE\n",
              "zIEntOIfbJn0OYYarDW/59lpPnYeKbNxAlBVsLmDxSHk1Oyos1RnnkcsM8oFaAWfvknT1XoVZX5x\n",
              "7ClE3e09c8/QP1LBbPlY6FHRBsmO83IW8JIq2RLc19403s5bnKeN7O3ZRDmsY0Xg7f9N5ssJVfWK\n",
              "JFTGhh5pM1d23pjnOvP8EePINqx+cXYAMl2qBptSecRVrLWDgDDkBZkKtn2QRCCey4w5kmsdbjX9\n",
              "atzvEBBYO3gvdlyaeI8XF9IU6YfExIwYMa9nO73DiMU1JUheNW2MvTzPaCEmpVz2niqiQjaX/J6V\n",
              "XZMZZ/Z+PSxjObeevQFESbMpLWTQdSWVbabEs7mGBFClD3YRj1Ux2R5JwxrNQXlXtcZuoZ894PyF\n",
              "fhEHNhlP3PqP6cLas6ue/JbdLgrwjrUnEqXXuHQcteyyVLOaDo5nJGMtV+ov9V1D/g+VF0LvS+Rz\n",
              "cWY7sStO5QHt+V3Mw7iuTXFPG8T0td0thAz+1oY6+rWVzhClWhQPM0T6WYjGyenEZOwcPEeu9A/7\n",
              "93zTswpGjzE4EljsOc5aqPg9QpSbh0TemMpAGA5uNRkkzhQJfRDHUzLElbZCJTt4bAOGpJAg55MV\n",
              "VcZ1/oR8PdtYZPs4HEKfKFl3CUnF+Asf/LReVtI9azefj2WyM3YTtC9ZwGCkQ1dnawl0R7cnTNdE\n",
              "HMzpRNl/7Y/1Ah2p03EEJOmbfN4PO2ZClkZMvVdZddYuL8s8mS5ZA2duZEbXA4vpXVJnO8sUhed1\n",
              "Ps+NJuoH621tvgjyjOuP3RVTkylZO2dFS7P5kBlN94Obwd/o9WMgyv6xUrY8Y9ZmZ+cjGf77V7lN\n",
              "weeRw0NG7Q4Njmz3cdf8lwNqX7tcvnwFri9N9/MHjRmhMKc0U6Ovsxv2yriwhYUTb0h3c6QfGkyh\n",
              "zp7QD2SDmc4HSWfna9aDoiqWiiMigHNlKKSgNqquV0SFblMow94FkpvFGeehN8HIrgXpJK5cr5jJ\n",
              "nOsQasPFEbvuEIzSW1p+2DTtqv1ioaMXJSN5yXfn+VB20OpK74y2JsTWmJ3DEeRgfVcUygOOoJpP\n",
              "M5pUteK8BLL2caCCI5VU48iVLcDbrSN4nV1/ZNV2F1Yl2M7OT/tVdaA0RSqytSSRlsUgOVxrEPfP\n",
              "Yj0YVyPix8MnLmMZtunCYS/oEY45RsVo6QV4yRdgqs1RvSf4QgybaOkeuaxDbze7QWcMGFr+wv0e\n",
              "u1fdcz9YkDENPT+XJlaHTANqKmQflcfFRkhbhwsyKoM+T5K6wcUGid++nsoYCYw0FdvYh2Bj/wyu\n",
              "nDfReb32PN/xP8qnq2grXvPh9xcWOSdc1lR8aZF0sfpFHGEilRWP15NLOI5kr1d4lQddmJKEDulS\n",
              "n1ok754MsE3qqKsQTEcx3RXiGVCT1XVYAmnSOakSN4w3nX2wV+OhqMtu2Rw/D6bTJ68G2PMUf9gF\n",
              "NIHFWrYBY+eVVon/ojhNvd4X4z4EGPsui/oMFD3BYWCwcQYRyyV6zEh4GB40ekKLndkWCm2R6yRU\n",
              "473fEk6kIKrnwezdJChFxZ84pd892wTw9WU5qycCsugABGSyLy+4EWgtqKPsb9TpOb+0PG9YMQWp\n",
              "efGlG7drrsZfJ3Or1OqNj3Qn4tE5puoJn4UntW/etCxVae0xU45HV/BZ/JbyM3rdp9ViyzLm+Bg9\n",
              "XO1m4ogXqZRt6OLoFiL/xya9KmACIAhFdbsjwtJfDbr7KjdGbGlCMleOXeeDStUGEkHkC+lClhvP\n",
              "qXSqN3rLrRZ0JRJNK++OAOCIirjoijFKHzP0nxc2bf8yVfeU68spiWCJZpMxDeeqyu4bsm5BtULE\n",
              "hgDUw15YJ4oWPJpoLuWGzHoz2cPgxugTkyhpOv4kAoHrM/2swlWfZlp1mGb7TrxmDM/gVwl44N0m\n",
              "SSb0IBeVv0Ql62Hp9IDL5fxwJLq8q4r0AeP1fZVCmrxxKZ++RxiLpN2SI60l3HNTlC7SE7JMtrpe\n",
              "7R9r+lf1uFOrmb5NmN3GrC6iF4amO0xtLvq8qsO2HZCOFvY02j+L27DoXwcspeIgZr1IhUudnVmb\n",
              "TBfJjwJxcJwhz5TMySGbP+dk1rPEXjHEvCS7z4NRYbnC45gEFiCc8xYCkVnGL4sLxvP0t8S63orH\n",
              "7rwmtZRABI1BPM/DHAVgLRKVDvrurtfhAyabgERsRfrstsYYIbDTiZMBbhARlT+7DzvdoiDyrIfJ\n",
              "uEmQd/ytLxFZoPD2aP16T8pCd9dIdLw0sqj95b4o6ZGo38Z/axE8Hw9Jc8kjCP5X97M07lL9h4jA\n",
              "ImGH4VMnu/wlt29DOb+8I9V27Z8iVDMNt4yNP3KxUUsIcf2yfQbRei18Ny4PclzbcDOZV5mHGWVB\n",
              "Gji/LMzB55SbfNEfFxw3kCtoMk/nEva68gJi1UQD2ycytMkAt11Wj36dWeQMEn11IlG0ifodGN8H\n",
              "iKFE3UvMNESSjGkhiNC/+PwIYihJEvn6JVrye5JHqK7tobCaRvPsLZJC0Piv6MBJXU00gfIzCqDK\n",
              "8//D0kdGN6VLE0e0r3nLkAlqEqs6JNrVrNkU/2hEenWPGSqmDFDugUWoJHdSuWJ7mFwjuUAAEwOi\n",
              "PZZalkbDpaaVuJkvlwrvQ3Jr8G5DJp8ysF0ugYrMCyTfkLRhmM8nJ4sm/wM6qLiEw8BzqdD3nuCr\n",
              "/g6ihBs06iV/MkPL2RSTIWtPO2yNTe6aiivfGzD5JIHTWLc0p1lxOhAkabnU8csJql1T+thWA3aZ\n",
              "fdspqatB5U2OyU3WIJ3VZgK7U3JUImpK3IMLl2wgsu1f9FE2NqTNVQ/9edU9hYD/8hO9xNERTG3B\n",
              "RSS/LKZBGL0Gb28iTkTmIzUP7q8OiBIbHpKSNTnmkwuca416atqggqNIEpl5hNxN5DG9lnqEkbAv\n",
              "2Rw/61/uc1J/ODP7wn/ZXScYWpzN7AFQtsYwL/B46xYUY4zdfIjZG0KuIisH8HAtdmQooDR39xW+\n",
              "K75qnusDvrkBA3o4aMWa3DZU9XE2/KnJ6IEoMKod+lVsHje4ao45eZwVn/s5ohu0iv75qdXn/Y19\n",
              "tXkh1bpV62KLsJDyrVvutPyNHQeY4OhvLa7ocyvJS6HfAVSYQWse6TnRCjbtz6opSKc+TTqbxUct\n",
              "OdVhqtzLVeP98AoX7nGVqCq649A1ww5zXqboxuktS2+Tkj3KBBBoOQtfW7vQ7hFPDfz1ayAPykSJ\n",
              "GTGcU5OuqXpNPZx9DnDqLprCIt2QQ7bU2L5ZShg6N98kfKJ4v9MeAzlHhcqtFxWm51kS9J01b8OR\n",
              "FTj0YfvK6XI4Y+s29u2H0K4hRks5TKRJIDBl1QzztSWCAqjkhJl1bCfjAFi50O9A+PXfZ1N8j06Y\n",
              "e8WqmCP3bUAw/T6lpvekimHhvGSklskwf3QSMyEFlmBmFwqglVIJ3jPGw3xErakAqcpmItucPJIf\n",
              "2ImW7R/0ftMDAffXau+1QzO42ee1VnuaiYHEs9RMWN2UJNk4C85IlETyVs/dUmvt5wCYoYtWNiya\n",
              "hDeyFvnWLnF2fe7fOmxUPa/Pg/E5lLcafU5n8sEJEqE3S/W53a75mVGfw27TdpKaHiAdUAAmFc85\n",
              "gp6ZJyp0qy7edArkXdc38tWhAAALbgGepmpDfwAZIm16C4ABzpg9iGzHdw1TvKJFp7zGyu4dXrvR\n",
              "XWnMIkJkyWS1/WO69ZXxKL2gqsXsrIhNcaUqroZKJUfIGIlELCcBtLT5mMNfR0cHq51UkNZhLdCt\n",
              "hV7iIhRupdD1zr93NxaK0SH/AbJGXshkObS/lQR9KPPAcxky47csfEHByOMMGMrsdvgq+EESQX/l\n",
              "ic2cVAvhWx5xQe4VXdsodGPISAWLJ8q8ALudOpwebIWRhO22/YiTUhb7CRx3VAz2/3QpGZpfEdzT\n",
              "f/KC1JR+h7/GJay9YYq5CkWRlC3B1dOGAmPZun4OHpfdYtQEqgoKIyv0z7h2Z+n+5oWabcJKfbJ7\n",
              "3Cl+pnqb3N/sB+UlxWhDuvZLv0k0nCh6SGMN74SmqIT98ggNCrlZXMYCBZId7BvgcvAD31YSqc8A\n",
              "Gz8QqEc6nGapx8pQXfunTWMcB2PsaJLzIzjfqJn0nIyacY2dXVpTWn3ZChpcklVSDdwvECB9Y1dq\n",
              "bGt9S5+G72RZJRCBHaAbUZMIfeKpBUuyLV9tXeaVc+oA7+z/m3DYPHp3Hx3pLYV+1m3x22XO68Ec\n",
              "gBjn5WEbb+0w0+p6qHEjIDmFED3FyKAgFdsbaDfmohamrEbUqbWwn1m8+xT+/2dUg/0a5kXQoOJf\n",
              "CQT/z1kpAy2y902PAzxWp/7BvIR0Swh1wecgT3oH0za6J1xi/WzWs8c6e3mW3lNeFavK6Gdm14Ii\n",
              "bZJt592P4AFJke4wj/jvoZUtlC/wC35CbtpBNoJpHPAgeJn5WlyrFsnMcGO2wDgHH+LTPV9QonMw\n",
              "UQUo5N1HoVd6AhJo/10jwMCj1BtOq0Tp3jTO1LZWEbrJaeWYffjxO3gsoMq0O3oFcgEAveLElAWN\n",
              "Z7Gd28rgce6Kh43mnuy4c4uk2qLqE6dTQfS5bvuB2JXYvp4qDIZuqjQ73NKT+PVmVSi4skpCHkCi\n",
              "VwIwe5zlsjQ6tTT1gJySNhWP1ZUiiCpRJrhhdfpTXJLQoyzeoWl1dTjgb5mdT3C8hxXr95ZiADTo\n",
              "1bOGMsVCSq/AX4zQ0TFeBqi/cp4W3T07lTa8SyX7WbHnyk0q37uHS/3ZHQqvZYT7PtnmBcp33b+a\n",
              "jg7H3Rq2rR7CtnQoRBGMS+wu7wrcBJ0RCTO2YfFv4e9GNXs3ajLhKWyDgJHkrIv+bPzJfo45LdIs\n",
              "33jlCv3nDwHg/gnrz0R18/tnvvRFqordczclR7lrIL8HU4ijw8MHMDFrW8oZlmOeVMXpC7CKjqPe\n",
              "qHztPPmAW4pHYHvG6c1YCOXgH/2c1UJSmEAkQemDfpmA42uIWOfMusUGWaSWSKOUpUJQ3+vuVBOd\n",
              "YcHjIgRrmARWDBaBXIYeJ1hiJc6n5xscmBlE9rR1haW2R/YWJ0Od7Zu2AfbC1yGDsX4+zFAz0Whh\n",
              "bdgyZgEeb8W3qYxRUyY/npWvVbbs6z4CJVH9vWmmBu9kC1MifOzCmXEhPnv7X4WBnIXw0M8HuUgA\n",
              "YebKjpAFnn8oM7aoyfH9lXRab2c0FpLaAfpES2dyu4aKaelBKlFQSN7F6b48wXs0en1L1N+D8zdN\n",
              "3WIdoqyK332RXAT/c7GcAv29uT/UFWZgp4gSNfCM34vIJ8k7xRnZEaEqs+UdG8Vbj6HF7Rz/JpuC\n",
              "yJeIl+BlF0EKM+n2pSj0D6J/nvHwJKjej1s2N2Xxaq6PMYXr8Dun7afUzNvHvEtu1H2ZXxkroRNr\n",
              "oD2kGV557L9J+1BhmnIEDDton9MFj22YwYovaaW2vdYzcSDSpN5PsAawCLGUD1EksXfC26BYY+iG\n",
              "qKoAggjr8kSgiw3+F4vgEgPJJM8bOOv5u2mRyihzKs/UiDXDtE/h3eYzblt4OsgV8gQYd7eiietN\n",
              "bBaE5N6JPOZLnyNKt0Y1mJ72fZVpwQGAAQ11Aol3I0Tjgb/5DVg73zbFv9T8gf1OW19VoxdQo6Z8\n",
              "TVUXNw22BFly6ST/B8wpa3r8R33xoCFeRpRs9uJXpifpCRYBqzSBFQKO/YpDcMfnSTknjkRwRD/4\n",
              "kZ5xnYEXuITfbfMMvTLPi3zUjkTfb33lwXDcMbYF3PjSs8fOrDjtn4RlE95PsrOOGsSHgfQVF9e/\n",
              "57v0KxG36Ho1lIbT8SzwCNxCG4ckmX3am/PG/TOnscD2IVkKqZI+RYmqlSp1t6nEbnRWELuvBGb1\n",
              "OaaQOPfjN4C8JqrP/aq+/hlqV0lYcHWa1+Fu2mGaovRrr9N7yLT3+ptoJlM/DWVqU0UaVKRT6/yQ\n",
              "iu9advZqDqWYTEth5OedtxmrqHkwW4xEKa+OavHqTN5yQOhHfDBzuMbcPhFrxzmuDRqBQm8+aGlo\n",
              "DVTkqHsj91RYRLOrp/85VYj4W8Hq/A+bSYnb/pQplUwwckE4S/R1G8aJhBkZV4U+CFI92eO/+RBD\n",
              "tdXo+xWqm/fprInTHLLHoJlvMxR2gkj4Smr75Ee1l21HqRnP7LhqeyGw0jtR9Js+J1hie5vaM24G\n",
              "Oh5/z4Fo+VNkmmIKumDuRnebcyEMbJcR+K36+IT3ojfXXR8Cz7xceazLw0oaG9a3/HNquBd3PpBi\n",
              "jmzkwBMlwM4H4wq5JxKQUdmhLzYFlLJAVdXCoHFXlqnFadwjNiYEJ2ub0ckNyuciCGs6LmAZejOc\n",
              "yEixuflBSa74O5nXjSZyo9s5w5Fz3TbxOIsyNCiqB1rSAIiykLJ0akkES8/ME784bGYdl5+f02xd\n",
              "y5kq8J9YCKwPZ+kudFJ9Qjmlj5ak20gvV+hN+/fe7bzBxVvyiKSLAsf2Inc2CtI4FdHi5K0XM1Ov\n",
              "QH3Ug1jIqrGw1ycYMCQLWtOhjou5vXm2luN0rnUxVbVsKcvhiIUhddMEjWvZP9HwMXyKic0MGjBh\n",
              "yeXI6CtS/vXYuG7OpaI3QKIxX6nql+Dm8sWJsgFND/kLoU4UgvoEZqO6ovhG6LumdjzbRv3a2pzy\n",
              "8JWdVvQ+uoT1GuYoW9iu/gVTjJF5kOpwUJMjwHVCEG4b3KaAGKmKVCcdhj3ofmqvFGcU0frmojvD\n",
              "JD603u0gTemTzZfyob0NTQVKXASCkiVFTt8kal63q0eOigmLAMg5Y53aMC+MGh7TyF2QUM1p16GJ\n",
              "UgX0G4mKcB4vWgzJ5WH6F1lNh2psDiXfOkjxP/AvEljEAHi54Kw49QqJYvOj1F7EilkHsnbDIv+4\n",
              "BvFZAzap7ei7j0p+sPatwcIkrKfcON/ekms2/HadO88xG3WEUsOWZMGPyP6XPOtUXJVdNpszVkzt\n",
              "J9OKlIQqUDodJ4/VwOD2qdpLx9nbiwsJa24M5rrOQgKnqyhFljH8sTJ/9yp9eiQdsVo2vIwSk0xe\n",
              "DO7BNT+kiIvn/AIOrXETvjTruNcQTKHIVRiEvyOsjrF/oOB0RNBAZr6cei7lbiL18az8N9LTzGgu\n",
              "OK85c7uQ1NaZ331IzXyrucjbhcJ48FlCUo7cHDehMMGhXfSJYjXGwtWQEh/wI4M5G/tMnXW2tfRn\n",
              "9QnevFlovNx7QP1cdtHm0hSCzHyJHftyKvmE9Qkz5fEM5J0GL+yCUrv76cYPUw2x2DBNkL+q6kgW\n",
              "ZkzHrQky1nErlwfM5KtaOqAxG7fg45814/6UdR4dRwgFotP4f4v5NTXluDCzyf7cWQ76DLteMfny\n",
              "O6/N8irWkCgcNPla4tFzxYg24Pac3u5YxEiK+0oY7ySlt5pKwGTSbcTtICpn8nyqi7sr/17hpkG+\n",
              "VR72R7U+Wls5ZonCyBPaPc5d7VF8RmpKUsKhlCziflTwq4eSO4XSsnH/DkfENiqGEWe+g+hEoMQf\n",
              "Q/9nWYrscZ9RiVthf/elMd8jG64orJwytNB0tGLbhmTocagD4BPAHncacrjzcpMS3GnwfH7znDGP\n",
              "kQSGJjeqS/uwi1t4dDRvJCR2nHmhv2+80QlCZgxYupuLc8LlAcN8zOsAAAOGbW9vdgAAAGxtdmhk\n",
              "AAAAAAAAAAAAAAAAAAAD6AAAAyAAAQAAAQAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAABAAAA\n",
              "AAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgAAArB0cmFrAAAAXHRr\n",
              "aGQAAAADAAAAAAAAAAAAAAABAAAAAAAAAyAAAAAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAA\n",
              "AAABAAAAAAAAAAAAAAAAAABAAAAAAoAAAAHgAAAAAAAkZWR0cwAAABxlbHN0AAAAAAAAAAEAAAMg\n",
              "AAAIAAABAAAAAAIobWRpYQAAACBtZGhkAAAAAAAAAAAAAAAAAAAoAAAAIABVxAAAAAAALWhkbHIA\n",
              "AAAAAAAAAHZpZGUAAAAAAAAAAAAAAABWaWRlb0hhbmRsZXIAAAAB021pbmYAAAAUdm1oZAAAAAEA\n",
              "AAAAAAAAAAAAACRkaW5mAAAAHGRyZWYAAAAAAAAAAQAAAAx1cmwgAAAAAQAAAZNzdGJsAAAAs3N0\n",
              "c2QAAAAAAAAAAQAAAKNhdmMxAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAoAB4ABIAAAASAAAAAAA\n",
              "AAABAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGP//AAAAMWF2Y0MBZAAW/+EAGGdk\n",
              "ABas2UCgPaEAAAMAAQAAAwAUDxYtlgEABmjr48siwAAAABx1dWlka2hA8l8kT8W6OaUbzwMj8wAA\n",
              "AAAAAAAYc3R0cwAAAAAAAAABAAAACAAABAAAAAAUc3RzcwAAAAAAAAABAAAAAQAAAEhjdHRzAAAA\n",
              "AAAAAAcAAAABAAAIAAAAAAEAAAwAAAAAAQAABAAAAAABAAAMAAAAAAEAAAQAAAAAAQAAEAAAAAAC\n",
              "AAAEAAAAABxzdHNjAAAAAAAAAAEAAAABAAAACAAAAAEAAAA0c3RzegAAAAAAAAAAAAAACAAAK8gA\n",
              "ABSFAAANqgAADHQAAAdmAAAMBwAADr4AAAtyAAAAFHN0Y28AAAAAAAAAAQAAACwAAABidWR0YQAA\n",
              "AFptZXRhAAAAAAAAACFoZGxyAAAAAAAAAABtZGlyYXBwbAAAAAAAAAAAAAAAAC1pbHN0AAAAJal0\n",
              "b28AAAAdZGF0YQAAAAEAAAAATGF2ZjU4LjI5LjEwMA==\n",
              "\">\n",
              "  Your browser does not support the video tag.\n",
              "</video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import animation\n",
        "from IPython.display import HTML\n",
        "\n",
        "# convert to image from proceessed tensors\n",
        "clip = example[\"pixel_values_videos\"][0] * 255\n",
        "clip = clip.permute(0, 2, 3, 1).clamp(0, 255)\n",
        "\n",
        "# np array with shape (frames, height, width, channels)\n",
        "video = np.array(clip).astype(np.uint8)\n",
        "\n",
        "fig = plt.figure()\n",
        "im = plt.imshow(video[0,:,:,:])\n",
        "\n",
        "plt.close() # this is required to not display the generated image\n",
        "\n",
        "def init():\n",
        "    im.set_data(video[0,:,:,:])\n",
        "\n",
        "def animate(i):\n",
        "    im.set_data(video[i,:,:,:])\n",
        "    return im\n",
        "\n",
        "anim = animation.FuncAnimation(fig, animate, init_func=init, frames=video.shape[0],\n",
        "                               interval=100)\n",
        "HTML(anim.to_html5_video())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e0cd5d1-961e-431d-8dc3-f82e57702852",
      "metadata": {
        "id": "2e0cd5d1-961e-431d-8dc3-f82e57702852",
        "outputId": "726ed09b-77f3-4cea-b9aa-180924cd065e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['<s> USER:  <video> \\nProvide a detailed caption for this video. ASSISTANT: The video captures a sequence of moments within an indoor space designed for art activities, featuring a child engaged in painting or drawing at an easel. Wearing an orange knitted jumper adorned with decorative elements, the child seems deeply involved in their artistic process from the beginning to the end of the captured frames. An adult is present throughout, standing closely behind the child, offering guidance or supervision but without direct intervention, as indicated by the proximity of the adultâ€™s hand to the childâ€™s. The setting includes abundant art supplies and evidence of creative work, such as paint splatters and various artworks, which, along with the consistent lighting and ambiance, affirms the spaceâ€™s purpose for art and painting activities.\\n\\nThroughout the video, there is a clear focus on the childâ€™s interaction with the paper on the easel, indicating a progression in the painting activity. This progression is subtly marked by the childâ€™s changing posture and the positioning of their handsâ€”initially engaged in unspecified manipulations of the']"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# and the caption associated with the video clip\n",
        "processor.batch_decode(example[\"input_ids\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0389710b",
      "metadata": {},
      "source": [
        "## Streaming Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "67aaf125",
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = load_dataset(\"ShareGPT4Video/ShareGPT4Video\")\n",
        "\n",
        "# processor = LlavaNextVideoProcessor.from_pretrained(MODEL_ID)\n",
        "\n",
        "# And we also need to load the processor for collate_fn\n",
        "processor = AutoProcessor.from_pretrained(MODEL_ID, use_fast=False)\n",
        "processor.tokenizer.padding_side = \"right\" # during training, one always uses padding on the right\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "0c1a4bae",
      "metadata": {},
      "outputs": [],
      "source": [
        "from decord import VideoReader, gpu, cpu\n",
        "\n",
        "def read_video_decord(video_path, num_frames=NUM_FRAMES):\n",
        "    '''\n",
        "    Decode the video with Decord decoder.\n",
        "\n",
        "    Args:\n",
        "        video_path (str): Path to the video file.\n",
        "        num_frames (int): Number of frames to sample uniformly. Defaults to NUM_FRAMES\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: np array of decoded frames of shape (num_frames, height, width, 3).\n",
        "    '''\n",
        "    vr = VideoReader(uri=video_path, ctx=cpu(0)) # you need to install from source to use gpu ctx\n",
        "    indices = np.arange(0, len(vr), len(vr) / num_frames).astype(int)\n",
        "    frames = vr.get_batch(indices).asnumpy()\n",
        "    return frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "e6c7c1fb",
      "metadata": {},
      "outputs": [],
      "source": [
        "class StreamerDataset(Dataset):\n",
        "    \"\"\"\n",
        "    This dataset handles the loading of video data and corresponding captions for streaming purposes.\n",
        "    It retrieves video data from a zip file stored remotely in HuggingFace Hub and processes it into tensors\n",
        "    suitable for model input.\n",
        "    \"\"\"\n",
        "    def __init__(self, dataset):\n",
        "        self.dataset = dataset\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        curr_element = self.dataset[idx]\n",
        "        zip_file_shard = curr_element['zip_folder']\n",
        "        video_path = curr_element['video_path']\n",
        "        file_name = curr_element[\"video_path\"].split(\"/\")[-1]\n",
        "        zip_folder = curr_element[\"video_path\"].split(\"/\")[0]\n",
        "        with fsspec.open(\n",
        "            f\"zip://{file_name}::hf://datasets/ShareGPT4Video/ShareGPT4Video/zip_folder/{zip_folder}/{zip_file_shard}\"\n",
        "        ) as f:\n",
        "            video_clip = read_video_decord(f)\n",
        "\n",
        "        # take caption for the whole video and not per-scene\n",
        "        video_caption = [caption['content'] for caption in curr_element[\"captions\"] if caption['idx'] == '-1'][0]\n",
        "        \n",
        "        # print(video_caption)\n",
        "        # Let's use chat template to format the prompt correctly\n",
        "        conversation = [\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": [\n",
        "                        {\"type\": \"text\", \"text\": \"Provide a detailed caption for this video.\"},\n",
        "                        {\"type\": \"video\"},\n",
        "                        ],\n",
        "                },\n",
        "                {\n",
        "                    \"role\": \"assistant\",\n",
        "                    \"content\": [\n",
        "                        {\"type\": \"text\", \"text\": video_caption},\n",
        "                            ],\n",
        "                },\n",
        "            ]\n",
        "\n",
        "        prompt = processor.apply_chat_template(conversation, add_generation_prompt=False)\n",
        "        \n",
        "        inputs = processor(\n",
        "            text=prompt,\n",
        "            videos=video_clip,\n",
        "            truncation=True,\n",
        "            max_length=MAX_LENGTH,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        #processor(video_caption, videos=video_clip, return_tensors=\"pt\")\n",
        "        return inputs\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "59cb95c0",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[    1,  3148,  1001, 29901, 29871, 32000, 32000, 32000, 32000, 32000,\n",
              "         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,\n",
              "         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,\n",
              "         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,\n",
              "         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,\n",
              "         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,\n",
              "         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,\n",
              "         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,\n",
              "         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,\n",
              "         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,\n",
              "         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,\n",
              "         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,\n",
              "         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,\n",
              "         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,\n",
              "         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,\n",
              "         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,\n",
              "         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,\n",
              "         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,\n",
              "         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,\n",
              "         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,\n",
              "         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,\n",
              "         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,\n",
              "         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,\n",
              "         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,\n",
              "         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,\n",
              "         32000, 32000, 32000, 32000, 32000, 32000]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'pixel_values_videos': tensor([[[[[-1.7923, -1.7923, -1.7923,  ..., -1.7923, -1.7923, -1.7923],\n",
              "           [-1.7923, -1.7923, -1.7923,  ..., -1.7923, -1.7923, -1.7923],\n",
              "           [-1.7923, -1.7923, -1.7923,  ..., -1.7923, -1.7923, -1.7923],\n",
              "           ...,\n",
              "           [-1.0769, -1.0915, -1.1061,  ..., -1.7631, -1.7631, -1.7631],\n",
              "           [-1.1061, -1.1353, -1.1645,  ..., -1.7923, -1.7923, -1.7923],\n",
              "           [-1.1061, -1.1499, -1.2083,  ..., -1.7923, -1.7923, -1.7923]],\n",
              "\n",
              "          [[-1.7521, -1.7521, -1.7521,  ..., -1.7521, -1.7521, -1.7521],\n",
              "           [-1.7521, -1.7521, -1.7521,  ..., -1.7521, -1.7521, -1.7521],\n",
              "           [-1.7521, -1.7521, -1.7521,  ..., -1.7521, -1.7521, -1.7521],\n",
              "           ...,\n",
              "           [-1.2418, -1.2568, -1.2718,  ..., -1.7371, -1.7371, -1.7221],\n",
              "           [-1.2418, -1.2718, -1.3019,  ..., -1.7221, -1.7221, -1.7221],\n",
              "           [-1.2418, -1.2869, -1.3469,  ..., -1.7221, -1.7221, -1.7221]],\n",
              "\n",
              "          [[-1.4802, -1.4802, -1.4802,  ..., -1.4802, -1.4802, -1.4802],\n",
              "           [-1.4802, -1.4802, -1.4802,  ..., -1.4802, -1.4802, -1.4802],\n",
              "           [-1.4802, -1.4802, -1.4802,  ..., -1.4802, -1.4802, -1.4802],\n",
              "           ...,\n",
              "           [-1.0821, -1.0821, -1.0963,  ..., -1.4802, -1.4802, -1.4802],\n",
              "           [-1.0678, -1.0963, -1.1247,  ..., -1.4802, -1.4802, -1.4802],\n",
              "           [-1.0678, -1.1105, -1.1674,  ..., -1.4802, -1.4802, -1.4802]]],\n",
              "\n",
              "\n",
              "         [[[-1.7923, -1.7923, -1.7923,  ..., -1.7923, -1.7923, -1.7923],\n",
              "           [-1.7923, -1.7923, -1.7923,  ..., -1.7923, -1.7923, -1.7923],\n",
              "           [-1.7923, -1.7923, -1.7923,  ..., -1.7923, -1.7923, -1.7923],\n",
              "           ...,\n",
              "           [-1.5733, -1.6171, -1.6463,  ..., -1.7631, -1.7631, -1.7777],\n",
              "           [-1.5879, -1.6317, -1.6463,  ..., -1.7777, -1.7777, -1.7777],\n",
              "           [-1.5879, -1.6317, -1.6463,  ..., -1.7777, -1.7777, -1.7777]],\n",
              "\n",
              "          [[-1.7521, -1.7521, -1.7521,  ..., -1.7521, -1.7521, -1.7521],\n",
              "           [-1.7521, -1.7521, -1.7521,  ..., -1.7521, -1.7521, -1.7521],\n",
              "           [-1.7521, -1.7521, -1.7521,  ..., -1.7521, -1.7521, -1.7521],\n",
              "           ...,\n",
              "           [-1.4970, -1.5420, -1.5720,  ..., -1.6921, -1.6921, -1.7071],\n",
              "           [-1.5120, -1.5570, -1.5720,  ..., -1.7071, -1.7071, -1.7071],\n",
              "           [-1.5120, -1.5570, -1.5720,  ..., -1.7071, -1.7071, -1.7071]],\n",
              "\n",
              "          [[-1.4802, -1.4802, -1.4802,  ..., -1.4802, -1.4802, -1.4802],\n",
              "           [-1.4802, -1.4802, -1.4802,  ..., -1.4802, -1.4802, -1.4802],\n",
              "           [-1.4802, -1.4802, -1.4802,  ..., -1.4802, -1.4802, -1.4802],\n",
              "           ...,\n",
              "           [-1.2811, -1.3238, -1.3522,  ..., -1.4660, -1.4660, -1.4802],\n",
              "           [-1.2954, -1.3380, -1.3522,  ..., -1.4802, -1.4802, -1.4802],\n",
              "           [-1.2954, -1.3380, -1.3522,  ..., -1.4802, -1.4802, -1.4802]]],\n",
              "\n",
              "\n",
              "         [[[-1.7923, -1.7923, -1.7923,  ..., -1.7923, -1.7923, -1.7923],\n",
              "           [-1.7923, -1.7923, -1.7923,  ..., -1.7923, -1.7923, -1.7923],\n",
              "           [-1.7923, -1.7923, -1.7923,  ..., -1.7923, -1.7923, -1.7923],\n",
              "           ...,\n",
              "           [-0.8726, -0.8142, -0.7704,  ..., -1.7923, -1.7923, -1.7923],\n",
              "           [-0.8580, -0.8142, -0.7996,  ..., -1.7923, -1.7923, -1.7923],\n",
              "           [-0.8288, -0.7996, -0.8142,  ..., -1.7923, -1.7923, -1.7923]],\n",
              "\n",
              "          [[-1.7521, -1.7521, -1.7521,  ..., -1.7521, -1.7521, -1.7521],\n",
              "           [-1.7521, -1.7521, -1.7521,  ..., -1.7521, -1.7521, -1.7521],\n",
              "           [-1.7521, -1.7521, -1.7521,  ..., -1.7521, -1.7521, -1.7521],\n",
              "           ...,\n",
              "           [-1.1218, -1.0617, -1.0167,  ..., -1.7521, -1.7521, -1.7521],\n",
              "           [-1.1068, -1.0617, -1.0467,  ..., -1.7521, -1.7521, -1.7521],\n",
              "           [-1.0767, -1.0467, -1.0617,  ..., -1.7521, -1.7521, -1.7521]],\n",
              "\n",
              "          [[-1.4802, -1.4802, -1.4802,  ..., -1.4802, -1.4802, -1.4802],\n",
              "           [-1.4802, -1.4802, -1.4802,  ..., -1.4802, -1.4802, -1.4802],\n",
              "           [-1.4802, -1.4802, -1.4802,  ..., -1.4802, -1.4802, -1.4802],\n",
              "           ...,\n",
              "           [-0.9399, -0.8830, -0.8403,  ..., -1.4802, -1.4802, -1.4802],\n",
              "           [-0.9256, -0.8830, -0.8688,  ..., -1.4802, -1.4802, -1.4802],\n",
              "           [-0.8972, -0.8688, -0.8830,  ..., -1.4802, -1.4802, -1.4802]]],\n",
              "\n",
              "\n",
              "         ...,\n",
              "\n",
              "\n",
              "         [[[-1.7923, -1.7923, -1.7923,  ..., -1.7923, -1.7923, -1.7923],\n",
              "           [-1.7923, -1.7923, -1.7923,  ..., -1.7923, -1.7923, -1.7923],\n",
              "           [-1.7923, -1.7923, -1.7923,  ..., -1.7923, -1.7923, -1.7923],\n",
              "           ...,\n",
              "           [-1.3689, -1.3689, -1.3397,  ..., -1.7923, -1.7923, -1.7923],\n",
              "           [-1.3543, -1.3689, -1.3543,  ..., -1.7923, -1.7923, -1.7923],\n",
              "           [-1.3543, -1.3689, -1.3543,  ..., -1.7923, -1.7923, -1.7923]],\n",
              "\n",
              "          [[-1.7521, -1.7521, -1.7521,  ..., -1.7521, -1.7521, -1.7521],\n",
              "           [-1.7521, -1.7521, -1.7521,  ..., -1.7521, -1.7521, -1.7521],\n",
              "           [-1.7521, -1.7521, -1.7521,  ..., -1.7521, -1.7521, -1.7521],\n",
              "           ...,\n",
              "           [-1.4219, -1.4219, -1.3919,  ..., -1.7521, -1.7521, -1.7521],\n",
              "           [-1.4069, -1.4219, -1.4069,  ..., -1.7371, -1.7371, -1.7371],\n",
              "           [-1.4069, -1.4219, -1.4069,  ..., -1.7371, -1.7371, -1.7371]],\n",
              "\n",
              "          [[-1.4802, -1.4802, -1.4802,  ..., -1.4802, -1.4802, -1.4802],\n",
              "           [-1.4802, -1.4802, -1.4802,  ..., -1.4802, -1.4802, -1.4802],\n",
              "           [-1.4802, -1.4802, -1.4802,  ..., -1.4802, -1.4802, -1.4802],\n",
              "           ...,\n",
              "           [-1.1958, -1.1958, -1.1674,  ..., -1.4802, -1.4802, -1.4802],\n",
              "           [-1.1816, -1.1958, -1.1816,  ..., -1.4802, -1.4802, -1.4802],\n",
              "           [-1.1816, -1.1958, -1.1816,  ..., -1.4802, -1.4802, -1.4802]]],\n",
              "\n",
              "\n",
              "         [[[-1.7923, -1.7923, -1.7923,  ..., -1.7923, -1.7923, -1.7923],\n",
              "           [-1.7923, -1.7923, -1.7923,  ..., -1.7923, -1.7923, -1.7923],\n",
              "           [-1.7923, -1.7923, -1.7923,  ..., -1.7923, -1.7923, -1.7923],\n",
              "           ...,\n",
              "           [-1.7485, -1.7485, -1.7485,  ..., -1.7923, -1.7923, -1.7923],\n",
              "           [-1.7485, -1.7485, -1.7485,  ..., -1.7923, -1.7923, -1.7923],\n",
              "           [-1.7485, -1.7485, -1.7485,  ..., -1.7923, -1.7923, -1.7923]],\n",
              "\n",
              "          [[-1.7521, -1.7521, -1.7521,  ..., -1.7521, -1.7521, -1.7521],\n",
              "           [-1.7521, -1.7521, -1.7521,  ..., -1.7521, -1.7521, -1.7521],\n",
              "           [-1.7521, -1.7521, -1.7521,  ..., -1.7521, -1.7521, -1.7521],\n",
              "           ...,\n",
              "           [-1.7221, -1.7221, -1.7221,  ..., -1.7521, -1.7521, -1.7521],\n",
              "           [-1.7221, -1.7221, -1.7221,  ..., -1.7521, -1.7521, -1.7521],\n",
              "           [-1.7221, -1.7221, -1.7221,  ..., -1.7521, -1.7521, -1.7521]],\n",
              "\n",
              "          [[-1.4802, -1.4802, -1.4802,  ..., -1.4802, -1.4802, -1.4802],\n",
              "           [-1.4802, -1.4802, -1.4802,  ..., -1.4802, -1.4802, -1.4802],\n",
              "           [-1.4802, -1.4802, -1.4802,  ..., -1.4802, -1.4802, -1.4802],\n",
              "           ...,\n",
              "           [-1.4091, -1.4091, -1.4091,  ..., -1.4660, -1.4802, -1.4802],\n",
              "           [-1.4091, -1.4091, -1.4091,  ..., -1.4802, -1.4802, -1.4802],\n",
              "           [-1.4091, -1.4091, -1.4091,  ..., -1.4660, -1.4802, -1.4802]]],\n",
              "\n",
              "\n",
              "         [[[-1.7923, -1.7923, -1.7923,  ..., -1.7923, -1.7923, -1.7923],\n",
              "           [-1.7923, -1.7923, -1.7923,  ..., -1.7923, -1.7923, -1.7923],\n",
              "           [-1.7923, -1.7923, -1.7923,  ..., -1.7923, -1.7923, -1.7923],\n",
              "           ...,\n",
              "           [-1.4273, -1.4273, -1.4127,  ..., -1.7631, -1.7777, -1.7631],\n",
              "           [-1.4565, -1.4565, -1.4565,  ..., -1.7631, -1.7631, -1.7485],\n",
              "           [-1.4711, -1.4711, -1.4711,  ..., -1.7631, -1.7631, -1.7485]],\n",
              "\n",
              "          [[-1.7521, -1.7521, -1.7521,  ..., -1.7521, -1.7521, -1.7521],\n",
              "           [-1.7521, -1.7521, -1.7521,  ..., -1.7521, -1.7521, -1.7521],\n",
              "           [-1.7521, -1.7521, -1.7521,  ..., -1.7521, -1.7521, -1.7521],\n",
              "           ...,\n",
              "           [-1.4970, -1.4970, -1.4820,  ..., -1.7221, -1.7071, -1.6921],\n",
              "           [-1.4970, -1.4970, -1.5120,  ..., -1.7221, -1.7071, -1.6921],\n",
              "           [-1.5270, -1.5270, -1.5270,  ..., -1.7221, -1.7071, -1.6921]],\n",
              "\n",
              "          [[-1.4802, -1.4802, -1.4802,  ..., -1.4802, -1.4802, -1.4802],\n",
              "           [-1.4802, -1.4802, -1.4802,  ..., -1.4802, -1.4802, -1.4802],\n",
              "           [-1.4802, -1.4802, -1.4802,  ..., -1.4802, -1.4802, -1.4802],\n",
              "           ...,\n",
              "           [-1.2811, -1.2811, -1.2669,  ..., -1.4518, -1.4376, -1.4233],\n",
              "           [-1.2669, -1.2669, -1.2669,  ..., -1.4091, -1.3949, -1.3807],\n",
              "           [-1.2954, -1.2954, -1.2954,  ..., -1.4091, -1.3949, -1.3807]]]]])}"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "streamer = StreamerDataset(dataset[\"train\"])\n",
        "streamer[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7115f55",
      "metadata": {},
      "outputs": [],
      "source": [
        "# def collate_fn(examples):\n",
        "#     \"\"\"\n",
        "#     Collate function that dynamically pads inputs to the max length within the batch and creates labels for language modelsing task.\n",
        "#     In contrast to DataCollatorForLanguageModeling, this collator adds pixel values to the batch for multimodal LLMs.\n",
        "#     \"\"\"\n",
        "#     padded_inputs = processor.tokenizer.pad(\n",
        "#         {\n",
        "#             \"input_ids\": [feat['input_ids'][0] for feat in examples], # each element is one batch only so we slice [0]\n",
        "#             \"attention_mask\": [feat['attention_mask'][0] for feat in examples],\n",
        "#         },\n",
        "#         padding=True,\n",
        "#         return_tensors=\"pt\",\n",
        "#     )\n",
        "\n",
        "#     labels = padded_inputs[\"input_ids\"].clone()\n",
        "#     labels[labels == processor.tokenizer.pad_token_id] = -100 # feel free to mask labels the way that suits your use-case (e.g. mask all user-turns)\n",
        "#     padded_inputs[\"labels\"] = labels\n",
        "#     padded_inputs[\"pixel_values_videos\"] = torch.cat([feat['pixel_values_videos'] for feat in examples], dim=0)\n",
        "\n",
        "#     return padded_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ae77a3c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# class LlavaNextVideoDataCollatorWithPadding:\n",
        "#     def __init__(self, processor):\n",
        "#         self.processor = processor\n",
        "\n",
        "#     def __call__(self, features):\n",
        "#         padded_inputs = self.processor.tokenizer.pad(\n",
        "#             {\n",
        "#                 \"input_ids\": [feat['input_ids'][0] for feat in features], # each element is one batch only so we slice [0]\n",
        "#                 \"attention_mask\": [feat['attention_mask'][0] for feat in features],\n",
        "#             },\n",
        "#             padding=True,\n",
        "#             return_tensors=\"pt\",\n",
        "#         )\n",
        "\n",
        "#         labels = padded_inputs[\"input_ids\"].clone()\n",
        "#         labels[labels == self.processor.tokenizer.pad_token_id] = -100\n",
        "#         padded_inputs[\"labels\"] = labels\n",
        "#         padded_inputs[\"pixel_values_videos\"] = torch.cat([feat['pixel_values_videos'] for feat in features], dim=0)\n",
        "\n",
        "#         return padded_inputs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "401a8936",
      "metadata": {},
      "outputs": [],
      "source": [
        "streamer = StreamerDataset(dataset[\"train\"])\n",
        "# loader = DataLoader(streamer, batch_size=8, collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "52b280c7",
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_items = streamer[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "9b9b019f",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'attention_mask', 'pixel_values_videos'])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch_items.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "79764fe0",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<video width=\"640\" height=\"480\" controls autoplay loop>\n",
              "  <source type=\"video/mp4\" src=\"data:video/mp4;base64,AAAAIGZ0eXBNNFYgAAACAE00ViBpc29taXNvMmF2YzEAAAAIZnJlZQAAD9VtZGF0AAACrwYF//+r\n",
              "3EXpvebZSLeWLNgg2SPu73gyNjQgLSBjb3JlIDE2NCByMzEwOCAzMWUxOWY5IC0gSC4yNjQvTVBF\n",
              "Ry00IEFWQyBjb2RlYyAtIENvcHlsZWZ0IDIwMDMtMjAyMyAtIGh0dHA6Ly93d3cudmlkZW9sYW4u\n",
              "b3JnL3gyNjQuaHRtbCAtIG9wdGlvbnM6IGNhYmFjPTEgcmVmPTMgZGVibG9jaz0xOjA6MCBhbmFs\n",
              "eXNlPTB4MzoweDExMyBtZT1oZXggc3VibWU9NyBwc3k9MSBwc3lfcmQ9MS4wMDowLjAwIG1peGVk\n",
              "X3JlZj0xIG1lX3JhbmdlPTE2IGNocm9tYV9tZT0xIHRyZWxsaXM9MSA4eDhkY3Q9MSBjcW09MCBk\n",
              "ZWFkem9uZT0yMSwxMSBmYXN0X3Bza2lwPTEgY2hyb21hX3FwX29mZnNldD0tMiB0aHJlYWRzPTE1\n",
              "IGxvb2thaGVhZF90aHJlYWRzPTIgc2xpY2VkX3RocmVhZHM9MCBucj0wIGRlY2ltYXRlPTEgaW50\n",
              "ZXJsYWNlZD0wIGJsdXJheV9jb21wYXQ9MCBjb25zdHJhaW5lZF9pbnRyYT0wIGJmcmFtZXM9MyBi\n",
              "X3B5cmFtaWQ9MiBiX2FkYXB0PTEgYl9iaWFzPTAgZGlyZWN0PTEgd2VpZ2h0Yj0xIG9wZW5fZ29w\n",
              "PTAgd2VpZ2h0cD0yIGtleWludD0yNTAga2V5aW50X21pbj0xMCBzY2VuZWN1dD00MCBpbnRyYV9y\n",
              "ZWZyZXNoPTAgcmNfbG9va2FoZWFkPTQwIHJjPWNyZiBtYnRyZWU9MSBjcmY9MjMuMCBxY29tcD0w\n",
              "LjYwIHFwbWluPTAgcXBtYXg9NjkgcXBzdGVwPTQgaXBfcmF0aW89MS40MCBhcT0xOjEuMDAAgAAA\n",
              "C7tliIQAEP/+94G/MstfIrrJcfnnfSyszzzkPHJdia640AAAAwAAAwAAP8j+NuVUetgS4AAABOwA\n",
              "2cv/xGPyuAAr4FDSLXK5tr13cj0N9z8ypEzO8TNK6gFpxwyYVRYW4nraRXRJLNT2OevGzRxKC7of\n",
              "Zbe7cmkIlivNDeOmPXAJloEjOD5j+Vvf1B9ydIsVTv0q1c/YMAYAw4IrTlDRSF/dPeAr0PErDwTQ\n",
              "+md3ti7VgTaD5lR0c3uyrbSi+l1OLJhI+sgcZivTmA4uDdthHWEAYDn/0LdChAgmKqKi5LmpN/YL\n",
              "2MssIHGcxfjL3f5GrLtoPSins8yEPHBpB5Hfe+6wgnGM5MBj0qvowROs+NAFD7+uArRPD1w+XQ1o\n",
              "NH2KgjfFkckDR+nK+4R84mrmu7J5ABg2rqihzTY07SlotZhD4MIbuzq6dcUXlor2Ff0x3HDOFw3c\n",
              "qsvQZf1HG2Pp086y6YPUy3f3K0MzszYzpI65Vmn951bSlmfemqrkea5NXF88XlIpbwpfyFNiBTlY\n",
              "KwEmrDNlmkXUdsqICEbtrrYIbQDkFYmE2HpNBiw7px9I5YF2DMBw5EI42rniZZER+rYd4AL1oReJ\n",
              "PlBfjb4ynHPC9mfVXJxpSdJvwvgqiRfzG0byGxZMtgfjVNHgC4yVZha3pv7aXdz8CcG4tvoV1zjZ\n",
              "uei1NQavy7K83RWON0CtkGCC/sPt5fKvFLFqofdZYQeQQEKcDgjRSxB7BT9bgH8xb9utVv2uKQT6\n",
              "5ln9e6GViJdSIKIZ1k342CO/0zlfxQD4YzI7ljSZconc3/f6uSGECPu/67exytE/Fqz860q6g89i\n",
              "C6Id1P5/MWLqIYfsTGINQIsCpvkQyap+7DGuqQDZamklc0pQCR0Lvh4pP1u4s8Ji3JjktA7+V1t9\n",
              "TP5nGNULvZh3PSMYiW6kI7Ei9bLEbyMKV1ShoXVZm6nQoup0PChzj+T00wZOnu58vy5U3PV+qwie\n",
              "ALOo0yABEfbGYFhtp322eAZurli/qDx7nKN7FwirUTXileQlVFrB48qlBQBCU6UDMP3cAUwqA/fV\n",
              "iFuvtiJjswbgETZe3zx+DjOvwSRJlStqfFqufjnGF9EmgMloti0XPRC28t65tAmd+SQyat+9A2wi\n",
              "ZPlc5XFm5Tv5IIalEF+VQx84bvxLQ2LYOSlU363GRcAWzgImj23AiARvR9ul//1eFiIuqtR8X7mI\n",
              "StuDc5bz74x7X9aYshq9ZsAAMwCc8OnyvUQAEGPj5Lv0q9gtvs6muvApMulkLEXJB1+DRkotmDoS\n",
              "aPvc+N1IIVjOy9T2TeMoXm9/jNadIDqRbMvxIpv/5liMP5A5nVywPP0G/RYtTwEnNCRpG6dWgmE9\n",
              "1JMMlQRwXMYHzT2N/Fk0srJRfKcpDc7e990F5diHqxDDDg5L66CAwLZrkUqMTP83cO4j5drPeqth\n",
              "4TjlE2FZQVAoCjhnJ2UGyxIS9ybxc/+UQkWXTM4oosa5iLySpcb3Hk55Ofrzb04qwY/KWhsHMJEy\n",
              "6/G2ES7s5WoDtjUl356jPJohmUJKABUnp2HrBrLgAAADARYImvDT+NfPRGp5QuqB/GGtnwqda0UM\n",
              "IM4DXyfvKnS1xgkqZZSBu7SDU/VWFfS2YDQJd/G4qFEZRrmBk39DGhtwzDlT9KanMOluqQIeQB14\n",
              "v0Dbyu7KDUf+Hqh5dVx41V4bmoE4s/Adxn7grSx1EK5Z48dTD3B1uTZDaOnjGt3Hz82CIkljIP4c\n",
              "zfWUjyak0qmstiobkCzNxvMKMfqfcQAYr7q7acjRzYVFyc/oLCwJKBdbIbaXwSwj0+SLaC+bWQVn\n",
              "llldJKeLm5G0OgdoiFulyb0NgOJZlwuVA0gjoho9MozmIaho2eRmdo7zGJAAAAMAEtzqhOfIr9Ku\n",
              "u1LVCQLeAfDSab8rpORehQc/3Hz/+A4rvDUq3iFjkySmOrdse5a1/LS4zb/7yo6lYAnFJgrb2L3/\n",
              "UOTHFwIkw3+HGwWh7Sg6bJt51x0oEe6IDc9fpkhDrCdE7kV80lWtvst4TdHa3fE5x+2EH9jFuqrl\n",
              "UqCNbVSG7M8bWuNYQmBqUMIIWOM+mVni5SbkT9xPOVQl7ZJkffg+qoMpa97N7h1wnrlOHpJvIzFN\n",
              "SJipxSw5RHpPr/DhBc0brebd51ePfYeRLSViSIAIoANbKNIvauv+lu/dy1ugTJnXKB1FQoMAmkRt\n",
              "Jdt1S9gq0IgOWtsyxrlw1WI/+SYLcREb6XVdLAEziuaDPVK/NOnhIA9SxiT+0gjiapXxSC14/OPb\n",
              "FeWnrOwb67gbfCc9Y5nmoswU1MRJ/MIJQg92Bv/MFt7pazlLZeTN3GyPfFtfTtxbUoyjf9uZPSG0\n",
              "cODdGUwai5aZ405iPU4rQUukjGpPtiT2QFW1g6jyNLcsVFecboSCFBxaoqMjE+AtZxpBuOK2GGiI\n",
              "PLQ47MS7lrg1QXtHy8vywYlmhoaTvybGnmh+t2sPiX9k0lYMr//8d0pZWRYBadOUS8dQOVP1+8aD\n",
              "sSTeejVZEp9tw/8nclHLZx0Z06bBAL6XHqT0Ag9ZCppVGHypYNM+YDemJnMPBDCEYz6c/2vbQLUY\n",
              "wLXCum01uTq8XcMjs9SLNZs0OgdbzkT379TT+cqr6WscSFiQS8IO3LTR+9HnBpAhGrYRBQ587kty\n",
              "1/9Kd1zjsKgFVPqZEeV/8xR/Fwzn6GIxqLPM1jOeVtzQpSCaLhse/SxwH6fnARcblbRxYuyIma9Z\n",
              "c3B71yfs2TjVgaq4SaVSl9paFGPCogo0LQ2LtMyUQaX0u/U0iUsXFn/nX89TdskknXwRzOPBbNwg\n",
              "tv44xLqnl025e0d7N3aCKWzx0yDhQFy7cFtAuFL4i2DT1twkKtbde8Bv0evumQ59xMo9BJD7qWrz\n",
              "tVvbGtunFG+2gfUzXzQNkaF4UfPhoHOyd5BYoXX58JT18iD0e9+5w++c7gbJzVkj64dRQgMwxMf0\n",
              "8FH5uKq9mTi0euqrFkyZLENQRNzQCYvmjNwfVnKZn64Segjq1HxPitQCsveyzCTcqq7QxY61mHwy\n",
              "je3vJGhtiY8mtFvXXwpKsqAo37BVCUSG9KFFeL8jWZtJOoJrvKl1iLBLEuRvZeq9/unU+8dhBJus\n",
              "dWlZS75osyiPn/NZ+R7zE4AUbwvcEGgZ921IGfqUck7XEkF+W2ZGOY6s9ntEEAOiiJ3hPlcY2rXy\n",
              "Y12Jn6YzRed+DZ7nOCf/n1Zi/PsYmimyakYZK3/Wln5PUPPVF9ggPKJS3UcsOx/4RGEOhqNQ3RV9\n",
              "3h2+8z2bqIik2xLu3C9AwKMlbPzVXf1LSP4ARvYD0Pue1i64qsxzxcRUeY7O+OfYQYyn9spMMA+3\n",
              "tyzgYqFi2MmRPHBbdH4ziFNLqx5OIi6KZ5sh9KddMKSzuwHgxaodMY0/vvCC+jXdy+yoKFth8HuT\n",
              "1iYsfXxIDKYfp5f6v2zXUP4HJbPzwsmfO0XVZrSkK4sR+jX7REyV2i3lMEoZou5NkumEz/o2td/3\n",
              "j/s0usubTwtkDWiyLReGXnXDtEmRp9xHJF3IadGfZ0EEizYXpVdk3KUE0ewyZE5lUJj91ZVrybqu\n",
              "lNsPyQGZllufCqXbri6PlpHGEU+rjFM0LVHLIK7eTxd2SPD0xnltfiYxBrkt1vSg1eF/NEiNx5IF\n",
              "K0VBtr6Rf5zShjFkb6JjSlrwrTfY+gh8GuKVQFxVqtsjdUnui0q7UEgN3eNjWSlMDZpp1K0dTfBf\n",
              "RSHoLyJ1YHrX9aUM8Z7v2ReZdkqaD+KaMruYvdupkm20Jk7yDq1sCRAJP+CzI1ltyC31hL2+XGO/\n",
              "2GwtkOH74Q82MsQroJQb7unRSfzngCHX2N9Qi0CwYppXQMl0OsRiM0YmphRSm4c2Th9YTqjxEfLo\n",
              "/SiKv9B07u3O2vLAbAcgkkzyoibdmrOQx3vV8OEVt/AZL0GFSX5iGCoKsO0U8eWRIGra2lSwfoes\n",
              "2dslXpZN6N0JXP/7HMys7kc1WaocazX3O2FSw4ACB5U1Gi65AgAABYUAAABMQZokbEP//qmWAAFd\n",
              "+ZhdtJ2sGvX4ifwh06QCeE/Lg7eZEkTKwojlMMOQ4Xgx6IBePvR3OdgBRbntBeLEqXA8mtspw39S\n",
              "72VT0MWvgAAAAC9BnkJ4h38AAK4Y8IlsrswaAWo0KEK7cH9jvynRqdBeQQkrR+XAAdkjq29H0UoR\n",
              "JwAAACkBnmF0Q38AAPLp/4i9WvXQS1V2dyK/I0SWsl+dKhXQ4LCwAAFOqeCTgAAAABsBnmNqQ38A\n",
              "AB8O3A04TcAWEi7krYl4lAAAN+EAAAA6QZpnSahBaJlMCG///qeEAAD5a9+bg3dgAOZ/v54fAGh2\n",
              "GWl/lyM9pALKoT+oN+a8soqpqNDAAADjgQAAAB9BnoVFESw3/wAAWt6Lsy3mobgo4xMRluOA3UU+\n",
              "o0b1AAAAJwGepmpDfwAAWt6Lsy3E6S2QIBZgWSRLgNly+X7WSn8Mg/pAAAApIQAAA4ptb292AAAA\n",
              "bG12aGQAAAAAAAAAAAAAAAAAAAPoAAADIAABAAABAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAA\n",
              "AAEAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAAACtHRyYWsA\n",
              "AABcdGtoZAAAAAMAAAAAAAAAAAAAAAEAAAAAAAADIAAAAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAA\n",
              "AAAAAAAAAAEAAAAAAAAAAAAAAAAAAEAAAAACgAAAAeAAAAAAACRlZHRzAAAAHGVsc3QAAAAAAAAA\n",
              "AQAAAyAAAAgAAAEAAAAAAixtZGlhAAAAIG1kaGQAAAAAAAAAAAAAAAAAACgAAAAgAFXEAAAAAAAt\n",
              "aGRscgAAAAAAAAAAdmlkZQAAAAAAAAAAAAAAAFZpZGVvSGFuZGxlcgAAAAHXbWluZgAAABR2bWhk\n",
              "AAAAAQAAAAAAAAAAAAAAJGRpbmYAAAAcZHJlZgAAAAAAAAABAAAADHVybCAAAAABAAABl3N0YmwA\n",
              "AAC3c3RzZAAAAAAAAAABAAAAp2F2YzEAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAACgAHgAEgAAABI\n",
              "AAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY//8AAAA1YXZjQwFkABb/\n",
              "4QAYZ2QAFqzZQKA9oQAAAwABAAADABQPFi2WAQAGaOvjyyLA/fj4AAAAABx1dWlka2hA8l8kT8W6\n",
              "OaUbzwMj8wAAAAAAAAAYc3R0cwAAAAAAAAABAAAACAAABAAAAAAUc3RzcwAAAAAAAAABAAAAAQAA\n",
              "AEhjdHRzAAAAAAAAAAcAAAABAAAIAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAA\n",
              "AQAAEAAAAAACAAAEAAAAABxzdHNjAAAAAAAAAAEAAAABAAAACAAAAAEAAAA0c3RzegAAAAAAAAAA\n",
              "AAAACAAADnIAAABQAAAAMwAAAC0AAAAfAAAAPgAAACMAAAArAAAAFHN0Y28AAAAAAAAAAQAAADAA\n",
              "AABidWR0YQAAAFptZXRhAAAAAAAAACFoZGxyAAAAAAAAAABtZGlyYXBwbAAAAAAAAAAAAAAAAC1p\n",
              "bHN0AAAAJal0b28AAAAdZGF0YQAAAAEAAAAATGF2ZjYwLjE2LjEwMA==\n",
              "\">\n",
              "  Your browser does not support the video tag.\n",
              "</video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example = batch_items\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import animation\n",
        "from IPython.display import HTML\n",
        "\n",
        "# convert to image from proceessed tensors\n",
        "clip = example[\"pixel_values_videos\"][0] * 255\n",
        "clip = clip.permute(0, 2, 3, 1).clamp(0, 255)\n",
        "\n",
        "# np array with shape (frames, height, width, channels)\n",
        "video = np.array(clip).astype(np.uint8)\n",
        "\n",
        "fig = plt.figure()\n",
        "im = plt.imshow(video[0,:,:,:])\n",
        "\n",
        "plt.close() # this is required to not display the generated image\n",
        "\n",
        "def init():\n",
        "    im.set_data(video[0,:,:,:])\n",
        "\n",
        "def animate(i):\n",
        "    im.set_data(video[i,:,:,:])\n",
        "    return im\n",
        "\n",
        "anim = animation.FuncAnimation(fig, animate, init_func=init, frames=video.shape[0],\n",
        "                               interval=100)\n",
        "HTML(anim.to_html5_video())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "4c6b0338",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['<s> USER: <video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video>',\n",
              " '<s> USER: <video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video>',\n",
              " '<s> USER: <video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video>',\n",
              " '<s> USER: <video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video>',\n",
              " '<s> USER: <video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video>',\n",
              " '<s> USER: <video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video>',\n",
              " '<s> USER: <video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video>',\n",
              " '<s> USER: <video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video><video>']"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# and the caption associated with the video clip\n",
        "processor.batch_decode(example[\"input_ids\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "edeff3a9-0988-485c-b9a9-f74a890489dc",
      "metadata": {
        "id": "edeff3a9-0988-485c-b9a9-f74a890489dc"
      },
      "source": [
        "## Load model\n",
        "Next, we're going to load the LLaVa-NeXT-Video model from the hub. This is a model with about 7 billion trainable parameters (as it combines a LLaMa-7B language model with a relatively low-parameter vision encoder). Do note that we load a model here which already has undergone supervised fine-tuning (SFT) on VideoChat instruction dataset. We can benefit from the fine-tuning that the model already has undergone."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbc13ffb-4c61-48a3-9a8d-8d96d0247bfe",
      "metadata": {
        "id": "cbc13ffb-4c61-48a3-9a8d-8d96d0247bfe"
      },
      "source": [
        "## Full fine-tuning, LoRa and Q-LoRa\n",
        "As this model has 7 billion trainable parameters, that's going to have quite an impact on the amount of memory used. For reference, fine-tuning a model using the AdamW optimizer (which is often used to optimize neural networks) with mixed precision, you need about 18 times the amount of parameters in GB of GPU RAM. So in this case, we would need 18x7 billion bytes = 126 GB of GPU RAM if we want to update all the parameters of the model!! That's huge right? And for most people infeasible.\n",
        "\n",
        "Luckily, some clever people came up with the LoRa method (LoRa is short for low-rank adapation). It allows to just freeze the existing weights and only train a couple of adapter layers on top of the base model. Hugging Face offers the separate [PEFT library](https://huggingface.co/docs/peft/main/en/index) for easy use of LoRa, along with other Parameter-Efficient Fine-Tuning methods (that's where the name PEFT comes from).\n",
        "\n",
        "Moreover, one can not only freeze the existing base model but also quantize it (which means, shrinking down its size). A neural network's parameters are typically saved in either float32 (which means, 32 bits or 4 bytes are used to store each parameter value) or float16 (which means, 16 bits or half a byte - also called half precision). However, with some clever algorithms one can shrink each parameter to just 8 or 4 bits (half a byte!), without significant effect on final performance. Read all about it [here](https://huggingface.co/blog/4bit-transformers-bitsandbytes)\n",
        "\n",
        "This means that we're going to shrink the size of the base Idefics2-8b model considerably using 4-bit quantization, and then only train a couple of adapter layers on top using LoRa (in float16). This idea of combining LoRa with quantization is called Q-LoRa and is the most memory friendly version.\n",
        "\n",
        "Of course, if you have the memory available, feel free to use full fine-tuning or LoRa without quantization! In case of full fine-tuning, the code snippet below instantiates the model with Flash Attention which considerably speeds up computations.\n",
        "\n",
        "There exist many forms of quantization, here we leverage the BitsAndBytes integration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "626e493e-504c-49e6-bcdc-adfff462e12b",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "a97903f3bcaa41698b86bff92daf7576"
          ]
        },
        "id": "626e493e-504c-49e6-bcdc-adfff462e12b",
        "outputId": "0db81d35-d484-434c-c2cf-7270bca26188",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "af51f21a951a41ab939d0829494aeedf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/1.41k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "da830ac413f74b989b65508d295d19cd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/70.2k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "589a98d04c4d42b1b6dececcc6f59b54",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a492295d1d214fddb0e8a55b660fbee2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00001-of-00003.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "158384bc7403489a97a284122a67079a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00002-of-00003.safetensors:   0%|          | 0.00/4.96G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "edbab8fe2aa0403e90a2752d343bb66b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00003-of-00003.safetensors:   0%|          | 0.00/4.18G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "22b9ec372dcb4a50908f72a2df011c88",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fcf96c9d3c9e4f428c86e906b11735d0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "## Load model\n",
        "# Three options for training, from the lowest precision training to the highest precision training:\n",
        "# QLoRA: model uses 4-bit quantization, which helps in reducing memory usage while maintaining performance.\n",
        "# Standard LoRA:  model is loaded with standard LoRA adaptations.\n",
        "# Full Fine-Tuning: no memory optimization are done. In that case Flash Attention is used to speed up training, if hardware supports it.\n",
        "\n",
        "if USE_QLORA or USE_LORA:\n",
        "    if USE_QLORA:\n",
        "        bnb_config = BitsAndBytesConfig(\n",
        "            load_in_4bit=True,\n",
        "            bnb_4bit_quant_type=\"nf4\",\n",
        "            bnb_4bit_compute_dtype=torch.float16,\n",
        "        )\n",
        "    model = LlavaNextVideoForConditionalGeneration.from_pretrained(\n",
        "        MODEL_ID,\n",
        "        torch_dtype=torch.float16,\n",
        "        quantization_config=bnb_config,\n",
        "        device_map=\"auto\",\n",
        "    )\n",
        "else:\n",
        "    # for full fine-tuning, we can speed up the model using Flash Attention\n",
        "    # only available on certain devices, see https://github.com/Dao-AILab/flash-attention?tab=readme-ov-file#installation-and-features\n",
        "    model = LlavaNextVideoForConditionalGeneration.from_pretrained(\n",
        "        MODEL_ID,\n",
        "        torch_dtype=torch.float16,\n",
        "        _attn_implementation=\"flash_attention_2\",\n",
        "        device_map=\"auto\",\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "605968ce-713a-4723-ae08-31e76dafc49a",
      "metadata": {
        "id": "605968ce-713a-4723-ae08-31e76dafc49a"
      },
      "source": [
        "## Apply PEFT\n",
        "After loading the base model, we're going to add LoRa adapter layers. We're going to only train these adapter layers (the base model is kept frozen).\n",
        "\n",
        "The difference here with other models are the layers at which we're going to add adapters (in PEFT this is called target_modules). This typically depends a bit on the model.\n",
        "\n",
        "We defined a function to find all linear layers in the model, excluding any layers related to multimodal projections and vision models. This function will help us identify which layers should have LoRA applied. We're going to add adapters to all linear layers of the model (nn.Linear), except for the ones present in the vision encoder and multimodal projector. This means that we're mostly going to adapt the language model part of Video-LLaVa for our use case.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "45034f1e-d533-4b28-8c91-95c601fa2ba2",
      "metadata": {
        "id": "45034f1e-d533-4b28-8c91-95c601fa2ba2"
      },
      "outputs": [],
      "source": [
        "def find_all_linear_names(model):\n",
        "    cls = torch.nn.Linear\n",
        "    lora_module_names = set()\n",
        "    multimodal_keywords = ['multi_modal_projector', 'vision_model']\n",
        "    for name, module in model.named_modules():\n",
        "        if any(mm_keyword in name for mm_keyword in multimodal_keywords):\n",
        "            continue\n",
        "        if isinstance(module, cls):\n",
        "            names = name.split('.')\n",
        "            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n",
        "\n",
        "    if 'lm_head' in lora_module_names: # needed for 16-bit\n",
        "        lora_module_names.remove('lm_head')\n",
        "    return list(lora_module_names)\n",
        "\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=8,\n",
        "    lora_dropout=0.1,\n",
        "    target_modules=find_all_linear_names(model),\n",
        "    init_lora_weights=\"gaussian\",\n",
        ")\n",
        "\n",
        "model = prepare_model_for_kbit_training(model)\n",
        "model = get_peft_model(model, lora_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "64822f99-dd45-40d2-9d3d-cf75b2587f02",
      "metadata": {
        "id": "64822f99-dd45-40d2-9d3d-cf75b2587f02",
        "outputId": "fb378bf0-9108-4c90-bfef-e46f3d07d583"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PeftModel(\n",
              "  (base_model): LoraModel(\n",
              "    (model): LlavaNextVideoForConditionalGeneration(\n",
              "      (vision_tower): CLIPVisionModel(\n",
              "        (vision_model): CLIPVisionTransformer(\n",
              "          (embeddings): CLIPVisionEmbeddings(\n",
              "            (patch_embedding): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14), bias=False)\n",
              "            (position_embedding): Embedding(577, 1024)\n",
              "          )\n",
              "          (pre_layrnorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder): CLIPEncoder(\n",
              "            (layers): ModuleList(\n",
              "              (0-23): 24 x CLIPEncoderLayer(\n",
              "                (self_attn): CLIPSdpaAttention(\n",
              "                  (k_proj): lora.Linear4bit(\n",
              "                    (base_layer): Linear4bit(in_features=1024, out_features=1024, bias=True)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.1, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=1024, out_features=8, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=8, out_features=1024, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                    (lora_magnitude_vector): ModuleDict()\n",
              "                  )\n",
              "                  (v_proj): lora.Linear4bit(\n",
              "                    (base_layer): Linear4bit(in_features=1024, out_features=1024, bias=True)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.1, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=1024, out_features=8, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=8, out_features=1024, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                    (lora_magnitude_vector): ModuleDict()\n",
              "                  )\n",
              "                  (q_proj): lora.Linear4bit(\n",
              "                    (base_layer): Linear4bit(in_features=1024, out_features=1024, bias=True)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.1, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=1024, out_features=8, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=8, out_features=1024, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                    (lora_magnitude_vector): ModuleDict()\n",
              "                  )\n",
              "                  (out_proj): Linear4bit(in_features=1024, out_features=1024, bias=True)\n",
              "                )\n",
              "                (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "                (mlp): CLIPMLP(\n",
              "                  (activation_fn): QuickGELUActivation()\n",
              "                  (fc1): Linear4bit(in_features=1024, out_features=4096, bias=True)\n",
              "                  (fc2): Linear4bit(in_features=4096, out_features=1024, bias=True)\n",
              "                )\n",
              "                (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (post_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (multi_modal_projector): LlavaNextVideoMultiModalProjector(\n",
              "        (linear_1): Linear4bit(in_features=1024, out_features=4096, bias=True)\n",
              "        (act): GELUActivation()\n",
              "        (linear_2): Linear4bit(in_features=4096, out_features=4096, bias=True)\n",
              "      )\n",
              "      (language_model): LlamaForCausalLM(\n",
              "        (model): LlamaModel(\n",
              "          (embed_tokens): Embedding(32064, 4096, padding_idx=0)\n",
              "          (layers): ModuleList(\n",
              "            (0-31): 32 x LlamaDecoderLayer(\n",
              "              (self_attn): LlamaAttention(\n",
              "                (q_proj): lora.Linear4bit(\n",
              "                  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Dropout(p=0.1, inplace=False)\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=8, out_features=4096, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (k_proj): lora.Linear4bit(\n",
              "                  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Dropout(p=0.1, inplace=False)\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=8, out_features=4096, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (v_proj): lora.Linear4bit(\n",
              "                  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Dropout(p=0.1, inplace=False)\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=8, out_features=4096, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (o_proj): lora.Linear4bit(\n",
              "                  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Dropout(p=0.1, inplace=False)\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=8, out_features=4096, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "              )\n",
              "              (mlp): LlamaMLP(\n",
              "                (gate_proj): lora.Linear4bit(\n",
              "                  (base_layer): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Dropout(p=0.1, inplace=False)\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=8, out_features=11008, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (up_proj): lora.Linear4bit(\n",
              "                  (base_layer): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Dropout(p=0.1, inplace=False)\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=8, out_features=11008, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (down_proj): lora.Linear4bit(\n",
              "                  (base_layer): Linear4bit(in_features=11008, out_features=4096, bias=False)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Dropout(p=0.1, inplace=False)\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=11008, out_features=8, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=8, out_features=4096, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (act_fn): SiLU()\n",
              "              )\n",
              "              (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "              (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "            )\n",
              "          )\n",
              "          (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "          (rotary_emb): LlamaRotaryEmbedding()\n",
              "        )\n",
              "        (lm_head): Linear(in_features=4096, out_features=32064, bias=False)\n",
              "      )\n",
              "      (vision_resampler): LlavaNextVideoPooler(\n",
              "        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc5dd652-e76f-40fa-9c28-23f60adcb9a0",
      "metadata": {
        "id": "cc5dd652-e76f-40fa-9c28-23f60adcb9a0"
      },
      "source": [
        "## Define HF Trainer\n",
        "\n",
        "To streamline the training and evaluation of the LLaVa-NeXT-Video model, we use HF Trainer class, which abstracts away much of the boilerplate code and provides a structured framework for model training. In this section, we define the TrainingArguments and initiate the Trainer class, which will encapsulate the model, training loop, validation loop, and optimizer configuration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "4ccbd183-f15a-4f94-a526-9ceeec3f61e0",
      "metadata": {
        "id": "4ccbd183-f15a-4f94-a526-9ceeec3f61e0"
      },
      "outputs": [],
      "source": [
        "args = TrainingArguments(\n",
        "\n",
        "    # args related to training\n",
        "    output_dir = OUTPUT_DIR,\n",
        "    eval_strategy = 'steps',\n",
        "    eval_steps=20,\n",
        "    per_device_train_batch_size = BATCH_SIZE,\n",
        "    per_device_eval_batch_size = BATCH_SIZE,\n",
        "    gradient_accumulation_steps = 8,\n",
        "    learning_rate = 2e-05,\n",
        "    max_steps = 100, # adjust this depending on your dataset size\n",
        "    lr_scheduler_type = 'cosine',\n",
        "    warmup_ratio = 0.1,\n",
        "\n",
        "    # args related to eval/save\n",
        "    logging_steps = 20,\n",
        "    save_strategy = 'steps',\n",
        "    save_steps=20,\n",
        "    save_total_limit = 1,\n",
        "    fp16 = True, # we have the model train and eval with fp16 precision\n",
        "    fp16_full_eval = True,\n",
        "    optim = 'adamw_bnb_8bit', # adam in lower-bits to save memory, consider changing to 'adamw_torch' if model is not converging\n",
        "    report_to = \"wandb\", # install wand to use this\n",
        "    hub_model_id = REPO_ID,\n",
        "    push_to_hub = True, # wel'll push the model to hub after each epoch\n",
        "\n",
        "    # model that was wrapped for QLORA training with peft will not have arguments listed in its signature\n",
        "    # so we need to pass lable names explicitly to calculate val loss\n",
        "    label_names=[\"labels\"],\n",
        "    dataloader_num_workers=4, # let's get more workers since iterating on video datasets might be slower in general\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1608aed8-d2f9-4ff3-ab88-c2d7664e9d48",
      "metadata": {
        "id": "1608aed8-d2f9-4ff3-ab88-c2d7664e9d48",
        "outputId": "8cec87ee-4110-4fb6-9adb-38afe0cdb121"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
            "max_steps is given, it will override any value given in num_train_epochs\n",
            "CODECARBON : No CPU tracking mode found. Falling back on CPU constant mode.\n",
            "CODECARBON : Failed to match CPU TDP constant. Falling back on a global constant.\n"
          ]
        }
      ],
      "source": [
        "# trainer = Trainer(\n",
        "#     model = model,\n",
        "#     tokenizer = processor,\n",
        "#     data_collator = LlavaNextVideoDataCollatorWithPadding(processor=processor),\n",
        "#     train_dataset = train_dataset,\n",
        "#     eval_dataset = test_dataset,\n",
        "#     args=args,\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "3d2acb26",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_190609/247565371.py:34: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        }
      ],
      "source": [
        "args = TrainingArguments(\n",
        "\n",
        "    # args related to training\n",
        "    output_dir = OUTPUT_DIR,\n",
        "    eval_strategy = 'no',\n",
        "    eval_steps=20,\n",
        "    per_device_train_batch_size = BATCH_SIZE,\n",
        "    per_device_eval_batch_size = BATCH_SIZE,\n",
        "    gradient_accumulation_steps = 8,\n",
        "    learning_rate = 2e-05,\n",
        "    max_steps = 100, # adjust this depending on your dataset size\n",
        "    lr_scheduler_type = 'cosine',\n",
        "    warmup_ratio = 0.1,\n",
        "\n",
        "    # args related to eval/save\n",
        "    logging_steps = 20,\n",
        "    save_strategy = 'steps',\n",
        "    save_steps=20,\n",
        "    save_total_limit = 1,\n",
        "    fp16 = True, # we have the model train and eval with fp16 precision\n",
        "    fp16_full_eval = True,\n",
        "    optim = 'adamw_bnb_8bit', # adam in lower-bits to save memory, consider changing to 'adamw_torch' if model is not converging\n",
        "    report_to = \"wandb\", # install wand to use this\n",
        "    hub_model_id = REPO_ID,\n",
        "    push_to_hub = True, # wel'll push the model to hub after each epoch\n",
        "\n",
        "    # model that was wrapped for QLORA training with peft will not have arguments listed in its signature\n",
        "    # so we need to pass lable names explicitly to calculate val loss\n",
        "    label_names=[\"labels\"],\n",
        "    dataloader_num_workers=4, # let's get more workers since iterating on video datasets might be slower in general\n",
        ")\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model = model,\n",
        "    tokenizer = processor,\n",
        "    # data_collator = collate_fn,\n",
        "    data_collator = LlavaNextVideoDataCollatorWithPadding(processor=processor),\n",
        "    train_dataset=streamer,\n",
        "    # train_dataset = train_dataset,\n",
        "    # eval_dataset = test_dataset,\n",
        "    args=args,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "ea64e3b8-bbf4-41ba-bad6-8afd1346f6eb",
      "metadata": {
        "id": "ea64e3b8-bbf4-41ba-bad6-8afd1346f6eb",
        "outputId": "fc872e12-094b-4d85-fd06-4078fb03f7a5",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/share/softwares/anaconda/anaconda3/envs/molmo/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/share/softwares/anaconda/anaconda3/envs/molmo/lib/python3.10/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Video features and video tokens do not match: tokens: 0, features 4608",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/share/softwares/anaconda/anaconda3/envs/molmo/lib/python3.10/site-packages/transformers/trainer.py:2232\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2229\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2230\u001b[0m     \u001b[38;5;66;03m# Disable progress bars when uploading models during checkpoints to avoid polluting stdout\u001b[39;00m\n\u001b[1;32m   2231\u001b[0m     hf_hub_utils\u001b[38;5;241m.\u001b[39mdisable_progress_bars()\n\u001b[0;32m-> 2232\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2233\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2237\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2238\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   2239\u001b[0m     hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n",
            "File \u001b[0;32m/share/softwares/anaconda/anaconda3/envs/molmo/lib/python3.10/site-packages/transformers/trainer.py:2548\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2541\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2542\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m   2543\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2544\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[1;32m   2545\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[1;32m   2546\u001b[0m )\n\u001b[1;32m   2547\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2548\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2550\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2551\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2552\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2553\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2554\u001b[0m ):\n\u001b[1;32m   2555\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2556\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
            "File \u001b[0;32m/share/softwares/anaconda/anaconda3/envs/molmo/lib/python3.10/site-packages/transformers/trainer.py:3698\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3695\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   3697\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3698\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3700\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[1;32m   3701\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3702\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3703\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   3704\u001b[0m ):\n",
            "File \u001b[0;32m/share/softwares/anaconda/anaconda3/envs/molmo/lib/python3.10/site-packages/transformers/trainer.py:3759\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3757\u001b[0m         loss_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_items_in_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_items_in_batch\n\u001b[1;32m   3758\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mloss_kwargs}\n\u001b[0;32m-> 3759\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3760\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   3761\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
            "File \u001b[0;32m/share/softwares/anaconda/anaconda3/envs/molmo/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/share/softwares/anaconda/anaconda3/envs/molmo/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m/share/softwares/anaconda/anaconda3/envs/molmo/lib/python3.10/site-packages/accelerate/utils/operations.py:819\u001b[0m, in \u001b[0;36mconvert_outputs_to_fp32.<locals>.forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 819\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/share/softwares/anaconda/anaconda3/envs/molmo/lib/python3.10/site-packages/accelerate/utils/operations.py:807\u001b[0m, in \u001b[0;36mConvertOutputsToFp32.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 807\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_fp32(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
            "File \u001b[0;32m/share/softwares/anaconda/anaconda3/envs/molmo/lib/python3.10/site-packages/torch/amp/autocast_mode.py:44\u001b[0m, in \u001b[0;36mautocast_decorator.<locals>.decorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_autocast\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[0;32m---> 44\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/share/softwares/anaconda/anaconda3/envs/molmo/lib/python3.10/site-packages/accelerate/utils/operations.py:819\u001b[0m, in \u001b[0;36mconvert_outputs_to_fp32.<locals>.forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 819\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/share/softwares/anaconda/anaconda3/envs/molmo/lib/python3.10/site-packages/accelerate/utils/operations.py:807\u001b[0m, in \u001b[0;36mConvertOutputsToFp32.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 807\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_fp32(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
            "File \u001b[0;32m/share/softwares/anaconda/anaconda3/envs/molmo/lib/python3.10/site-packages/torch/amp/autocast_mode.py:44\u001b[0m, in \u001b[0;36mautocast_decorator.<locals>.decorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_autocast\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[0;32m---> 44\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/share/softwares/anaconda/anaconda3/envs/molmo/lib/python3.10/site-packages/peft/peft_model.py:849\u001b[0m, in \u001b[0;36mPeftModel.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    847\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_peft_forward_hooks(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    848\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspecial_peft_forward_args}\n\u001b[0;32m--> 849\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_base_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/share/softwares/anaconda/anaconda3/envs/molmo/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/share/softwares/anaconda/anaconda3/envs/molmo/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m/share/softwares/anaconda/anaconda3/envs/molmo/lib/python3.10/site-packages/accelerate/hooks.py:176\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 176\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
            "File \u001b[0;32m/share/softwares/anaconda/anaconda3/envs/molmo/lib/python3.10/site-packages/transformers/utils/deprecation.py:172\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/share/softwares/anaconda/anaconda3/envs/molmo/lib/python3.10/site-packages/transformers/models/llava_next_video/modeling_llava_next_video.py:747\u001b[0m, in \u001b[0;36mLlavaNextVideoForConditionalGeneration.forward\u001b[0;34m(self, input_ids, pixel_values, pixel_values_videos, image_sizes, attention_mask, position_ids, past_key_values, inputs_embeds, vision_feature_layer, vision_feature_select_strategy, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, logits_to_keep, **lm_kwargs)\u001b[0m\n\u001b[1;32m    745\u001b[0m     n_video_tokens \u001b[38;5;241m=\u001b[39m (input_ids \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mvideo_token_index)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    746\u001b[0m     n_video_features \u001b[38;5;241m=\u001b[39m video_features\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 747\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    748\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVideo features and video tokens do not match: tokens: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_video_tokens\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, features \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_video_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    749\u001b[0m     )\n\u001b[1;32m    750\u001b[0m video_features \u001b[38;5;241m=\u001b[39m video_features\u001b[38;5;241m.\u001b[39mto(inputs_embeds\u001b[38;5;241m.\u001b[39mdevice, inputs_embeds\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    751\u001b[0m inputs_embeds \u001b[38;5;241m=\u001b[39m inputs_embeds\u001b[38;5;241m.\u001b[39mmasked_scatter(special_image_mask, video_features)\n",
            "\u001b[0;31mValueError\u001b[0m: Video features and video tokens do not match: tokens: 0, features 4608"
          ]
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "285bf5ed-8e17-43e3-a198-59e07ed6e3c1",
      "metadata": {
        "id": "285bf5ed-8e17-43e3-a198-59e07ed6e3c1",
        "outputId": "e1c7ea81-bd16-4279-88ca-05d6e1d107c1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/RaushanTurganbay/LLaVa-NeXT-Video-demo/commit/b81b02b023fd4ba5f2392da889205b0d50e99c41', commit_message='Upload model', commit_description='', oid='b81b02b023fd4ba5f2392da889205b0d50e99c41', pr_url=None, pr_revision=None, pr_num=None)"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.model.push_to_hub(REPO_ID) # let's push to hub the last ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "566e9061-486b-4a96-ba06-f0aa256e6625",
      "metadata": {
        "id": "566e9061-486b-4a96-ba06-f0aa256e6625"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "b5bda0f9-3328-4dd1-80bc-ee54f3e032e1",
      "metadata": {
        "id": "b5bda0f9-3328-4dd1-80bc-ee54f3e032e1"
      },
      "source": [
        "## Inference with tuned model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76dba71c-b540-4035-a386-5c09d8b74ecf",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "d997ad73e8b4487f960e7ed1a438e722",
            "fa6c7a28b7a14799850a302a25397f49",
            "ae47cc26df1a4835adb5bde6af9a41f2"
          ]
        },
        "id": "76dba71c-b540-4035-a386-5c09d8b74ecf",
        "outputId": "d0c8cc83-b8ac-4e2b-ab88-e685fd8b589e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d997ad73e8b4487f960e7ed1a438e722",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "adapter_config.json:   0%|          | 0.00/884 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You are using a model of type llava_next to instantiate a model of type llava_next_video. This is not supported for all configurations of models and can yield errors.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fa6c7a28b7a14799850a302a25397f49",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ae47cc26df1a4835adb5bde6af9a41f2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "adapter_model.safetensors:   0%|          | 0.00/84.8M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model = LlavaNextVideoForConditionalGeneration.from_pretrained(\n",
        "    REPO_ID,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a90dbe8b-296b-40f8-aa6e-7d9180f71434",
      "metadata": {
        "id": "a90dbe8b-296b-40f8-aa6e-7d9180f71434",
        "outputId": "7911d338-ce01-490d-a278-25f4e265a855"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<video width=\"640\" height=\"480\" controls autoplay loop>\n",
              "  <source type=\"video/mp4\" src=\"data:video/mp4;base64,AAAAHGZ0eXBNNFYgAAACAGlzb21pc28yYXZjMQAAAAhmcmVlAACV921kYXQAAAKvBgX//6vcRem9\n",
              "5tlIt5Ys2CDZI+7veDI2NCAtIGNvcmUgMTU1IHIyOTE3IDBhODRkOTggLSBILjI2NC9NUEVHLTQg\n",
              "QVZDIGNvZGVjIC0gQ29weWxlZnQgMjAwMy0yMDE4IC0gaHR0cDovL3d3dy52aWRlb2xhbi5vcmcv\n",
              "eDI2NC5odG1sIC0gb3B0aW9uczogY2FiYWM9MSByZWY9MyBkZWJsb2NrPTE6MDowIGFuYWx5c2U9\n",
              "MHgzOjB4MTEzIG1lPWhleCBzdWJtZT03IHBzeT0xIHBzeV9yZD0xLjAwOjAuMDAgbWl4ZWRfcmVm\n",
              "PTEgbWVfcmFuZ2U9MTYgY2hyb21hX21lPTEgdHJlbGxpcz0xIDh4OGRjdD0xIGNxbT0wIGRlYWR6\n",
              "b25lPTIxLDExIGZhc3RfcHNraXA9MSBjaHJvbWFfcXBfb2Zmc2V0PS0yIHRocmVhZHM9MTUgbG9v\n",
              "a2FoZWFkX3RocmVhZHM9MiBzbGljZWRfdGhyZWFkcz0wIG5yPTAgZGVjaW1hdGU9MSBpbnRlcmxh\n",
              "Y2VkPTAgYmx1cmF5X2NvbXBhdD0wIGNvbnN0cmFpbmVkX2ludHJhPTAgYmZyYW1lcz0zIGJfcHly\n",
              "YW1pZD0yIGJfYWRhcHQ9MSBiX2JpYXM9MCBkaXJlY3Q9MSB3ZWlnaHRiPTEgb3Blbl9nb3A9MCB3\n",
              "ZWlnaHRwPTIga2V5aW50PTI1MCBrZXlpbnRfbWluPTEwIHNjZW5lY3V0PTQwIGludHJhX3JlZnJl\n",
              "c2g9MCByY19sb29rYWhlYWQ9NDAgcmM9Y3JmIG1idHJlZT0xIGNyZj0yMy4wIHFjb21wPTAuNjAg\n",
              "cXBtaW49MCBxcG1heD02OSBxcHN0ZXA9NCBpcF9yYXRpbz0xLjQwIGFxPTE6MS4wMACAAAAxvGWI\n",
              "hAAQ//73gb8yy18iuslx+ed9LKzPPOQ8cl2JrrjQAAADAAADAAA/yP425VR62BLgAAAE7ADZy//E\n",
              "Y/K4ACvgUNItcrm2vXdyPQ33PzKkTM7xM0rqAWnHDJhVFhbietpFdEks1PY568bNHEoLuh9lt7ty\n",
              "aQiWK80N46Y9cAmWgSM4PmP5W9/UH3J0ixVO/SrVz9gwBgDDgitOUNFIX9094CvQ8SsPBND6Z3e6\n",
              "F8l6cO/sl0tgR5IvQW1AzIYHPD+Jc955A6J96y38PLy5i2642qEmm5cCf4HpMJoFh3R/h0w+Gmf7\n",
              "spAuKgdvq6hwMVtgPXNVj/h2U79CioEJRoJdC4ZPZqmfehpftiTUaAbUNkHCRH3P7HnKaUR2NcGF\n",
              "Q3Ffkz4YuF7ckdmlC5siAKaJXIX1pLDkGrajp+EwzGuJ+siF2wejQ5Uz470p4GmToe3W3usPd6Jc\n",
              "UelS9TGObikefqxs7ZZ5n6g4KN8leIFM2UG4LZ60bGCZdZkZafE5APDKPTy53V1h4PImhI74W2tc\n",
              "/ojWTvy+buUVVJhfIMLPewTkDqca29/o9PhFLgoAOKQ0V/LuF/ZvfezmjU4q0To0wdzpOmtiRW21\n",
              "moQY1pTpOLqV7LELSVJ1gzSi59aqFfxXRZ79U/T7n9WTzNx1mPRIT3pC3eAqDoLgsqU5XjfLr/q/\n",
              "AeOBLkwFZccz16GTs8s3iNxs2EJjDy3IGKc86Hx9xSuVZa7fXM+/09gT3M3P8pXwV9nt8udQ6ubF\n",
              "XF1C5+CRVgNnfkm7Geqg+3C81L5y+C51iuVAum+sA835ccgE+KJ9EnKIVnTsA3hZa9ze6cfxe5kA\n",
              "C1k+Usppbmf22kL03XCXGWC2dJvGfL8crX98lPKbGzNIAGps6TY1Q3kiqc/MHi2DJFv88Uf8cNC1\n",
              "Tk9JfS9NaWd9PjfO+LGH/5K6eNYBJR23EZOoedESHMZynT0kkUtYAL4vBFcWAn1eT4AKJLZb/xPU\n",
              "KsmJWu5gTaRPyTqBVnva/KLSlu0mupi0YFHa50AdfQg4hQXlQt0tdKjyq1JecDEwiFhJ7QK4dm+8\n",
              "ZJIBt2bnTAKJo4NKAm4zr/5L3OUhuUtZWnT0xyINlmwjBsDpbHiQ9L++BQafP4WF1MpSp5l92fza\n",
              "4x5cPl+QS2jqysnwGNAkqk1EMLPKwuQpbZG9TPzE7FqORga1597ZDkoqdxroLBDCPJONZ0Q7moEY\n",
              "VOv4sOG3HfC4k+NB1iiA6yvndTkBDuXHW190QpF7Z10bXH8mbvjyLemfenfNksuAghWo5VyZXhW8\n",
              "rayqN3cRh2GYky8Vxjcpb2Va6VVH47lFpy5bUSr+edYBZiF22G0jNiBTlYKweQp04gZgeZVHbKiA\n",
              "lEQc95rsRpJa0pZuHSBcEaufk94mEowijvh0nSRWFfEDhaHi9zETUogbINTXRt8rj8ceu6yfuYyz\n",
              "5TWrx5SlPGmGmsWkfsBTgc1TnbqjHDdmfYxx8jvpVjSSKbfQzuAZJ9pybpKiGwjgug6yQfnOR1Ps\n",
              "MulAvR4jB7y4qxKYeocDHIMLSVfT5OYfCSaoPQrgspzQxTkj9VN3LSg1j5PhisUuR10TCBw2IzI4\n",
              "L0+vgwk0Bzg4H5MxYfj7bElSDRrqqEHBU3MvQ/Y8Rinou5TyeE6AyFjMpGEMOZQHWlKvsnrJLU15\n",
              "fhCV41G8XRIJX/hZuaHp5bG6EH2jsX56//KK89Np+fhJdlYACqo0Sc6HQCCxL6PtxtS12dsXBKBx\n",
              "TwGm0yDc40i/OxCBKtT9qRC0re2DhmNEY9Iw/qqZASMbtmgFYPKqU0ks5XBN1qP5aPVv3XQh0jJC\n",
              "hz9UlhXf3y3YgEMJL0cqNU8NwWRsaU/1dYtPfV8HQI4XK46krBFjaO+G1qfP69RHJk+xFP2aENkf\n",
              "k6nogCaG7AAEdpVDi3VpwCeYOuYkf94y6/Z/0BX8ktbDMAMuYCkie5dpNy8fOZO7JFHcm5XLwMhy\n",
              "rSB1M72qHVZp8hW83kSi/D4M1q1qn0bUesmowkyNXWbvQ+Ej7B8MMHl8LwefWIL9Y1JPWr6asBfv\n",
              "u7dwVhfBPY+gT59Sof82wCnfjTkDVDiv5LS3GEH1aStN+hIegpfP690n9qIw3i8XxF/hWwZ+5+XH\n",
              "jv+HAAu84gMmrPDigy7I58/7rQ+7/sizi8oJ36hSo8Jx9FvsAEUNVFnkm4ucBSKvBZaMqTlpIX08\n",
              "u/6TWeMvD1UP0vVh7fbxB9www7JNjSzGkDwd1dxRKRo1LU8DF95bQm/313tmI4XT7HKB8S2jWKMr\n",
              "BpyWBVQck0IH4vBWT8j2rj/s2Ap6zLF375Y2lNzORyEUW8uC/pFtfyxGx6AIlIvZa+c9zHovxyF2\n",
              "AOgxcQPsWhgOnV1OGJBHk81v54iTOiHnRKe5uhb2T5Vfq6sJQTIdaPMVnV14RyqPrcvH7rp3hDHR\n",
              "+MK93JXbMaGRR6FQ+UTrLU36Q4GSUSE99FBXyYX0fsvejxt2Swos5+Du+LP8Y0WmjyFXrHa8YD4i\n",
              "0i2eVTcyYw7u2tP0zDAiQSIshR/3y0u62XcGMAmgTGImi6GlEnTzdvUzQDake2QH7BODBNAUruyx\n",
              "K5hufSymJFy9Q3W95YOVLVtcw1QN2nLTiJOrbinyuATwJhwTqJ5XlAkmjV4bSlknOtGodMVNILMY\n",
              "9RN6ZEGJxE46v3sE77/EuAea8M+O2FTCTrDHpU/WFZSZaif5MTMc/jD69pPhrfXFkucseGMacfhu\n",
              "rQAyM2RJSMLIGUthVOrQ11wyYBpICym672TAGYceweohklBB/N9XSzBAwcWbbCsyF+7MvjbiMcv4\n",
              "gCIzj7UNESLWfpkQVd2z1JCbTSec3eHZsNuJkix9OvutVqtAnexJbCDGd9igojdLAj8vg9QkNOIu\n",
              "C98g6Qrm2CD/asePUBObVLgDxpqm+yvcjoPgokgKT68E+Yt9MpOlCaNyivpd+u7RHsMdwQ+qVHsw\n",
              "AIAhhYYAKbNrvbDOfh8KwNb29dMg2k9ACwDaYpZKXvY/KLGiuXwufAKJ70Nm57qUaTe/5o6Jz8QL\n",
              "16SvdmB2azULoR/HD5/5YgkElvTfivkn/O/nNZ9Kl/i7uakHRo+mVD4wV3hdkVMsXec8hPJpEKuK\n",
              "AYlPoZACJhWmLQba7X+B6GKTkiH8ayRFV9gmKwDV4DEkhhe5RdnRRwtlfxY6yeMIG92op/oIxYeP\n",
              "m6c3ELf91U0v6GbYvzyc+HQH80ds8iX1ohoBQMpsca9qliyq2l4hwehIBBeEijodyQT6Xc0HYjvX\n",
              "zd0Ch9D7yekGIP8qeTJVRGcGAgIw1Mo1FVP/pCXKEC+bnhcjm7SOLNplwN4jiiFwTV2gF6w59GLJ\n",
              "3UKW20z9wPVOPzDX53pAJ+Qj9zFKaHQDZ+wozQOQuHhUK2oIipyzXlHqdCEkVHVcJ5FWxdrSgknK\n",
              "3x06bAlqyZnAYYntyoMps69qurtEcXatBA9tngGbqzhH6317nKL190EilFthvBVPX1g/pjsNSBFt\n",
              "ocAf9Jb2HZpb6e2nG8pzUZbvEHcBrWGD55NU/bcdFC4KYVES+RC+PqS7o5qVHXSkqtz9EQBeahLQ\n",
              "nUB2v9vPkZCr8Ahi1ctt4yPp3cCvr4N+faqmSLXzIvoauUJzLW4PNlko8NNWTFp9w6nYPwQiChos\n",
              "ewZkD+tw/rJS2SxpT5gt+ZxBsSiDKm73Z71B2SlvfUiMJ35Wh8xJVFCSvhJ3YN/IVnIxtu7WmS7K\n",
              "LMAtUL+RlvDWsa0GKRbV9WRKP0vqJ438rwmyz8LBjtzupnBPGpnHfngKpjIJb2GyL0PNKJYyyzKv\n",
              "50kCPzpzLPuTSpDEZa//x8vaqVrAAdyMinZ6XcVA/kozmkw3KSv66zHtlPqnSce2qSGuUimk0q/Y\n",
              "mL9jtGhFj/zudoUfam3W1kiIGVafuSHCVE3VvAAACfyZDih/ZZYYMIA7ksAfGJZgcSHFWgs+nj+x\n",
              "ogZR3pKb3JVtuigDDrmPKuSCcrVHxgEytsH2FVYVyL6zS8+Bu2e7Q/yKgNl8s7YvFHtFF1m0lzZX\n",
              "0rps0xQdNDSQg5KVTfm+5wi7YCadGntjvcm7eezm/f/K8LERdVaddbYAIKUu7chFECBWqRAoDBvX\n",
              "4I8PexNJ/QkvlD+HctvRJZXua4zO69Yvd+bBP0njJdNSeGu9/8R7Rxnm5eSnVfvs+iOX9SQDMN/0\n",
              "kFGd7QmEFRIRdSeb/ygfCfb0dC9zxhiHgfsa6spX5kPZnZSTY04b/4ji54w/CFhF9ZzL8jiagSJS\n",
              "btpBZypsQqSFrQAGmNW2C3e+1yNW7rnY5tAAMoe2/XRNbYpjr+XQrG9SpuNJXpjras9XN99OtHPM\n",
              "ySBSglfx2N/U9DPvXJIhz2ktLoAjsxajTEqiQjW86WCoGsF/UD6doOr7UWqbfMydz6kjAVr2PzOP\n",
              "Y2+zwr4m2JDDJA/eA/XwJ8Zov+C1Y7hLMratne6L+9PA9mVqO78Nogrdu7L7PcjU94qw2hz587wP\n",
              "1cL6DdZHj3sXzoMCpXxWFuhBtfl+x6LLyQqh8VBPT3duDto4CJuzuSB/PrQ6SuyB4B7o5pjYStjO\n",
              "nkUdQjdIfj+Uf2jMi4+QVUY+ZxHxLU5cmYd/CqPGxBXTT56pmJqbzC+QoZI+CHfRmP/bLyfqCEaa\n",
              "pmlmUB1C+EjFiqHIUsrYAew5zr2DntnEo+K8h7PVSxIbGl9x7Nb/t4biFLZa0TtP+gkKiWi4mdMx\n",
              "vWboDmUC6Yo4o94AT4hf8oOrtCfImAGackGaxZVFha5KFhefmGxEJmjNaSX0NSoSBJWcB3DMrglm\n",
              "a6IeLyvYQiQW7hrPjQNxMs+0fFyKF/mIf9esffIBQYC2/u50uWDFPdLhoaRLzbzN+QYFO1b1lW2b\n",
              "AhK3hfNgfjmDlhCg52lNQCI2lDoPfDwayew6irPmLezr42FwWpR42gpjoO2KJ2AF2nNSLapHy517\n",
              "fE1OGyzVHp/FLg5Q6uPX2U06tgzKTapLzn4zStZI0Hvc/aeZqqvzVRt/5MXDxazWMA9TwFgIfjRo\n",
              "6xHTghygxus34dobpaXS3KE2hqXrFZQv8rdwrCKduF7mzjXCqCsOK8eCd9qegNa5WxMgPs4o0niK\n",
              "U48l/jzbP+pG+NoQXS7pz6OZpE0PHw0gAAc8x76LfLAqWCVw+FhcOHnby8OEOqQf0WTTUe69N4sW\n",
              "AEbm+U9VsyaDIdqnJpjilnNLN2oyiGAg1TPu4rmcexgGsAAew9emkanwvVedIiOy2jo7DrL9RsDm\n",
              "RnF+tCbjh7uF6EpGtNE2akhKIMr3bgjqsVyd3TF1g/CjPA/FKsXifOwJrucFXfFUeDYeMsPJ+v45\n",
              "8zPSOwYpnegmOYBIHYOkT1jOA/ym+LqSWTIlJSMh1G7IE9cTRYuTGNVobw+n3ze+lL5uvedIgc33\n",
              "Ebc6797HF9GLkJ2jdvNheI3x6ZprPL2x/zJiVbpcAmgJoUibe0n2ttDZU3Mz8EcT/4VlMkY/12t4\n",
              "LIQLEtzS1fyACBqQ1qLyrmRQGm65pfqg5UO4U8HDu4soUEOdwoiosji+YsorsLvJB3KUvp65I70a\n",
              "Mo5+f+W2Jxulc3IzSE3PtqZg2LONs+/Y6H//MsRh/INX2I53oL5w0M1BcMai86BiUTb5AAAaP5qv\n",
              "JzjVbjfrCsRoDtrG/iyaWVhiWpBkmbkgMnB9N5mClh734hihc1XmKNMte2PxgVBLQK7Ub9oDQvoE\n",
              "GWmnKpjLAtR4NkiKPBejoQRHrR2O5bC+hmuxxtoyBI4wOmslHue0lXQXFpreZQBMC8S3TiZMEpmC\n",
              "kk4/eCQhRHsbuEbwdKbhmzqJ+EQy73Xb2YXhRCQCMgkMHzp1yxd89uCrbGuLg/nQPB1Enx3ktCWZ\n",
              "6UHxg7n+UrVqPkrOpvK2H7stYzsw+eHo2LsaqKLRUtxrKfsHNiNQiNzOviSPJgDwhRmEV0aVCrra\n",
              "nDayQxzN3HRh6oBxTyY5zL5YF2+6TbY3BpW6FFh4+VaUBwt5EVXy6PImJie6TNWPwrmsaTbfqe2e\n",
              "RlMmSBwqTwDT3aiJzTFRgjOap4SO89/Zhf6XaowXJBhJ8PrW1GM2+p5uWaeDj6u1sM2k5+JpGPi5\n",
              "YfgmD9ITu5x0thtD9FIY3S2e/O9IhLo8qZ1cPu5wUoIzLHmpJGNa+3XmEtfjhZVhZvbF+E3GtWlo\n",
              "tNGJfQLs7ARuYnmPiVr9lzBkIJRVm3J/4k1w2Tqi9Il0dTMSivtWbYouvOsxSKQjFpt7yvYhouhT\n",
              "TJW0754/9ZzCfTarDnxUIPzI5eYJsLjnnfdVdy9nKwDYk7dj5UI593r85Rm+pBc9u3VXaBqIzLtS\n",
              "wfHMpsSOqAgkSwjOekJFj5Gl5p5omlYG54H17F4esCRgVoQWMtbxY6dtO2fATgzUnNFZXg/TOebR\n",
              "ohYed9yDvoMBg2zqkAZCjZxdkf5sbYdn77qjSe4lHhT50LXvI1Tm00Qag6Nqv4vJneAB4pFpw13v\n",
              "P4zxZrOLmhhTFOo/DwlXH8TvRdwG5Gzwv3pdBOgM0MMNgSMjUEhvw0+ybFc9ixESqGZAFLAVfLTa\n",
              "QL25PXmsUByH+cmgm5zBA/RbQbDrXadEM74143Rt7ioYfXV716OLI9h2TCmFMfl3l5xTLoHfJFqM\n",
              "wzKM/Q62TXqkHz7O1dKiQA0a0iD4Jog2YbZ5psLIEEa0OGCl0PVaz146xN1eiDCaYzeCrWG4y3JI\n",
              "2vVj+fT+LIzS4oIekpMYsElmDylgeHd4ZdP4IeOggffeI7GlG/UC62LLbVH7GQdiKCvMCD6SIWiV\n",
              "5iX1r7Gcc5pjIuVlR/vn9FkQR/INumwfWyihCFD+dSk5RY+948ocC/Bbq0tSV3jR0oOoqijrg3Dx\n",
              "SMmxpQtoTWlpBRupXS0qJ+1Ih4Cw305P8T0qzzr4+chpQ2w96McIRC+KAUnxV1o6LcF8ne7aXrHf\n",
              "JLDg9RTvyyG+yWhsqN68QX5wQ4GFea0dPpZbN8l90LuGSA2cOoyAq9Wu8YLhA1R+5MEMr9riSSZR\n",
              "dj8fkhuBL/STHAnMoxpFxl6hVSMeEA0Q3F+DkNSqK51IFXGP/fuOqXekMRHYtQuwMcRnO+J+0SyM\n",
              "gzoV+HsrRODCcDIMKOCBPKZr3o+jJiU8BCHraSuRzPIPzsOavIR9UKzhFgKTt6rl8IQVZ+i0JMbw\n",
              "XRl6AiNIF0RG+I21h0HIjRHC1xjEDuArhwvDQXTGWXjon0U+hEMqLbnvzqw1UJomT62RO4oqWj8j\n",
              "/IGllphp5Sy2M5VvFYndJhVdLLeqLyYjLIFfTskIu2u9g3zdaXpvJRI5tkmckaxXFSLoLgmH6iTP\n",
              "1HMxtPcLlqh78By5RiDE6ut/xttViSayjEQrebcTINJEnAODJDHw1Csn0Vipwxea/r98iAx2KPHv\n",
              "MsTw1Yz8Z+GO68aTl+M9qfytDv3KieV6kRt7oGQ/NazbsJMUz4ZgoRLG90vAw8WsYZEM2vhDvUKM\n",
              "c8Gh/XAorYOknoKuHFhf2iXsrjrVbcghUrCFP9JyOB5UG0hpkAWR3cJg9M824yDjP4AdftsYL48B\n",
              "SVA4AHEfubAZ4CtKr+oSvI/htdPDgZMKC6GCNjgvtOsQAqpNi2+FB6KQj0TJpH0q/KTN5dvNx65V\n",
              "RhNkVym8jgcKJDsFxlyXJO/NiJ2oFUTqB3L8XU/hHQ88UGEmYAyoUd7JqHYSIa3+hx8wdPCqQq7+\n",
              "n3szOul73197MUHPuykoxgBKVq/vpf4r5dN1hc75oMZ9mDatrZYIuC1aCXEORnpspdUIKu3f6+9o\n",
              "nAXcxcZWXdtYA55dacNtQQIirmCorP57hmc7gkjfVOgmlVVEQvxqa2F0SI2NSMol6IP5XuJjVsSY\n",
              "LITNBgp1xCKWYOCaNi7jDPgu/6I0g1Ltnc4C333LwTYG+eOXlAslNajw1aItNhHqQy3l8XAmDrGV\n",
              "ufD1GB0NHLs6243d4kaPV/hxXrWGJEeKLKTNyXtjRh3YqmtFtmKNGYshZxYbb1C/5CU7JgLb1s0z\n",
              "+8OFIB76OHvYHaY7qIXc31e4FgWZz7oQaEJP2cg9Mo4KPXYN1xA4864+BTjTn6KXDfZ86Bj+MEmU\n",
              "HOiIXADZIWkSG30A6U/jO0JGL0f56ApUNjWnENAxH4uDMBi3P6MgmjESStGQx0cmdbGRXQN0N0B2\n",
              "gD3XMv7Iu4fo2IkYNVTELsVdtkSRhd4LDwkN3HriGvYFEqeeLyqAzE67ICJTUc6CjSStudgUXB2F\n",
              "vkW3QHonAdJB+M1W88Bw7lwDHmJjL7cnN71A3ZSvyc/sn4p80AIxoT7I89Bx0dfQ7LyLmwCAKU2j\n",
              "fwOHihq/f/bmeSyhuQbSjdqwQY0JauQx3ZjJ8HTYZWVLwMCQeUKYIiGO9A76Vv4aFcLvHLKqtj0h\n",
              "D+cYoQLIxa8VUgOcfYbDR1rkasCykiWOSCL1yclVVwzfa/Thu+V3utavJtSrqoeFuwq5tquwlE8I\n",
              "tWY2SxCZB6xtyBVmgZqFRUbcP4nxJJQPxMEzF/Yw8AQtMLZsb8X+ztYyP+AxrgRMmD4emzYFJdvA\n",
              "vpOhCu+U3b0HrF/s8mtCLP3ucX2iqZmsAlptj30AelHAS56yMLpPUjdvBhGs5ryOWSom9J5imfOX\n",
              "doLKxtEeuMdNgi76pt+ZkqKcBChvcN6IJz8dac6atcGA4mjaYB8gG3cuK3YAAp+dGIvoaePSTk1g\n",
              "BTXp33DbCNCBXAcdroaGc8FSoGixOPwyW4ylu1pKzQRQw/TzEH7Uddl3I/ov+Jr/j1kMn69MKcFh\n",
              "+zfNcGHlQj/F5B9afzvK+1GQQAwvXaFqzTn61s+Pw5rze91QMsdaqSs+AwLCR9vM8Vw7PHnNqSud\n",
              "e4brVsTK7sBmY/jybQfNIb2bFOn65jNR+EPXyohxJik69mA4zKza/wRVRvIlwfa8uoUPH5NNbcEU\n",
              "kwlY9gayg3WtBWZtSvwoy0bcoSrikiaV+vUbjGR40f1nYUoYS3aVsuRxep2RiJORajJivrD735Z2\n",
              "xi2qEifkgTNpdyEQ1o6sSVzlxPukva8acicbrG6FuWWp+BakWUiNeX9dnPUYIS4AERm/QA8ffnRt\n",
              "v6ABq6boElnQx4D0BdKUY2nyW2wvgxK3S13APLct+o093l5x81MlhsfzMmH1ssDLhAGkEDnVp5TN\n",
              "vAK6fDFv5wvk+4fQ6E5WwvumZ0yRQbeD20MTsMIll/yeZb1/w4NMmsYtHKNqmnwuvCceVL2SBqL4\n",
              "Yjbhvhlb5TH+/ZfIXeyv8z0Y2mS4emae7bjEJ2pet49k58gPGeSBtWIZlS3ij+Kn2sjHezn4xOwW\n",
              "HR8SfZAX3EgLbZI3k9k60nf72pKGhFDTaxQg3Q5YLTlmW+U/of6j4KDnJk2erVVkqXyWqYz3U6PD\n",
              "0uwJcFC/MvgqMJiPFkKgh94sITt1GnoI/idymUrJnMdtd+1VDU4+11VIqjV0DDoiRviWOSoppBcY\n",
              "EJBb2yqiYcP5bkmezFfm1MLmw8J3BO704r1VH4jvzIYbcgMfuewT3I0Weu5Z/kAhqoHtCIVpLIMh\n",
              "5jwLQ+ziLHCZQVLbG7FdsppukEkiT80vUz/84eFk7JWslYAmqmnvQU0pruJNOghkKx2e3vjijSrS\n",
              "+bZ7P2xOjWujsD4DaZwqrlC3kDZhsYza+fhx/nHWbI2jasZOxia29ThH9X+uVYEbmuN28AoYRe2V\n",
              "BFo5BBCyUxiab/NOfU9PBE/dmRxRk7t5fPyP+uxII4ITiiKmtaBZvLjmdUgtt1PLFC/5I5Z0GkiO\n",
              "NhckygiULIdcyXGufXFNPBlILPWKJRa4QcpLzMxrvGydr4/gejcnprJiBPKY3qEsoWzQSg5htjnz\n",
              "DlvHR/s7Vq+B2SZnJAnB2sriuFl/apcgWEK0/CuVeKTMgfEnkLalIe2I/KI6IBbtFWACsaWCbRyO\n",
              "0yuVxvTWOvLZixSjxpBmY7vLX0I7KRuAetZ+bkdONgS/5CxeLaQh3XAx3+hq0IqNjAIXTLz8pbqg\n",
              "PKc18KvVwy/AMCR/O404w+rA/U4n1YJksHqvRXCxZG9KQUCPo4lJGDrG6nVVXomwCBqGyKlay0J9\n",
              "mfQNaPapzEawqVq8m9Pudc+WMDdzRstLNYw1jB7O7yyW2Izmh1wHrc0HxZZdoVditzLEq7qW8gx6\n",
              "XQIawfnyeI87VtpUrCDkdEpUjnDelVr0L2niUhIEC1bgyTOFA4n+07wOPYdatVOtg7epKt8zSLWX\n",
              "eCAOA2HP80IrCGYZU8AG6yA4r0UlHrjjDLtSr6n48StUNygT6H0wZ4xVsrR+73ixhps9ZPBVBeTx\n",
              "BgiweNhoB1FYN4M1UCtExT1BhunlCLcr4wXHZNx+9Cl3HZzoNHy1v+V6vfsUosTmjaPkYT7drp8H\n",
              "FR6q41bJsCgKmnZiXw5qsWCd8QUbGRpiTrssus4MAFLcNJBlh6qI75ZErMUZoHsR9exnufBcNkMX\n",
              "K7KSpq3NY/A/3Qgg4hQSjSogaDXqcRayvCQ9t1nOEgnUxaoUVKJKjcCj6b4XcZAr6k/v2hVqWaXC\n",
              "s0RZI6HML+x+2QgGJrES+lzlb6b6y1snwqHnkNyg2oO3PC9x0CHdvfqjGRq/6gNs2C4+5yw5I6fg\n",
              "dSpXx1ksUvuyMMRztTTm/qTTCMrtljv9DSYI9mt7bheAcqH5j3cFUJS5fWXd/sqmzflafYzIREEB\n",
              "fE3RnfcM7K5SGmsY8ZEorUBPLgCMWyIUnihPr/cxNnNNqWAFZPGMj9hsSvp1LejOpEOeOAhKbWP2\n",
              "8joRZTQ93z0XttSPAc7KiIyVQir6Oy4fByym60HPwGKpUxF2r3BNdNpuyLgAKXvNNS3PnK04yLWw\n",
              "zaipauKqhaioF0e5/Ple8hc1mmp2Cc9qci59glg3pBbG8gapYeDi/6UHWY6ek3oRzuhCPjYrDDAo\n",
              "Gop4JpJavBaAKLpk8rN+CDGC903eT9ZwbX5NXNZVAEI68LxzvlFG00/kn4DFOd3Tl7/B598lzFz7\n",
              "WVnmRUvMS6qM/ZvnljkuIiFYlA4poR5qIrr62X99clT+2DRkqrrFeGOWc/WK8p4RnXzxCpI+dGpG\n",
              "QiybPtH4J3wHmpuaxphF6HFzlC8Eo1gJWQjbeYxi+vQfr4E9pbk+MQIVvhlj1hRF6QYKaO/6+J3g\n",
              "gPs4TiYVFYTh31CprCX1Q1LGGgvyKsz0EjsfEgObKSkF+0uTDZ2vZaALzKtXefYLuGFoDnzd0Zr7\n",
              "qsRPPlzPfJIlxEXs4DgGY2dlb+lJRg7uehLrQa3xTfOTkfSAWBpEa+gXz6UTniRy3j6s4PJmU3p+\n",
              "d2wtrPDunhR/eWtcxv+sYF1gmzEA5xsNRkPPyxA4f11czwvUNsG3uRcjDfoBSOJsU9yZK6gRRhVo\n",
              "35BnJIOosBvV/vQ7AxrZZ1BgEeDVU7p0t+hNQRD37kgg46u6AgBKMvtSVhK1dnQvPkl7wNBU7fG8\n",
              "FBIsy4X/KV6vAIv84sj/p3gNDYKE0g6NBFJShA2ZOpfcxh4YdYm+48p3pYUr3VaWzjQr5L//dn+x\n",
              "8/ARudOC6NLN2OM878nvQ/W2MTwKlvERKhhsoYO6G+cWuAOOZXXs27CKNPvl0hAoWIXzZlPyHftD\n",
              "Ylh8B2WrL/HcVA3ZJbpy6PcgPJVdSDWfbjng3zdtxxD+K/TQOqz3mefcoNst78E5SoG01PkhMhQj\n",
              "Hn7pfn1+Oc9QhvUYdZsOXT7bozeJOf2AYiEZXY5IAgncPMV1mjxKALAYUAN+sVR3tFlmiLsjNRwF\n",
              "0lUmytX3IVjDyvKVR0wPARQh7ZRvwp/ehQxZYBdG0goFi3+KljsddEO0r2w8SV341Cgt/BmJgvkq\n",
              "zvWvn0JypGCXRqyNOXtsbhOwtWf7GXxBiFBT8M1yFKUFUU4n14xaKuPOIxNrGtRykqhlgVEKBEf7\n",
              "GerbB4I/vdBZ94TsKUgpxN+0bIP5P74Hhxc3HSRCaJPPUhLihhV4N68F2ZcxYhuLfg7H7PpIVLwX\n",
              "Rx0u/AgeeD5A9LSDq1n/aTDD99Zyd9QF+XP3z4aAuNITcwP0+0ItJKGQTNFi5LRusmvTtPn1IEDj\n",
              "HKEiX4JZ8B6Wvtn2SdUC7whK0GRvtVl1vgu43Rlgsfb1mDox7FqEbBnoWV9kpcDuJKnVhRBOPy13\n",
              "vff76Prwm/XePpPq/mnuAtEyAWUgOwXk6716sNB1YI0WuCWoXUgQKbPPljDxeTMl/cXb7/lLhDex\n",
              "mfgvQaoGIFh9wT2ITzplLsbXsfo5891H3wV2IhOKfM7KSkGfgDJQSWQ24kDPSo0Sr+4TiVBnttgc\n",
              "VY91aA/HbpB3yoNrkgM0BPgCqbzFhF52E8rL1ZirKXiMw6Egwc9Mnf3FAYsHEQgGn1ap6X5TkXyC\n",
              "aMObx9ZwIY5RndGcs4+sW9oeynHrVUhP9XA/a2XI4ddeHzYEzsZI2X1TFA0XEY5AHRHXpTXmi4x3\n",
              "Z1LV1aucqf1OwqGcwJT0k9nXWijhqRaEyfUkwfyZxhtSuW6tv6MIB1JZXkug0eVfoLGWlNQqFye3\n",
              "AOq0qM/W8r9obdxfS+4iKpZP98U9OGzAlvlB3+dYVKyebyhiyaEbqsTQ22iS2/C5ajGREU8nqxc0\n",
              "OQASOdYSCj9CqRWMSmDA+JxuGVZjLKeXJg/W+ey1W/wU7LK1eyMdCs/xnYq+7/c2dbVY3Con6/5Q\n",
              "rwpSKNx2FthZ3uUOSe16hLS3caOnihY2NAUJjjqgnzOcBYMuB4CV5hHqZaXHhifTTIRkmlPwvK7P\n",
              "NrsZPdtbmOq8qCNqo0j95wGWszfCDkN1HE5qTen4NOJQfu7M4tYrAKylG0PJ3pVHHvmIVHLIwT9H\n",
              "3gk9nEBxS9YIcJqlnY+T1MshUHxZ+FBqWtCiaJDCVViQZdLGv1pAeeOPdr3e2C2UfcIB304SXdY+\n",
              "DVYaf/ocTrMSdsyMcdmZM9hzy5LaKMbxkNorXRK8wENyD4rJnV1ID3z/ePLuZ7HLFrTu71hx7QfJ\n",
              "Te2MZ3mFgxWJpsHJXJPrf8HdvmPSFUJEoA0qnFEs9k6cAJkTh4JGTijUHXja49dbMj0/hJtv/G8E\n",
              "LjnwunrbYgloHzN5kzLk3Sk9caX73Pi3dKSmIPHntTpI3FE4G4NWlJQxmcbxc/KL+dr+w9JTGtUp\n",
              "Hthuok7rPpmnuKTVEQRctHsjx11eLds8BLt5ZwRLayFriAQ9iemMzSuKRBX0z34lFRhypWRTsT6E\n",
              "md8HeXNFP5xk8pDhY5vDL2vCBgoyTWYtIrP8p6Ca5KRUacgzwjlYvX/RHBEg4zIIpuNyXfZYJiT0\n",
              "R4MrLPA0wS7ZuW5c2eHSc2Wp82BM1DQafdOn6n2AdIy6GZc+msA7LcF7sh0oK2pGPniVrFj608no\n",
              "dZyEgcvWbRNXmYtwFNp3Gt06ZaTOUIP21PitdLMcafWXwBlkUkumjKvHIK6LmEiVd+D7L24lPjjc\n",
              "WugDW56ynSuGjuQG8oorrpMMj6fGltSKWLfFI+ZWUcYI9fpiiR5kZH0WRTleDJgLyCIVs2GYI/g1\n",
              "hMFaZhKaVAic+k/UG3k9sRQqIAY1Sn0KNwiWgkh6w1vf7vgaZRJssuZVbaO/0Eyq2oadvMBr6Nug\n",
              "U2F/wjxz4M5EuXtIonAbAubem4lCLFSoda6o+3vKELLlbY64yZHAkRY8eE/eptV6l6oqfDtsc5dL\n",
              "iZ3AGG54RXJylWwFfbdWS1hhuM3a5PzNzlDgGLczoXNOl1/hHkowez5rcO3NM/rxYEhVTlBLclOA\n",
              "AAWGegA3wm7yYL5LlGwBi3ISdqPehn/G+jonBWV33+vIxFEo2NbCggy9x35NJPMb9oIxPusc3xos\n",
              "VAtj/5XSkx6EtTXpeNlFoelH7Y9k9Pj9UUh4fAFiZQ/M+en27vbYxLMQgv3kvmEioRQeV8tpcr8U\n",
              "5qYcuuV6OE/ufeWxTvlK/S5oQmTmyezJzD9rNdvWzsrVTYsDLycU5DRTGxrYWxk4dzIwui3xY5JU\n",
              "LtpVzPLGZhZwD6WDNGm3nWjBRsdOroXwhI8TAaU4BFJ2GPAOAVHbVtApqrT41TCMGX9TqQgX3Mg2\n",
              "CsT836QVQjBkZEuzpuOoMslDHPffjg7j189Vg36Vh3sRegCqSTHtozHoscgiXQ23rRXGNh1QMDCE\n",
              "IKiQC2+dxB6buKAaTSglfIN6S37bscfimAdO3KatTFz65EFS6KF/PXqm5DBsbBCjFqMbIS934Zo7\n",
              "SxYZsC8aBcSZIRw+EvGhlX/NseYhsjbBt0z8XCPTQ42Zo4wjQ9778vqzRymvhf487mSbS/0V4Ssu\n",
              "K9yfC50f6o2Yl0R3XfsKWgJI3EF0OQKnwKYHZcOCbafphEu8XhBf3s2jTS/ReEYccn2T174PI2b0\n",
              "RQl3AQ/cEguWGUuzKfNITCtXQUUW3U+0C9EhY76dhKeDmZmtOrocLCJWUonMI/vFaFchsFPgHjX3\n",
              "rfOPH8gOf/z3eVOP1W4F9FVV5ikiM3GwAELceBPKVewlesyXzwKjML754honQ03GhnvZAhyEZg8V\n",
              "XDWfzMzcdACztx7z2sVteKAnLKjNTH7tuG0uk4c/yZ7waAD2MquFZONXXMyNgAABDeW541v4LBE0\n",
              "JHCIadWpMv///zcA/WktuBoL9IEOZIPfLqgF0FD4n7c842nemX2g/feYRdzrKPQzaC1Dbz8QWHg/\n",
              "0bp9H3LURwSGzbUkQ10z4UAj6o6Z9hCFk4qChaQTOaXaerJOKxIl3cTfM7M96JeNu8IaEV3ISp9X\n",
              "CXvF48Lv+enJmQtZBf1I3eRaPujS23qt6M4enXWwQsXgdGdFJrxDVGPAJ9RokkK20e/P9aPT2M6U\n",
              "ZaoPhKi0q0tOx5IvYsAvIQCNAZ5Nbmy7Y4FPgCTBuEcgPgQpqskrIpSMNTD5pSQQP+bsHE2P2nGf\n",
              "iWu/SdkrG0bwCmnsQNqQgW5gDRQX1Iu+gT68oAVf5K7d8lB93dmnwWiw65UB4C4x1yGTQMIiNvp0\n",
              "v7mFc9S192eGnPAf9DvVMkCU1z4aRB95Jri3G9vhEgmWbTvC59DoPPVhn4aJyVSQgllhVG+sBPcP\n",
              "DWXYaO/BiXB5VLxfGfoHD7o7AEcQimZ5xXDTFiu0EdaCrgIQOoSDkD+vNQ5pBn5K/znPpE3xFuTT\n",
              "E4azwbCW5KINlt8RwxB7KwNTFD7RO+bft5ymSWtuZGiuaEUZUB49Dc9vTKxvPypnFum28QERL0tF\n",
              "2eZ/44lzci/TpMlMXPyr9/1GJZM1tZEkNoJx8+ETMAeMvre35iKr8c25JOrDi8gofKM8yh+itVWD\n",
              "RHYk8P/GcUO513+HeG6+r3haQmL3iHw7190HpQ/WO72uGXS9v3sv5JiJJ0Ml1O2zy3KhAAPk9QpL\n",
              "AERsWxrCUN/Kwu4PmICzHra8kneoViaZowa5JFQiTBa3sxG19T+ZE+L27CdSDbA0OpDUOtB0FXqo\n",
              "EBZA6UvEkmZgVDN3GSXGMA8j4R6M6qjQ1WUBDugSK4a4qONHKy0KBSTa+QBSWY0A9xBxQz/Keku4\n",
              "32rD4q06AhUx2BJg17UfnsiZ4/e2w72p/0MlZ6Oed4FkWzk4TMKrZFg31CSScoZw6gOGBcMb21qp\n",
              "eq/URBOyC/pPghPc4cKjjy00CEd7VI1YuIitNbk6vF3CdypVIs1LaBEy7zD/v36mn0qXWbVrDsLS\n",
              "Bidlj7FoK/oIyChdz6oNd2V/ry62k2Nk80j90TCDaBsOKXXjvEShBN2a9Jgs57Kw2UyIJ2dSPa3Y\n",
              "9GE26AP2Tfuk8ra8twqpzQpQsbraMTM61NHmNtYiEwwAOqapYwOnrK/LTZzLXyPm++GDJ4i9Dhq0\n",
              "qcIhdYFFdl51f0RGidA0oh07bzg1doNH9td1fIsSzv4Btp2CDgQYW2q/+w5AgiFwYwDU7lx7JgVR\n",
              "wQAtcjFY0JIF5/RXohaYlSlOxt3Eb8l7n8zm55twYOD/NKO+JAdSSj+aZ1unQD14RBxiaaZy2eHD\n",
              "Ic61g2a8WYgIzadbLzpkcBpdbMFIUJiaUZ3vBRY6chCxk7SEN13CBsNKLPQ8PUdED5Du6Z2RI0Gv\n",
              "i8eIFnxPitQC8ARoXKi04odDFjmIOpOBZSV2SNDZhGpGtFvXXwpLR9wn+9hCh0p92i3qcW9GszaS\n",
              "c4UHeVLrEWCWJZvWRbBa4qs3wTV3YXx9FA/yXlqo5rELkEZrkR+OUMqYd1hQpCmcNIeWxL23tMzO\n",
              "Pue0vF/bUsDDVhFsNsd+a6egESUIhEvTf8IY/8YyGxZa+37/c3x5wAametJUvea5b43ojolN1T7t\n",
              "LVatz+fWTMWLAXeNphBfpxORyqIPkSAYh+PzGkd8gcvrHB8cUO8Fq0aNcdXjRPOfjMycH+1WjBCG\n",
              "RyyUIHzcHl9dQ7O+OfYQdnIBc7ch7V2XrAXKFi2Idb28Qtuj8ZxCu3gvEJ5469KL4lVwMZpWFP4J\n",
              "aY24Dy2Q1w95CNvXWoYSfhY2b9SSHrZsxabybJnNWeSpYZdAMxGMRquPMtBgvPq4PGtKQmIhSN09\n",
              "ooba2A52RqYlHxZRaPyeGQkQ21jqcRk3UeUZtPLHwmLUOfEw/iCGz2o+oE62MQEldSTo4dwTAnj3\n",
              "acrZpxC70k/Rmo4crUST/ucGNL9Hhb5AGe2+jwP8ff9BRvahYt99KwukNT4oOu+VkA93sOqHHjSS\n",
              "PD0yRW8+eYCDtxBLMGA6wpvVbcA313cjYUNntWL5Vo0r/a8b0yCAJF9ISa+/0tOTfL++Z8dDUEDd\n",
              "UnwQJtyo1i/8fwwRQ6M6jnTAKTaHfAt7Mhd57W6imoULfaemrCMzOBkYRnGPTX2sE9bKCjQsXTt6\n",
              "c1kDoEbrDwAv5mFDJLxZMKtPbgYCeZcG5zZeQWZx2Ql581IpiUyJ97Ocd9F+pVXPXVk7nz0ytCmI\n",
              "xUvF0y8OVambFeCGvM+z3Yzrm6V2G1UZjmFcRqKBWHS5S7V/mrimA7fxZGBZEdc2ky5xuaiakT9C\n",
              "hsvFApg2Epp+HcZZ6BY+fa+ZOzsyJDL5hlPp8Vzwx3ULQEYd205oAWuU0FXrBpwBgyug/wWSAA5N\n",
              "liaqXq65dQno5AOHngAAAwACewAAF6pBmiNsQ//+qZYAG+6QCAkszZ51MYWSmVH1Z82w/StugO5M\n",
              "OMwZAK9dLe8tMC/ve26lIQ7ptpWP0cf7Gblfepv2FCab57sOA9vf1j0gAGE4p+laf0NQHR7hHMVu\n",
              "ettaA7J7UKph35lJc8XmQaAfSntHlmlnDi95vAOOMJPzZ1Xg6L9NJOIq1iWxCfm1EXHqB6kfqeuo\n",
              "Rkj50KxLdNS0+3VsBSR9yWG9y/ibCqFbniJPXf449Y9SBLmyL36ilwRwP15zgye+ffLYfwK9nsxu\n",
              "jRnnmfLaTp4MDQXriYiKzh3QwTN5LrtYaXtUiNDEQPEgWqHKFlQ5psiq+3G1KPRTBtMCYkT3A48+\n",
              "9U4mt73oZRs4HLrizKvCqgOorGj27KMZ1V3UNMnmb8HMs4WLstUTHLJlzoHBxYEQR9q2luL6FWnh\n",
              "LIzbqb1Jz7MtlkbOfSwKOjZHFELxeMWdr2RHGuGBhw5tmuMf4ex8RAyhDKEgf8O4usun1b0B3zNo\n",
              "3o74NJXNcXwrhVOCX7yXaEAEpxK3w6CntWSZZEIXMNwhoXh4aYjFcZagUSh/o6JMTmMhCrtFz6tM\n",
              "58cq7cDc2c5T3P/0mOAmGX44CWB/rMRBwioXgCJBqyQusXia1PJ/OwAsHxkklv5m2d2PNfn3gkv3\n",
              "PD25j5K0li7m84pbYe3/U6XcOhpAI1k41+iPSCv9MHLNrIYz6l2d/sH1Kg+LGZhbTR3w8xrp4kk4\n",
              "BbetKTG4Lfx0QoBcnJVgJdvri8/yeO2kgWap/MZ2VOfZ3sCroLArZWo7LkuSBaaSF/R2Oa27Cp4j\n",
              "8lVu+kdmtJUnQ1aBonFMPFS8FJBqbVEPNvxDG3UZ+BeYO4ycznnLYomFP1L9LhKUQHTfoKz5Yc/o\n",
              "hW9tzAP1Ubg4P+muKrhbbm2xQaq2envNzqDI50BZY1iu8NyQukX/zdoTDSXNomdGVPtcqkmwhEmu\n",
              "dCbCqtbnIms+qSJlaFIFsdxp88X7lvD8AB942XO0GLT9+Z0rY8ED8EY8A+SpWvLEB9p6kZcCsrXq\n",
              "0IkPfI+KALM7BDmue6zzTtpAXpdzHUjvQc4usKpf8gEBbquNgAwZ6bzGcxbum42YiJoR52xZxtIp\n",
              "ihjq48QbIsWWiwnXwiuTYztLIwYdK56tYmBzoxf/zU3Qrl+Jj9jDOXGdre+nvkehsM8uvI54pD/y\n",
              "oF/iWarD9JiCRAAgkQULXePXdZqW+/OTQuWSMJlWfRt/dt/9SQQVdS5fIfEQBRen5GoyL6thGF7O\n",
              "SSc5Zs7lPMMTJTo+3pUn7IxPxo7rNNMGsQPsgys0Cpow0a/QR3LA9rVIn3M+oI6bZN0HD01IE4Fj\n",
              "O5VdIVm0Zp96XYD7pdPS3ihRM37O/WUZ8UNPnsN1SJqr/hXorWrl3K+nmWHCpLVZBfk+x1RVvLRM\n",
              "ZeFPPNZPmV/hGvYsULwiLn/uwRucBE+GLkkLExNXvAMvHLLsJO71eSZ9Q1nOg/MujkkGsgY17PMI\n",
              "vIEU/cJHHFzSuBfuwfFkOOV1oBXl2/utwWcJDpHx5d2FRqsUL7JY/Gyy5Bfjv94bCPctQN5Vc6U5\n",
              "kEjkzwaXkY8+kUF3jhCezYnehyzOzMdKweFwHx+J2HqmBT4f231HLi4g2VHCWV9Z4+rS4LLJiry+\n",
              "yNHNDZV7gfWHwQeEWnv27LDJ73//GB8NPKQmRi9JhPOPEV0HZXDNKsha1OkZ6ZwLFfiFH9p3x9UT\n",
              "TPv9Myn/Z7grq5JyMsnVWzEamgYjC5C/BSR2C6QlxnrdAq0nAKpnpCS2GYoh5CutVYSx+daK/R94\n",
              "rvSazkqHS5Vyf46Ll7k/jGfDY5JtIHP/hbN2ksTfGOMkfF/QTOuLD4QS/3Scsa1+ZuVd2pER9Vua\n",
              "1sMIscnkXcmJk223GK5PhRzNggkz2R4h8Qgb6O0SYtb/NHBLCLfOw8qbIFuZNxqrYmvGoX6VsKSB\n",
              "6v83Dty+e6VleuhtlunDMrxLb4UUBeVxUN5FQU8ndl7qssEkuY5HP3fJ27HuSmpZeAhMz2T7yeiI\n",
              "cfT1kmDRQTpd8PQ/ybZSiaBw4vRoYC4cZQsClUcTBRxFlY7td1PFWWbnAv5meXIY/bnLTlegGPGQ\n",
              "wtMxJJBO0IbRmDOCEFzsb9198BcHsfS3bKpcCGMbDhWIcVszRqhbTlnlJhQaZKa2r+GHwDvLPpSi\n",
              "0h2YdtsZeoP9buHj4/+sQKWnUKuHSEGqsvSG17TSHti9o6Rj09WDoyC3GfBOEhGRhRmCK2/F/b50\n",
              "ZAPv66j0fAcaHIv4TX9598C93J2+tKjdWcRscvEv0fKgLKcEtI+JGSVr+byQFnp0KszdMWiffexz\n",
              "O9UkOavYvDZ0JMhCwQYK9Q0wfC6QMt/B8pi/GjMgkQbPjfQvZ2nuNM9wGXDGYyqHkE3kt2S7U3hg\n",
              "Xrsbjrhg0IJ/mgPtfMSOrkaBtlUoEUfs7z/lJHjabnkAZZQ0ae6qQNLb77h7EZI0f1+FKbspltHM\n",
              "GeuBtXI03y/dDBxa7tbb/0ZbSFq2Q145GQnV17ipsZuSILdHNgxwqwfEdNzxrIRcUqg/Ie4+DrId\n",
              "Kh1q/nmjpXHq3WfdEbOwBnLrc/69bFs7kfxiBWUsfb02jCCizpaBFefSAH241vb1Ru2mdptWolcC\n",
              "fTwmLUJPeV4bjT+uZmSs0A3Kmpvrj++WT0R6aJenNqZ+3TMYyrPMgAKXrT90BWT6mRwMaAqBBPJu\n",
              "rEhATTNqNy+a0yLqQZRDBrc83965L/OW2f3YR3MNUmSGSY/A8hxKgZIig4hmzGaKYCRRAbLIupFT\n",
              "vz4tirGjQVjUoEmG3Tox456u9tL3d3slJu/gLtMiup5JBpiIi8/kW1+ChmLyEEUNbaENqDmlEyjd\n",
              "hTQvXb0typybSYMq20CHO5OJ4Of9rZbnnfAK7Ts6B0ROf8pm5We58nl4cFJRD9YT4jpzC624cW5U\n",
              "XpYW/m8G8IDy9/n1+WFMcySvopH0UW4Z1jvvLjAENubJrsvDu3N0FKNMoGXI8598A2tW0l4Ukal+\n",
              "FWts6xEbRDIWTPuOXTG9CfeHLp+iSU6p+liZnMiDRSqrnkcpr+LnYGmJUKal6UgxDcKZHXOccps8\n",
              "duJXdb+8/crx0nwpWNIZ6VkQ6Qa7kmtp1E2xKoo8FcTI5SjN/TNq4WvouDDys1rK8RMhRgks9mi4\n",
              "RhJxgjtwnztZM3hUhpW/XX1wmFf3tRxl/LfZWz8rskz9LookEZbogDEksNTHK+wBXEnNL+n+yfLi\n",
              "yPreSkEv3hBVQkmiqOPfooHGJdyf31IhhPp2P3xxOlgnBkJDVMRI855KFZRrGWkdcq0JLx2DzPa1\n",
              "Ko9Ppfqc0j0Sr14WR/zHH7JdFlXjdqblgxMsBuZXX/aN5LKJ8uUvUvvjNEVOSPr8nuVTHNSR60jy\n",
              "1V23iYlFr+x+2zdRzMnW6GAd0ayVgO3Xp8khnKOsfba63hbUGDWEUkwrWCMOMiw3k4YmND/HSZ8w\n",
              "a6OBenyJA0huMxQdEuS6PUpXneDaSIHIsDv98dLXhHmatqRuaLWqzFLDSdqjUl3mfk3YCXUqfayh\n",
              "B2FvKpR3EFGCXzHdMtObOss3vUpP/2nSwiUIemKxHCx7E0VYVhGroHEFUVplMi9HUtEmt59HOfMW\n",
              "t4GmUpxKUF6YTNWdp9pkpmXUn2MgiQsqVf32SrZVLYt1xx8UA6+Ou1fVkjlTDOJNDBpwJk2kMLpN\n",
              "GGO2hV3ex3BjisgYyO8UezKKu43jOQB/Jli2RtFAAqXsuC395qFMs+vSIGOJct3fNRbU3WH55fmF\n",
              "QgSBZUud/yP+rQuRvX8zSqSomd0A1m1qlX1sSnjjeFgEpMAJTbipPm0lxmTagO6XYoUtdaQy/oio\n",
              "VkAH+1JrQqrOBvD7E+Xg389lxkBjbRwhdCrGPlc8Ve3rsbHD5Y0ZiYtkGDqfK2iY1bwxvqRKXINH\n",
              "RdiC3AyP15eRMMX4C+mXkZIZhxp/Ie4xgj5c7S0v2aGojxAp+nNYIzqZ2cwi3C0TNcDdmZYjW2CG\n",
              "0tlayf3H5/VvrbgTel+UVCFJlDSHa2y2XRkKl2DgY8JW1MeR28EEJGM3Pgbti4lQm7BL8hbX/9yC\n",
              "F44ABPUH827DlikBqlCuTwVPIimUMnq+4xzn4wUTBXsNx7sEjlXIS/8V7wi6iRkop4/ffKNbmsSz\n",
              "2CHB1oUj+eyV7IDyYcxZ+oePgUHVVaVhbjaGTiPaLc6Shrk7VUJfC3anCHic1FxQasi/y9fpPEiB\n",
              "9vR6N0ux/AHAfxNdHIQ7Bx6jGqyVHIqAQWSE0gCGyF8ZxqnDPp01x45gyzKWNvo6gtOqfWDDbNwO\n",
              "t3uP+GkSJOyhmVUYob10jBf7Z5bpbxHMW6BNgpPN13/MwBThMLcFMmxOj/cPRokifINoOGMV1pT8\n",
              "p3lVMJu/ZIVwKD0W/4SmaN0mv7ruTo6lN42bLwOx0ZxiSEH3d7ElGjN2MMnuNhxBo70tDfvNL8J7\n",
              "F3w/DCdza8REc4jacwNrX+3ns23o5VRTJ4Mg3l0fIvanUb23//5HQC6uec65wJd/AktCz9AvzaV9\n",
              "Mt1ZhxQTKskcjQc2xUQrLPZywzEzIvN5yjniXtLxExXCsPpNSRknwBYLQM75Ev9uer2FlZMfvwvc\n",
              "HqzYUN3nc82ugWTQcAQhg61vl53yaCUNuiF9go32NNdHgyYfivgK+dMIGvxH1HqwBdMSOt2dTdbe\n",
              "3Ed+vedFmHBRvbVi4sSdxFp1+ngrRBmIZNE11Skr3fHbVopdIXSnUUWTaRqvPw1xaKi+93Vwkko6\n",
              "RRAsjgyxD/52k7M2AanQHJLyoBOB+2de3ls6zaFAiUEbMzrILrLweGaNXQ+WZXukVT1MSlRB4MLC\n",
              "nFG7a37jofr3TVzR4EUt9MExt/yPvad6APBFrcfVqBJtHmPlSqoes42t+TN9/VL7Gmr8RcLwtlde\n",
              "pJoBF0wG8erHYWnCoRAkZMa6+Im1f/L5XPjGS5/9XgxYLiapMO+tEWJIu//hr6/SoWX92j8XQXNY\n",
              "BDvIat4EtiKE6IcazB0eACMswXfFQQ40adHqS8LFtUWl6VtzR1knJ/ayvWB0RpCjCkVD8TfY8LAK\n",
              "VQqNePp9x4w3LCqqbWLNAZo+Kk8ChmtYWgDykt30uNCHPW9QL0TKCB5ap4G05p78G86EBXvhiSdz\n",
              "xNqlYatpdO26guTYvc4ddA4s5K9injnOUzkNpfK7Eh/Vlt0apsNriyMQ5aEildFBjdQUQI+l39sy\n",
              "6FnxNZLgUeN752AeLHHV3DLSSN+WuCfJRLCOyuougl0tO80dUgspcrrSl9TNnTTyht1NsFp4aRvM\n",
              "/YXi9e935T9HFQ/bBO++lBiOvd6iP1xhh1Dn/RLOCDU8EETmeFH65w7Kd7LrHyToZdoFwpTCR+fU\n",
              "PcaZ3a++TIKYfrSj36Mt4f8bX5PWBFtvEJELlA8QfoLZ0Q/Nzn6ocHGCh4LVQDYGG3qrGBZk7pC6\n",
              "Gy+CFH73s5RCpyxVLm9PVeuW3F7caZ7b3pVFdRWivJXW4B4mL7OGAYfMES0wmviR2Rs2Wg6qt2Ba\n",
              "RjWIVg4DmnJuVfEqKbl3vTi2e/aXlUJyLfgyIMTZeibVimEUgeM/TWHJ09Vyb7oNT6ijw7bOtVnu\n",
              "W+u60SeJ3ISc2FFSqd5seLIIjTlTbOuxKpmHJEyItkM3ohX/h+zU37dOi3YDNGrTIA2/sbiHdwee\n",
              "oumGBqfFL2ah+OYNrldNledE7Em59cPQ1T3xAeNUYlKrz2mayzO/wX2AVjXLh+DjB13Zf5t5uKkp\n",
              "QSaEVrnGwDE4cc8KWxUI5SlFXfbwKTawLiMLqIhUr8iCGYblreT98s7GgB3fDInedTvzRIeqDmfh\n",
              "69ojK10k0SSxMS7w0s0zS9I2ksA5mqMeHhkaG9AMWNzfhW1xcTqR9rJWTK4/RRRXtprdsxogmM4X\n",
              "CLE/LTv768Km2+sXIqQ30BOIIF38sjwpvX26JvWyIgV2aNeAau6Jv7K2mvGvFFtu2qcm6BCEJEIk\n",
              "c7EHKn0lU4BJZ5fsDwFRx1CWdjNRdg1elus0duZRBx50RxBLXM83UTSJmN9m50OKhp/s2DJu7ueH\n",
              "zggNso0Ym07ufgMxfLStPhAiIMrLQoNfmlFoGlKJyUI4j1cVyawUTHvlEsE4hQ0Aqid1NT2IkHsJ\n",
              "sKvO/noJUW0/XpmF0fUnQ1M4V5VJCJnnw2T475AXvp1iPIZtFDjIqwsyHrw+eE/TXAub+xMIVzGe\n",
              "jr3I/mn9dsT5FQ+EYF4d30gkz0AZHSciqQRQs0BpJc5NKHc3Ak4Nhcnz8LJndLhgR6FeKr4IScHb\n",
              "HNIZJq9tP99HE51r8uixiKDmtpn0LaMYE8fYWuEoaDg0Wh/OLKIxLgZIXjAHuLqx5cDxLrrJp6QF\n",
              "jabYdNWi0LgqHIfDofvHdMAV8eGYNgXPMUoB9/SVfR7j1PVZe5VRT9FEFtgwmdLMBEWS1JbIfq44\n",
              "5PG5vAD/8kqd85adWsLF+hN0n/KtulW5VobrPF4O0fMRPxbA5a6jhs5suHy86/ovwsaW6U0pEF1D\n",
              "x7pdeR583TMUfuhUEhLSJfOi4yDv4O9E4NM5AecqbfWrHXGxt/xVEjjCa8qc0fooq7U0B82VHMpb\n",
              "9HE84299BUtqpL7QhUhP0poIRkKFBnfyawjOP9LI6ytTnug/pnghNADBW7azqr+hRNr6vTW6Q2VP\n",
              "0KNQNjFKM1kJpTt0JCoz/pxV04Pg2IGFMmkHdk94sEiQOgmjCvTT1K8ufzkU/V0aCZiSgCrTrZII\n",
              "CuvBzmBdF5WoAbLhLfdDH15HCC+fkKaKDNilQSdeIkx1KkQcIYtLAMqj91q5zsCQEtaWxeMpkwdv\n",
              "XFZz+sphlCxf+Dqvek/8utSgfJ9eRbQnWzkgM4alAvNZ3fojycq7lt7/m+5nyjpOIO+FNaMi7lod\n",
              "+VhKawk50wFR9Jkhe6l6CgFO+xKhYhH72yoDFpe0Hfx3kQFVcGl75Hno1SNfKSIX1SPe+eHceOT5\n",
              "4Hd8amNK8SQ49pUsqWuTW4ns18Tz750YQL8VVJve4xWvChJ4Z7SsYB16QAREzhE7nt0htaLNCabN\n",
              "3F4/FTUdt4P/o7DzBNUXa5eYarVW4Ts6MDDWBIxL1pb9Drsl8u46fMbX2l1/1BpayHFLUFs1+pQN\n",
              "oO8T7vg3ozMwelKVdksIL40fJWTE5igncj3cXHJp58zYq9ePizEvi9VQAAd5OxCtdCWgQszzRSEL\n",
              "0E2E46cY+8TlsdSl4LYPN/JcRIslm/GLIMtNrc5aQ1H5Ri5ytxjhhhCx92FdPe5M7XCIMIK0IQAR\n",
              "xwyDe9sg6mC+ZDbtBerXUNmdhZzRf03QHjLi43nJAzL/34xq3syLqp71NKYNb30vWvxcmHEzXwn4\n",
              "rwr4cY+FJcNZgWSdirhzyhPPUekthTRi7DE2ycrIKAM4FVnobtRpjvcCsRl69QcH1bKWXu1y/G5q\n",
              "z/t2kHH9Qntjj+8VgQqY41qVL2FPyB62ahQGcweqahRcAo5ExsGYbgsnjT/+ycYr84nPHmuCJgO9\n",
              "QD20iAyWDC0+7taH1IGu7joApDex+R9N93NzKRjv6tSsCemx7kgVtqD0YLSpJA35p8dzLVpecmR2\n",
              "1f0e4/2nz6J0bZw5pw3pJ/PWCCYQGhPJepelkexd+XgtXDz3zC43PPi3IqaKWD0dwm6mDgFAkWqW\n",
              "Zz5eU9mU+yRM6okyzYERrGBJgk2t9zEdI2ZFpr1HIu6EZpkwP/8ZHqYJbGiqldzGnfbw8kD/Th8b\n",
              "elwqaz/HjTLdX9JufVfLxsS8XiN37SEAFh3tAsSqMP5YJJHIGhwrDQYZm25m221GXM4NumAe5hNd\n",
              "8p+MZknD85XbPXVK1S7A5nfIWIDOCr2w7wK966VtVwYoJa+GLWIzclrVcSywno88f5ayfDVDnvdw\n",
              "3r3DfJg8pp2CZKgf7lxFiJJXEGnBKoD7FJCXzI0cq7etrQVOYJSQ6Rrle4/zcd/QAvU1aCFC1N7B\n",
              "JABqctlqbBV1XbGECMYYgcBO/4UY1En5ni6ASceSDnGIpW7SEATRwKPRoVf1Nl/Kyf/otK9d7Rjo\n",
              "dD6RI/4MXhtI5owEs0m1iDgrZt0pGrxgQXakh3cY8LA0sg8xK6oIAAALA0GeQXiG/wAT5NdQON34\n",
              "MCBto/2ouH39ABc+CL6Nz6auXxefM6wMNxljXyL9VOzWUhATRd+N4WqtD2zcJjbjWLEVoyl4whAf\n",
              "ojVJtZCb74Rwdwf74hAg46UZQlxJpYQzLhAu7hIvcwtYXXavlBsdT3bPhgDvvP72m1oqwxIsutZm\n",
              "OyeA0jgdDlY23JC3xV64lEJdCHNd3MPFVhrTYBOCKZw6T9OMTdwpRAR6p4H3lNIMdAUSu093Q18R\n",
              "xXK2K1goHWWLjx+0KNATGS06mcb2MBHEi/y4bmDYx/apkywXQORP7NbpKeE2TQMaeGwaorAlNhjy\n",
              "/r76Zuc9m1gwPwnaBH/CDcXiOZrHRGWgMTxMYS8nJlxugIjettiWxWP8W+Q4eBFmj5wEK65YfgGE\n",
              "8sqjRz+aZqvYpiyBjPIGcIoE9xRd0bUweEWvoNUoUyJ7u3JojuW8yot5TQn3b9ZzJBA1lhe29uwt\n",
              "4C1IC8uQbH2UiyIjbHF04//JI1OeQ9zMKKD4JBQqWh1GT4006zhe9bAyW6eS6M09DDM2nSbQMcY/\n",
              "oqgLuY9mVANHNHkRjkHw4vr3ehUE7jkuVt+G8MxkLEFVez7agw/NOiVh4hDkjYREguieDp9OcPCU\n",
              "Ktg8NPv2ZYRe6i5Zp4Vofzxqq0R+afN8yEWft0/y+LLkwfVQ+zA2w+aVik34FBImGFbEVJ4yqBSY\n",
              "lljSDxej5GurXTrJdBBC4nHRyPSe3ne914hIkuNzEH7KsP8OnppWUnrNA/ucSmqwKy77+IMQSbl7\n",
              "xm0upVqX1Y0EJ4dpMWXlbxdkiZBXEGkH97GoasC6ORhkk1pEK//sIU7h3fnM7MwF5q2kTmHGRzu8\n",
              "KygjmeSV22MH5ij/kzT/CyCXSvj1Uj26r8V0Nw1WVcR7xv5ULuVrH8jzWAk5lNc2nyCMqUzzbYl3\n",
              "S9uewm4D37nWovzIJSfEKFEIAOiWD27RUU+sRfy6ZynGWu27ob4TkvRt4m67iAZQ0RUOKAENGp6e\n",
              "vKHq3dOqBMCLdAzgqiG3UaNUC0qa2ASxRyA2Hln+SRwpuxJQKmP7oOW2fzFegJr3ykU51C66+wt3\n",
              "pfgpao+OXR+T/t/dm51MVruWCMFfbFMFfRd4RPlSF2GKMWW6DiutXGXOI7ernltmiybKyMp8jGtG\n",
              "hnyGBWk85m8EZhVTniP717QtUs1rtFbqnzuWaOsrlaM2/lcjCzYD6P3oEkuEl1ys0o6+vOQggJ4v\n",
              "q5h+UUl/qKPBlP5XdwJKX4FAekpkHKC73KyA0Kd3OKi1Bgd8MoOnFG7pbQPsaLt6x1sA8bujYHrk\n",
              "kie8B8I2lu+bOJH5EGqpp4DK1/xUhK++8iT/+/ffpHV8cwuwANi720fKneji2IqijlAEf3rWXgvf\n",
              "U6RQWPYuvVj85x3IvLnn0xt6Zn/Y0gAsXJ93kM/hmMkm5OBt7/uo4x7/FjLo+ljd7N6yYhvfL2ov\n",
              "jbaRrAncF1HxrF5NH9G1DGej0FDcZXyCsst3Fb/kyGaBW6Q9S5Ehs+Kd/XtjOvCa9Pi/Huukq6w5\n",
              "d4u1cKWawAAaO/aI3hcslmA3cmlVQKTNpVvwcI9PFIfY8tWIUPtt1bGMrmRrk/l9rw/4dIrY5V7f\n",
              "lziwWuQIfzianfFaf/I7Eqojft3onuRQo2SrOBp+TXvv2XHZRqJJU/vk+gRz1vZ+Nvy429myWWB3\n",
              "0v3ob/+9nKSIghrJ3DCc9kmmQDt2xOOETC5MnD5z4t9INA+c87/cBnqcE6MCLgcGUS7s8YPLRIv4\n",
              "Ca4NY97eAA09dSFUWjW+B6oTNhoNf/LXSlBzYt13WRCyaduBbe6sl8Y9Hw+1gRy84VBs3rhoMU/s\n",
              "BpF7NRSOfHqn/QfC3zZdFv0Y9NMYMm7J2H9fYnkKEnmDvFx1XrtzElBZuFAYn0rklczxEG+apGhd\n",
              "7ZawNzjb2ufidcvT/yBlcEsuRsn4n9eat9495EM3BAecOx9UC7EoJzP0JfjWrWadgJ4TO67YEVEj\n",
              "738+08qLo7JqpCmKJ/ONllB0V7v5Joi/BcvqZ2QBe/68+Tw1QLSROXUtdBTVlQsFfNXk/pDJbkPs\n",
              "qGMQgNtQZ6pQzBoWsp8piHdaITdJMnCkORpYmiS5MCMhsomuxpHbDjW59+B+AL8JiuTzr85MJ5Rk\n",
              "eEtz3rU+FTaVWl+Es4Bvk6LldXb5TZ3e+DzrObsPr6AWTKGzydM3c1g76dkrzF1EgcbsWBng7xMa\n",
              "s8opG7wCfrfoekZoi45jKjSzFlAgNQzsbcda2lP1oqnT4vUJNp/e6FDkGBG3x8Lf0PkkQujO79e+\n",
              "QR9ZZtC6XHDSZdxMgEau9JTRXEt+H/uoz6s2YI4qA7Df1r+wS8OL+5p3CgVxZXQ8Y8k+ueisoQrb\n",
              "jSR5VhRFgzSN49kqwOanvtnxvWYlod+xXM0meWBVfXIiCSKSkDjPO7s22/tm9nOgJHr/FR7qe+0D\n",
              "7j2pr9fs2g4Pdu5X65agu/zaLhxviWAullmrc8uZPp/K+K2g3K1o/JkChmzTL+b1OHVSXwYxoVGp\n",
              "1uN/iq7C98UnwZCrO8VGKRSZhiON22AgQQzRtY5/gX1zrade7HL6mKRz8R836YIIm+R0GhAWf48I\n",
              "mmFLfZSDYkl6HSIMWKUmFG4EjV+2Df1sWX+UxWQpiMYmYhgvRoG758xwcp7j3GulvBnK4MFf3LI8\n",
              "FZohFUwelKh93J1PLfUIBUkQMVGF7njEQaojuaSM/ID8iddssJjv20KJJIt7iOS1QcMT5hvSyTgA\n",
              "VaRS7tRs6zgwswQ+gv+WjVM+UTp8s67kByEvpRBleg7VFDS5b067it2xGKFnOz1Lcjy9E3bmV15v\n",
              "Vnlo2GbG0ZgbUGZatKKEQXOJDYOy82+iSYCAip25cApqz4zDhNBO29bYAhqAHLLu/AGGq6rX3MhT\n",
              "MFM3mCJxqjr4gIiFSd1lTmTm9zW9doYaHxgZ6uurrefackbdCm9WszGpt/dCDd8CoQvOLYmzZov5\n",
              "QkJ3T02y76lzB+kgK8+Py6Ffa5MlN+BkJ4551vO/mIcX3YGIpMuQFmv1kqWqj2tO3JLfme+yYQdy\n",
              "K/sQDrWdTO+Gse+jG0VpMLHRaM7klXE/2iI2Dl9eU0SMZO1MrpedgZRzKMlSA9ydeYvPoZ7RhwMf\n",
              "Fsvrpq0/fYtkOwSNnzNtkYNSLWnTk9F2GAAVNfO4p8EFORQ9U6Ddb2Fe0Rsk9kd5/hHqwJsA1J1Z\n",
              "FLF4pkoP4sy+nmk9Igb3eV7XCxeCjUT7AwYPklHIZvCo6jfru3BvrfEKJrYphS7DL3sG6CsVE3iw\n",
              "BxQzUK1TTJzUgz6W0EsDY8kOhd4+vpXm4iMqZRsu2GuCS70MpSPodcr+NlSQKLSnmDSGPRQfCx/H\n",
              "OPrlHHwThT2yuy0UMAq+QmNEfIsCDAD26M2+1f7c9NwRveCZiD8rlg3t7B9X9H4RJNwLPLy3MJik\n",
              "GneVDk5rwGVT9/e1RZXdiANkXqtuH/B1sirxd3PMYLxOOv5djy2xA124M7+qXuGryeEOPsU7Uv8y\n",
              "aJZUgA5srmCWD9zPQ+gwWU+CgCEKwNchqYbuzSHxVh0HNMPGDP6oxmYCPwkEEnpJkVW4w6oP9mPf\n",
              "vSuV8nECljCAB9zA1wjGQMiWq/nLJmNajzFg+U7w8+aP23jR05URez5mBdfY8OYLxsRG5sqDAagy\n",
              "ppsM8FaDjX2u209vg5f/Wv4lfS7f47+PkW+3C2VOEGW695OWRaVF4dzKcKq+XrdyE2lIfZvDZXu4\n",
              "X51Iea5aLa33D+OBAAAI4wGeYmpDfwATWAYR9IehosR94ANpQK3Yb1SZjF/D1exhQ4jFwZEIZsII\n",
              "LolmQA5IJk8npPMd6HPvfpRFAcJ42Y8bYzhLadxdfz3Ks547jKq/Cfe3gl846kdggz+Cf4mH3uWD\n",
              "TDpK0kqyf8hcU/VwFzslo6IEsIPk4BsTX2wEoM0YLFaybuithjqD4TvK0BqJZinAzgcpvwJoSbJS\n",
              "TdpxyclzQiCK6pUZuTxax6FUIESbPSD+0s2P/L8x7SOGxGTwI6E4bxRVegeNItHf8bNIJ5ap4+Tq\n",
              "hjiQfS2zoiiULlWPwhd/d27YgtZtjx9T7dmNznb9SndhpSTKkoSPKGAwGBtJSYWzPUo0k9gz5gVR\n",
              "4leedkfdqe6u6Tpr3Z58RESjLQR6qn0rbNeusuthz9D5asmjYWStVIWs7GBIKWar4YV+8GMAFuVq\n",
              "oFJwMbp15Vz4A5hxsiMLMkkpKT5HZPaBNBwRzV8dlq50zvdZK0ErcHQKZH5u2gEQVoSV6bJI5AYh\n",
              "xSbT5QFCarRAvU/A5EFiMorIXLsbAniiUhMZM8YwZO9fDElD4Mynjd+S8Qhw/FyTfZmKh5J/pb0y\n",
              "S0KxJe+3Pzf2c3AIQwWtIC3Rcm57w96JkWaurDTcBUogFwyei8T0LTfamR1OfCQW4yU6ewA3SwZT\n",
              "oIZKDvXZKRGkIoKHWFifFLlE6ddxWGr0COmnV8rJDvpBgSrcF6gVgO6BOFS/nqG8eJusa5SKLYFC\n",
              "F9bDmA0UHoicJVthpqNUp1gm856eXSqm4YNHA2KXNFO1X+WocZLEpRUf41IzifmAGUx6Majwjz42\n",
              "Nm09/VLQViDJXd7LcMXGfhBO6im70KMWcTDePs6/EwhlhfhuPfBkR+7qIeQEJ9MUkfGrH74ddQ5D\n",
              "x77t3dNZR5OIGxMjKpbHHrEOPKkrJMIU2GVB6JvPpeKkUoXDIVc1aGxLD2X8qqDRtww8YKs7YtOK\n",
              "IoGjjJjJItwbS/nLbSwCueTtak2ILWFxZAmJCibgQ/+Va/A3b+dxXh4eic9BGSmT0tB2uMFSFrvT\n",
              "afENEEWP2eddGDEyMbYFZaHZ45f3k1KzgQVvlCIouQeOzb3KsizM5xFUCTfwmhP4mIEOPYywKCxH\n",
              "VsRHp+BB5gvVVeScgmAf20wZRg5Gw4MlMDvqDZFjwMwI2YvFImLWhOW/P/BGYbrX+GRn0n3Z9QnB\n",
              "2e6MzpwYPa4BGwDPTC6TX47l7vWfHzxWV/5vxNIY41Ug4dsOqDL3z9KrsoU7m583Y6f/iuiftYFZ\n",
              "AXgivI9Vcwla5jFTbKLLB7Yf8SyGFHOqXUBfRX5dFVXLJMvGrBzZJUej7I39EeJmVPBMQfOIDf2W\n",
              "m+RVcDIocc5Pof90GRVd1d+bgxN8IwKtPCA94rkUobl/qvFliPKPdVQdkp+YNMSDG4650s0JbA5h\n",
              "FuaJ9OvmNRyJJ3N8Kut+AdwFi/SPDmYjgeJyeBTEkaV9+rXxOL+0bhuCx3X7LatGl+iCwyR3i8Wl\n",
              "uw5AQKZ3ToX8m6ly2gzz6duwxWQk0yisxkkJfSPGSKe3amYd2KjkpUHkd3wVAzD1lgc9e+liIcmg\n",
              "d5vgyTdY3KXsaIkSCPHBhapenoe6C17gtTIcT/fL7bggOvL2opLWKABR6JJv1XSP62WEsHAndSHa\n",
              "ryb0EGE9rwO4hblgRxc9jG0N3m3br0LouMFZEe17Yg1pvI+00Dyu0Y9NmDiAkF7E8usLaK27DZlq\n",
              "nh8h5kVYN9UensumutGIO5vrWQk6Or58MXXDw0cQHX7rj8LPZkkGgs7N7Yf4AIPUy25zfjLP/pI7\n",
              "DlL8MDFGw6W++qz1VblVbIKk2lDfR/IQclbFDIwlBJL0TD5RY8O0HxMC1BmBlJhYCtt0YN8/X19V\n",
              "NKiVlvWSoc2SbHbGQPcXwyBBk7vZs/f5HYWEjkFXKAL+XN9qwuKdLgy2g85MocSpmDyFb5aTSYww\n",
              "VZRI6h5vhnKp8SUDIVyxu6pXVQxhcD1MY+EOMVCkUfNrQmGerXDdoTRlswZNV7L7Rv1vs7qMgvP9\n",
              "LHYNh7yL4JwAX0FiM21gFbI+gTThn/SSnjKBygv2t+xey1VHkqNE7Ae6Cy5gDzHsFmvZWP0Kyd7j\n",
              "L2OOR0mVR51LTyZnU6l8NQcPAFJovT+QggDeMy/HU6o2u73dz1yNHFCtGUOGNpNGDsCPhpeSr0io\n",
              "6EweAqmFiqkixdZrv0xp1mR/oaPApBCMhhEi8axsRqC/mDex/moYDbTb5g9EKCmi3FwU+YI4zI2X\n",
              "fl+Z6a717QmL2ezG2fn4T11rHYT7GwJXXgqvX/q+FKPThFzCV3zSTaRrcFDjG9GCauADdlogUjSt\n",
              "HfqTT4oxfbMDRvWj7Yo6+acG0qhlU8vYqpMNIqrfLOGwVtYTGC9vFjVAIQLcrj4DEK9WFIDxKua9\n",
              "FfKfGMkdCpBVqMJ0Pnf8GSsblBb0J3Z3yBrL4kIQ5xadmCeOXgTr/rHqHciGv6ohy2pC5hOaw/uz\n",
              "BZ1Y4A7ya9Oa3mudMZ/VwCdhXlDzEys75YRdZieHDxYzXPW+8MavR2Cp5qaBaqXzS+6piK+SLS6j\n",
              "j8fhm7IOe0hWvh49Ur3XtBUoSAn04bRPfAovGNWF4Dy7CScdTxvoElpWLRdgQH0lBkigAfTWjekj\n",
              "8au65ZHn2Cd3rUCnfppeErDmqv5IsU6tz9Gg0hWQa8bdb+INOBaI2zO1TnCNqIPIsnawPYbGRV58\n",
              "smNGdlWplcUksY1m7iqhXHaeZAEKvxhl4bCmpBFjVd/NOfSaHuJF/TZQoZFq18xShQb5SILYvJjr\n",
              "fmEm+7QRCMhk0eH3jz5shblORt4ng5XyQziJY3Gk9PLCrszbDp3ixnsB51wm+r2vFo9ApJNnI3LR\n",
              "uBU1w/gzdq7Ta5ak+uNx9B4ao730ZGJuLYbqYNKxy4FZ9w8dFZiqJgiGP4QtCQAikPpZl4g6WNSv\n",
              "G90QI9LFiJab/9v66wqsnFJeNRz8Wl6FUcnWch2VxSEnBtJcuBNEWNOmpa/5oRST1GFsbZJdkJRH\n",
              "rWcf1ToI7z6RVvAAABd8QZpkSahBaJlMCH///qmWABsovfVMAAtyb678a+2Plu9ANtN1uqifvIm6\n",
              "7rY4tqFIZfYTypfxi+af8Zwfkl1hqbPuRmhWuGvS7WNODFpmmEwFKLrqg+6So7bYz063hMdEl0kU\n",
              "NR57zys67Y1ivy5hitieo1gygr3iUQ08wjMHlS64Emxrg0m4by3IDva8qME8WTaBsKezDGvIveF9\n",
              "ugih135q5jE7V6ZRMDiZM9oX8b0xwVhG2J+Iy4g3QRf+Yz7brQiW0lNrdBeWSXHYWXZKUYGc+Dbj\n",
              "ahVyNbvDlg/ikzYcXAkVqS8jDZ91WQSLa7nEO47cfkiV+PoyU941RWFKRNE0Y671hs+We3UL9l+/\n",
              "Uf89KlQBkPrKThV5dhr4PY8oiq1BHM7IxLTsKQxVhsj5+SwOHRYKI8YCen94VIgURDCO+XiknKdI\n",
              "6Be6gHIBZoEANk6K3W2GyoGt6T0IG69hYJULIChbtibrmfhk4xV9D/BCm/yJ6PHY6gWu40w7C92K\n",
              "teWZFdAT2XEYJdlXL6Bfx4Yy6RlO4/g1AC9z4pOHR87gSzCY2rm62/5b0LChD3GshlSNA8T2A2if\n",
              "kFrKQPhAvqFHy5eaQHbsleSGICY7/BCN2f5F/AvkrghszNx2koHT4+Fu30/ipZvo1CTvdhjYoYpc\n",
              "7rVSPdA8D3hzZELNeFcAQk7RK/4lt2bfaWPTaefx0yAXSn2DNPN+W9GuQRDBjxl9/6ur7b+kKJ/q\n",
              "N8ytq1ALQyNF2EkGiOfDXDH+MFxcPsqimcjnkYdz+aWWnofUp8cBa/lhXNs0o8/ZYHqVvEkK+gVr\n",
              "85Fm/2MgCfG0ZwG4/jnskwSGLZ//eF/t98d5KIRnpX2lXMGnmCcllwacyXv2LBNyqUlgT6ZwjYQ3\n",
              "eHN6g3DhpXzERbju3gyr+O1ifqSGSesPQoAMmCtajAQo8IH/ombrhBgniwA8JqmKTJHymHVDX10d\n",
              "sj+sclvGg/iQCIev7qFPFPLVpBsW8djEZyxQNunhLtqpo4RNAXaFADrqhhyetKJ428nC3A1MeN8K\n",
              "/wkhYx1k8RSezNdTtOzumrlk2xrzOSs/Ed1xFz9lA2yZqofSj+tiZTjFlNiW9Rh+nw/Jud6q6IzG\n",
              "a3gkElPhXKuF1ntxQTV282wwR7Zb0AUk2prLWxgxR3/2EijW2k8ATeCn2PdRqCIeJP1SMciz1NMq\n",
              "QQGZ4W7djohT4E+0IToi/raaECMzjKN+tljZtzWtHQ+i9B9eTzEDumo0AAhOxgKulIUAPCWoeE4/\n",
              "z2VB0po6Wm6ITutgroHWaTUYuLG7qsry5TTaM6vk8KcWsBy4M8ClusCfK7tqraErKrvDXL4QD6Fq\n",
              "uJ1y5VntmMf1fH30eNSk3ri2nImB4mxcnhMRnBoXdOT3wT0Yhnt6ySPmpui6Js452/zkGMraXZgq\n",
              "owvveL3F8aWbyawoxX0FDdrX6zXfs/CZdgCBuKRXzf3tT/qz4/mIS3cTWgcXmeLatzB6yfJMW+Ed\n",
              "418sT0eGvy/e9H+skQzlOxaT+WHKoGIYDPa/QqsPv7pgW4HG10MNI62rNELxCJ+/s+78FZnaW2ij\n",
              "tF3KOOh2yxA15ZpudXQ4LslgFvX3tiMIWMUke43UmVj1uCo2rOdmEE1eFWLC9EdZK4ASHykgkABI\n",
              "MSr0v9mNUlfgzYOjNQ7K6yOjEYyPD15eawB4NGpMri20Dn6xJIKMRJ1dUyussWUWGYFg41DMe0lJ\n",
              "85NBLu4Wc5/M+KRnUclJV/0/oLBpcncxU3UVjOo9Mz7R8z3UuIMiK0HJRg8j77KILYfeLhHnZ6Vs\n",
              "djkVcHCfEMfNEO6Qm801NDdGUOFHh8Ow18F7qiBHnMfLSkZXLypV9wvULDpppobdlTH90H6h2Iva\n",
              "8Nl84GGj1dbmrF7hcWimbwdXPKfUwmR3ylt9ap4jEYQ7aH3Ow6J75V4yps2vkGEqJ5L65cQtsVOI\n",
              "C6cPSpOd9IyUaNigKwecnlLMk96waigavEw9FCEtAmHlXbA/+IfdvzyRD5Bvz3A7sREI6GHDgXhq\n",
              "VwM0i2+q+jQM0QcjuV0Yc4niy0r3LWSqtJmQV1Eqr+KRxq5B03f8lXQy3mLj9U9rQ9eTAz59sqJX\n",
              "gn48s6HyD9Y377voJVdrhAlHqTy6Qq0zqdXYgZcv9wL/jaHLmKZOnqhHGPzxyp+wwojEnF58eBEI\n",
              "6MSD6L/Y1esqdf0C7ft23c5LIciLjfy5qGxDuGru5bf/RZLOiyofwhY4WtD1kxc/J8h7BtOCnalj\n",
              "pFJTgf1Kg6HMyUNHAsu4Wtr5tkztg0zb1FeIxVxpTlD9Dn4pwXyRZ4ugWmeTeWiBR1BPC0IZSKVA\n",
              "6Q+L17Qqw7lIU3/StOAjv/n7jEwpoosUyoyxYeSZfKODogUbrpLF7skZvwX5cINAQRYj4BIkdsEz\n",
              "QJ5pIp5/cqqai6TCv2UQpEoBGfGqV13bhtAWIR5hTTamOnCQ++eUVz27wZc6S+gM+7cyXL70s2Zd\n",
              "55H/l3rpiOjTTniFY9DjSrmN0KoDKsTYsciux5LI4eGMNAQzDShVRViPWKqv55Q/CKwMoTed1O5A\n",
              "6YHW30T2bOEFNoeDEtemxg6k/uIfPeMOkrN5qcf1CK9S4Q7chJSJi46aBvskh8L9UYSpnPbaF3ja\n",
              "8DlFBY2yVVKhV+SpSOTCyJMCG8Z7ZGlBJJ4+/BMQEUqIPkapwVi/Jw4rrnIOKLgVaXGXYIeWx9Bi\n",
              "0o7bic6jOtytzsDk1ddlI3F0Ug8mkGTMO7LM5lryRZQejWPceYZJj6vYMtjRRtlFfyN4neQnfD7x\n",
              "5q/bVkdijOTHJICQZ6xUlsbUjsplMs5EYt+eIqsC+ySIcy/xVNrx+3pu1c2fOBLtzZfo7bOOzdGm\n",
              "2CN7osbxOVCfzIudZTAxZSNxJBc7COaE4Mnt7pEfjiPkQBrzae5CmgIp5OowKmFh+3eGSeiEMld8\n",
              "deSmDrxzDUUEi5wCUiF1ptYhTZTtyLwk/I9ytYopJzjQPwO1+KBfTVfLYPQfKGTkxPazDZp0dkg8\n",
              "zZJVOY08i+Nh8/i/eWbCuHFG91ocYlJFfBSbCLrVpoIeV8Jm05FGOqSbWaGwxc65FN4j6d61CE/a\n",
              "YTneDQmeWu7DcwQWWwe80ktG3jfoeDbHdmGrYNexGdBQ9GCn9wu3+Dpwj1kfACIP/19+SPM3j5Gg\n",
              "QswZqL+Wrp5WZk2s5huvoJDPWe091zUOp0aTllPd7GGufkKW2yPm+sM8GilnNdZ4n6Jd67iNnXjU\n",
              "IYtNEBWzd2nTxuGDvnrWr8hB0leZr2JK6N4Om6frQLH8RFwl8nPmsUxWfb/THSIrbt8H/oUprR7G\n",
              "VQiopHYAstbuBLFYWYhweBzqP5/WNw02myermMVY4eobmT8EW4b5ZayCJZvshXJnIT7nFQZpRcK7\n",
              "oj/w+pMFFMV0OLaNBkmf7M/8PK6Vqr21wOwoI98S/aQPgQ8/P9qMwUts06Xq77Ls+cZcrLQ5FiH1\n",
              "iH9TIEeyT81HPI4KvmjoNJ2ZV2DAlXPp34Pcyuq62DD8yM6B0tIsj05wMbMB7x/Ii3cqViR9Z5XY\n",
              "46J6+Hj8EQ0/dfmk6rQUiiCIMuw2tyuBPFifwew7crNGwQiLh2JgE+5zivTOoTEqyzmIbYesB85x\n",
              "R9Y500ZYslUJq7BShMlkXgcdfWJL7JHscDNJwtRXIHlDOXt6n4OuRym6RJaAZwFcJZOJJKXIfeXZ\n",
              "tbPXtQ+rWUXxmgzfXIaQwxW+a3zGwSwa2E6MMO9ce9ROyrfqh62/yMZHbdMebmmhDPiHgfQZ7ZT8\n",
              "zri5Ev0fwhjJn60A7nkmoZVLzgsG90dNmpGCb/FN5SYeDp0ZxdMtoDthHQCI1NmmZISCTcuuSdQR\n",
              "XV6GsoLjf+xO+b1xET4gLjJ+2pUxFI9FRT0Zsz3cmn3jOz5McSNgFm+dk5qjpBJWLqgXD7hM9unm\n",
              "qpvZi/pN/ZGFZGuh2i0dGo8HFuVUZIQjvCtARRYNBVQcYktYs2tNxRJMQaD7BMTLlpjrbso3Q5PN\n",
              "vgUrLvy1SnjndZ4MPRIFz/Z2XYdewmnHry4gV/r0ov95zAi899E0SpMlngRn7Xi+3Jc8kJkGskty\n",
              "tMo2LIBKH0j9i1hiailoLGNMLLPkY7ed+Vel99VZOKowFPqpBjJ9yNMNu3QAAzykvf7WchayP+xm\n",
              "xyeRe97GPBd1SANqKOOQF0DfTBDS9Vz7kDl+5lsb5ww7PKstYS0PU4f760EFJQHfzZKNZGKSVddc\n",
              "p+u6pNsVy3UupK8kICqOfr+FrOpk+Vapo6Wl/4w3JfnHPy6fBWqA6gC3HuUeYEyH9vBy8/2uGTff\n",
              "pXUf+yECPUo4OH9Ux7dfWatw/NPULOgGGdgZC1dx03Z/XmQUYNX0M1fYu1VgrfrM5PkY20xZY15n\n",
              "KEO+FJMfbq5dTLIOOJeIGgxOPi69Nbfloz5Yfjkk9WfeLgOoiJ5ipBO7vxbf7AphEyoyrH3iNZK1\n",
              "dmbwtR8JAFYcSRtCAJDlW3TzDJ2FvGw4M9mh543apx09H+G1+jbsuvOdbAVoF7HB4RidpiUDskr6\n",
              "334Pynbejn5htH7YuMDcCH5ES05+hACA0eJvziSZ1jkGIVRN0krqBuxGq9hSAD+E7sEIglPO6n80\n",
              "Ua2rOWj/9pKG2STh6WDjtSTkoForEd7jbLgBUH5OxsdH6mineXFXbTpDZSUKIQpP1oVQDRTpASdu\n",
              "QpCg0qnPudICyqwK3AOTjOPDUAr8afVZS8C3tvOjn4pUXb30TbpVJhwwJy5IGM9Mdi/ubd7Fgutc\n",
              "6M53Qr6bmiJUsm1ZU4c1bVft/5/ixDxtWHZMB5FiROGAihpP+Cn3X2R9yRPDpZGxsvXx9LHUD9mS\n",
              "N1oA/OKXD0xknoRdoNUwY8IjuT0c/T6KIoF99LxT6rdTHlJvCL03ohxD8XwJKCgzbExBJBcdaOr7\n",
              "Yus+gyrpO/Sr6mImmGKz7mR6ZhcNF7u1cpA+smqF/mJFm6bUT2HNb9cT39twTEJ3a6opAcCIeX1w\n",
              "9QemedXGanKcfIIBxPHP+efKTdjPgrO5zLAsEHZForG4NxHgAf/Ho530GO8l6K3DfWOtW3cyHHLx\n",
              "pVgyJH7GZcyuD93tQYNax6YU67b/qFkDooY9kHkkLdnpfSCfNeXByJhU+zsCNJDaR6OiXXYYv83a\n",
              "K2iRPjDTd5qKJTf8A/WNTEaaBvCmgOqwJJBhs0cRZaNvZ6xWEDREzMsER0xBokvkxeuQ5pkqye2D\n",
              "kBCz4l75Cc1/ORSE671VdpeuB3upI5xN9r9dpuxy26RkCR1HkfnbgeMf4yN08f1n3TCT3ock9nx2\n",
              "tER3q/AJUJf0DBLIREGu6xqIWuiiHWtkiT5Gfmjv0WwONDhZoJRdEoMieILJuMwuKFaHW5M7hMrX\n",
              "TZ0WTtQOZmX0p/L2kTUn/xmXYWrFJQQxpskD6moGExi/c29AmiFkIZ8c5cESJDmzlXgbvxuu3VbF\n",
              "WL3N8pVL8/b+Jb174YHIjhTFXpPGsAMSF9t0vZs73bXXA7YYv7t2Ym760+XcXxQDb7eSktG9x/dN\n",
              "8hDW6dqmtSwGTxg6uCYTBUGet75F18yhg6Q6Ng0p+UDIUkAl1rSMSul++KEPKNDbJ6s30gPezaQb\n",
              "NybMt6H1E/78tfwen1Ol2J318D0z0IUc7QN0IC66Q1zTSRh7zzN8Z6RIS5tg1clHTE3CVK8lJcBI\n",
              "/1Z20p6pueDK3AQtkQ8BCnGiKEu6HNjazuT5blc8j6VWJhEovQFAZLU3SL7FUILGLkFsVLg5aiGK\n",
              "eaUQiHSK3VLqQX613KDTlQ/80YEObOUNisJ3mvqF/iTldCo7ReVRhzlqBWcjnim1uiOtUvnuxM3P\n",
              "cfPHOEfA8MRXBWVdpHQBVGaIwmMxQE0lXWooGeTvt8ICZuOUVkXjbtfekPtlnrGLdUy3T6AXXWrS\n",
              "Yx1XLjOEvaqCmXVtRi2qLSU6YEhNKJZ8mk7ZJSJom8IrjKFff35xhkuWWecTuFXVIVnzw0eeMyRu\n",
              "H/KgfaZtgfRmRDlX5CCSopfBglV/fzzKnzu/ksgUzKQbc37MhFrzVYn7py++iWYeVz2az6Vuulqu\n",
              "jBiz1mwoupRkIM/HfblHr7LEuqx5L5zJxS4Fox6B5nNttY9o813B/Qo/iwPH13r48IpCIWTXBTEQ\n",
              "vkvNHRkvEg0JwsSx6UP78yGmjtYkUesQOvo4OBQOcKu4KVKIulcggBe/LzL1RpRUzLCfCYwTsznv\n",
              "2IFMaKR/bNj4xY6dptAyQh/oBQrAaWTax8MBQpx/6dA6uIP8UZ9jCRKNhvl8jelB5zbku/h2iI+s\n",
              "1kK/Aq40Ba2skdjXe0sWdDQAlxH2MVHlG5PZAGVBTtJd3iqUMxPbDMI2eeXyhQbxamH2QpwIj4xg\n",
              "N9XGiyqKuLYFGOVFT6aM377IvG7BY717e+pW9ICgx3AWXD5DRv5syJuSthXsrnQMlbsf9FnqYtbD\n",
              "pyOqihnr0Rr67f1lF0ooVOKUYPvzBJtZsz+k7IOnPdK+4b7I/N9AMjVw2GVOR++u014V4dtiqfeV\n",
              "vQbWKfmg8OQwMDC6vI7Apic4aPR0BSDLQPV6J+k3wLnEnhGq6QaVwT3tPYqBB4rr8Iii2LEzr4PN\n",
              "zZ9IIsouvKs275UBxql/trnm/vKdakY31DZAlQGjJe/RQ/oYGSNXJQyTipnZfwkyf+KwOSN7QnLG\n",
              "DJvGAqA6BE6H3XHkCS9k1nqDICHf+b7T9QWrieJW5shdNL6yP27UT8My8kv993OWG2M2Urytiycd\n",
              "w4D/yFKx3Pk9NSPFrFCLU1SymF7LPBVFkd92c/2BHCH6qeCCU1GwJeiZalZpTItx1613I44X6hVB\n",
              "UmS0blfAe37JXkvZBCfdeJ1gnaZicvXQjom5sTYsp31tviNWm/NHvlrYLg63hCkfngGiIN9HWUZW\n",
              "ddKOrA0Eek+i1IBXdfWiHclZ/V6iN0+7DZwyvLjmhc9SNCNlEaMbpVMJGakLaQr0RHOBWLLH4QmA\n",
              "qcZD3llyU/DSPZMba35+LppmtAKJu3cXX7Qvezysl+/FtHxsWmaZM/8JtIvRTVvhVaDuAuaySVlQ\n",
              "5nM8QLGdwEIkmbaH77qCE7x2zQy0i2lda4+l9u5e9ryACpQekcMnXyWEtJj5Nlgfl4IvdUIne7Zw\n",
              "eVpSdoAz4svfP+NAeiFA2OQHm6EH9pdyjzy3InBdIrNfuztUvvS+ix2Qj7GTiUZjOwuFO4ybRGOn\n",
              "6OPFjgSYRrn+7+ZeWgYnQQuyHvqWRBq8tN3TMRxEOYQTMWPRo5/otmDoOUGn1sImTSgxjfutKzwK\n",
              "Yp6EB14Qc1fdQl5HYBbda716EdUkzoHNzEu0OgiwgV1TRb2ovzG+WHjm4fpxigzeRpNBeDX++WbH\n",
              "b6/kAGmU/pUeSjh3CVXnlhb0hIl0pwcSCs29+G4WlqRDdgymvs6we4eXYgQrl7Bg+lhHmOb8u4VP\n",
              "PXxAEU7f5eAJwzTet92NieUVzFwjd7TNEgU6PXuuQ9fzMRrnuxYh4h6/AMkywt8j6DJjvw3CGq8g\n",
              "g/8QUytyIEi3xE1ZkrCv9lei7L4RH0h3sB3L1LucXuOvthb07f2UdF7SmkDwJjki087cAhtJkgti\n",
              "hkXBRPAjEOqWWpMtZqTfAxlUUFcVKomIpsGQEmTpPGZW3LIvgDQQJ0c+Wf+X/GOzwzFPJrW+8rmE\n",
              "gzirh9MRXyIbkpDafrzBJV0le4pl2egUYtEkhU2Z5ChizvhIb/+f1z97i8jKJVXa8r02VGhc1wf6\n",
              "L1dC2FodWf5IJ6ntwwr+3LDxvCJ27zUwLkuFRvkg1P5wOYCwRVGsNu1Jprfd39g5RXK9cXcnACaN\n",
              "D34YcYr5GNxBcCtpzmQ4ve5Aho/uqri+UxCeE6HLVdlv7+4hCZWATJgGptrtLZuO2ans9snWWSXV\n",
              "g9EIG3v83lgTw+CsqxwF340/j6Iw1HHgfswpmF87U+i4m1OnrztD0qV6timmigtw27ip80sds/P0\n",
              "IpmyYJwAeFZtUh4cIJVUCHw1HLRTTR2P2ciJ6CnlZjVjnzgToK19eM6BAAAMFUGah0nhClJlMCG/\n",
              "/qeEADNssHV30MJszYAB0HYpHmd3UaxDjWV8xXBewOcjUtFPyl+U0TLuabzjW/NMH9/sJu7PhOCc\n",
              "xtTI0FBb4YavhSgqxJArCu2EtlbDzbNsMyvYAYilq7fXWXc5cBw/GJIB+r37rbkve1SA6dGIBgEV\n",
              "DU51sRIrO1eIEmFy8ALij7ujd9csph8LBis2rAWkID7MgjqvnJ4woLITfscYpxcZZlxuP6qlfuNq\n",
              "CF2SY/qml6aKJNhTFGzTgOXN88WlXobhzgv96Ws8WLweu5oeq7+STlVQzgEYFnZSZs0zEgEWpDkn\n",
              "bryYsYtEfY9RPhulQxK3LET79j7d1G0krcYXPDp107rurzTYtuLjrAXjwbbkhIwB/fexllAgDxki\n",
              "mZOhWy1DelVWa40ot0d8Iu5wE2ZgaMXwaKuiIw6uLMwkjdTjp1JbypiXE0IC9nolgd0/mJoUcMBd\n",
              "6BGfwKA6+NEW5wI+d8ichDI+ay+Lbj1tr17kFdUt1Ze30fNWX2AISu1+VMQxpJ3M70fW6lwjGzZO\n",
              "4Y9ZWNnuiwDotaothj0QQk+u4/inOAAkW/2w2JUH/QKboep9U0xWoBgTS6itj2LEqDsyUZEEaAZg\n",
              "yXkHczh7X+jegtOo3lU/JkVZ86FHzQjL7oulfYV60LULXlNzK2hivR9bmtXZ9cGfd8P2ZTnmehLa\n",
              "Wvg4m0Aqui5jBpk3xNV8ksNZUPro8jFM09Yc/y711w4swaE8CjbtqVozIbIFi6BAaX1oKBkyBuB7\n",
              "fVL4bFN+SJLv7LJSoFby+IP7/neJlF79gmWXND698eLMeFk3L+r3lhpdBOmbHhumUi1W8SFBi+jE\n",
              "T8F9svmrxV06B8hrv5QqwgaAVMsaoqfsIPMbi09MijmfmZwejEme05+Uk7ira7OlJq//fKAsKI1W\n",
              "3/G0gdRJkivxKFU2nb1kWZ+Wrt8mKTdIk0Hf9OB2ebxsJmDSRbOF7xGsQv28iEAox6Um63N8BYCG\n",
              "76b0AQpR72gRjp6J58offBfxD0cTm6IuC7zbyOS8N+HitEvPPDFVACLmqf7qGKBal5k4C33JyqJN\n",
              "jiXYfTrKkaEj+ehI42CBMnGiTNXVD/qKzWuAp+uFZiQMlj39k/Xs7wukcWFsOX4cF12C3A5ADW8d\n",
              "JVjuaIdwJD1gB3z8bLmY/f9u3v+bteYMaC28r1kCeEDPiBQBieRqCaK/xB3PY3KtZ7j2o7DbbyFD\n",
              "IAiRBy7FDt/E2pXkyMLtVSuq96mdc15kvnKCsgEneEv2XwoM8SNXzhAFiZoPKj/o+hOUtiQcZmWu\n",
              "AYiYfqa4NzgXpsL7n2RIj91IidqoQVkN+hCdCvm6yWrMNRk95veLuJFbrFd/yRil/JDG5GbKrCa7\n",
              "+WTEfAE/zNdKNedcaVnxxFtUhny/gB88nSVAaZyRvgxWAIL/jAPrfXgmV8+DyCWLUsGwPzxrLkCM\n",
              "Kmhy8sMNQiadv4BAsoVUCd/Fm66e42iojsp2H+s3mlsYopd8Qmq2NFEsQ00QIfBLwmXqfDEQwApP\n",
              "qBwrO1ufEATolAfatIu/qOZpSlT5xW6FQUTy+xMebhalUsYdl2YbRRcVSLJSMADz4hwP2ymcgoIQ\n",
              "itcczxa9Gx+Ts9fh4v6x9Ag1bNvB4uPmvVhilIbOA/mGXw8FaEvcjXE7DrRyu/YkRrQOnbO2w1Pu\n",
              "sI/VUZXgOQ/9yr1rm4AAzHHdkFXz+t/FOluUXej6p3aW5g/ONxg9RtXqULYHlhP/LabELW+lYcel\n",
              "WvuzFLqfq6Yx/qQsFsGy5lBzbDUZhqggtFZVkL6R+SpkRAg4195bulEhsm+Pi9b5hC1m5sWQbM93\n",
              "ZNJt5Be5aFf8lAlOfAQ9/vdBe7ex05BuWONvlj88eynbhSEA8Lg21mCqEH07Y+FX31i8YqPXF/0Z\n",
              "DIBc3o9m8UsJGdyHCo/kqI/6tGxFO5umDcJbj9HciNq10L42VeP6FvL+2ncHJLke242h15kqXAWr\n",
              "QmYy2Zqqqu7N0Gk2dXcEqi94h/iiTrBSlOfmc1Zy54Wy+5Tp5UMWHBqEsdQOwJIYd7nBNXzzzNjC\n",
              "V5qZ1FIhQPF1S6MYc6FIB9tgcG92RuhAphZdQlq5RX7Rut34fTk3y8K4QlkVN+bZdgsztFx8DXWa\n",
              "mHwq9s+K9wA9jH3OYdmpriY5jBpsKxAJRPk0PoA1wqce5ET73PIKOuOgQAD/qqTzm0xvgOB9Wf3g\n",
              "t0KtsAWEGkUcxcYRQkEiDZc+S1YSQEUtuD/h9L2uFJFQqlUabN545ssauoLuxa9h33ghF7NKALGj\n",
              "Lce3hZYzkXsbuOrPa9j977ybyBDluWDtUSfkHxG9OKQ1VUpEiDwEb6JHyNv9HFlCpPZx2QnHsxOd\n",
              "+XSbJbo4HRLHQjJjkH1cI34AMG8gHpII5ovmSDUw4XTvRSC/GN6+5as4Pak2+KAntW7FK9dmlGBe\n",
              "n7raHoRbbuPGoneZGJirMe06Z3r+xcSTnP70+JxnoprvqX51kPXwX2s/YU39bkz//FekhXzckK6w\n",
              "LdF4pdfY9Ar1yqYi70Dm9+KeT+isRhs6OWTki4tHB7HKmENiMusAq4VsrRa+19zss2Bo34qtQwNk\n",
              "5Zm+IqKDG9g1KM+Kva0xTWcb2rnHVj7DGxZhOFPEy86pS4DmKRypzhp9WCyKh9F1+vxXZ0PDe+ab\n",
              "6U8qopP6q2wUGFxPKfszSuwZ2gGaB2jJC/wmP3inICNYQz+8gWxSf+PEQmLfE+uv15VcCA4GuBDp\n",
              "zcTzCNgXGWNDSme9LEOjuhTIbYO/ngt7oBpEIp+chPqCu3W85HM1k0JHZddJm/2C86BUXtSDDR1F\n",
              "9wyprs4G00ZrmNqjDMvRT332PxzYjQ7P90pN0NiHzZxuGcfjXhZO7tEov6sAb6Ie4fIMvdxoxquI\n",
              "c8cNbzoqwdBM6aevuKPFgMiKFhI5EEei+yYflaOjil+zTMzLR6ns+9yTq0uBiPg1DicEGF6NW4nm\n",
              "j3C6JzYNGJMSOG3Fm5zSlgxh5BxlPJb4oxhrecByWVyStcaG1Mp/X2kMBggjU+mpnRmCxA2arMNs\n",
              "El4pmfN8SGkQgn0pA1L1qqU8ZTuHY4uNVTTqai5LddxEiMmGuAFLQQElAG2FMvEg1wb0Q0Ps8i7N\n",
              "Sb5GSJpKB8goTRqQyyvaOtdkp3EWz586AuuH5V5pzo2s+xV/+SQXpifbfhB3aZwNVVJZQVCvWtwo\n",
              "Xpd57JUSQ1lHq8KGhuoIystiY5VbD2RKn2MfU4FCsmzAzyeBOYOED5fXPrcQTglmRqtwynyHT/29\n",
              "BDnZeufhv4m2TvPZbqRKTPSE7xEyGAzoixxuAo6KpBs72m+/fzkA1xWYmF/yPWdISXJ5TergjeEv\n",
              "He3ocjeYaNAhH2YrqykOCQmU1SOdQmgxWQF85sIuDjSgZA5VjPkHVWdWgb4OPsGdREMtFm3zC78E\n",
              "96o8XYnG/HEDJUGdysNtd+h598COaYI3rSFAZKrEoNkL7qkw8l9Q8KW7sLzFWuNT/g7QvDmQgwgJ\n",
              "3ESK92cCOcmaJKoQ97/Y3XbNYtUj0FkQ58SokbuH/YUrdktcDvy4A3a2dgPMbKHhMQkAYtzw/J5F\n",
              "qEVXCqVdkogJZ3u0C3IHWFTwMk23ZlFwKlbtlbGVDHtFEKlHyKo4rVqXN4QZBGlcFiKaQTQ0deVc\n",
              "E9Ky2HzlFeqUi8JXSirfRD2pIdRLFd3mrq0CHrlE9rCfJ52SzUVBXRczjvgoMfWU3rTWSRh93OKr\n",
              "ykNe0fHAW/gKR9DDQy+5wL1eEjHmOpMwwavwMig6CrnXcfI4l1HRtwT4JjsiBY6oQkr6f/f5mbqd\n",
              "a72YuBFb0591JLvMLgfov1SpoJSA/3K9K48BDP3/zC+n+M6pMpGuP4xIs10Wvx8xWXwL5WwRGYrH\n",
              "ioEb5JpXbReAlz3s891ikZ2ssubXGX9OxEBDqmN35dpVuOl5swW8A+io62vQu4ot9J/uQHVnEPCN\n",
              "+Pa4sKdn5yAqEp5blBDvP0H+YRI+VcEmsihUSciz/M4YB6yCg//S0gPYjRQTtc1CF38++JxiQjlR\n",
              "CF1IKEtZ0i9PWD/+4CaS8dqwcaocHUB8aXadxox9sApSsd8HC9oG0zKqYkVEeE8HjUD0f+a8FJ+I\n",
              "iuhgQQAACSFBnqVFNEw3/wATWFvUnsyRQALoodS2v46n62cYlYwU0FQuhF2PTmPj+khURpb3MjIr\n",
              "qr9sZsp5WTecvND/DfpGE8nNfR7RzPlKAgoZjJpteejB42M8WlndTDGlUQfe8pW6OIcGksi2uwdv\n",
              "lDjaTw3CEvPJXnbQ0BEAp3MaLkWe5RN9EQlI7ZvRol36lh4km0tqsxy85lIT+f5VDludu3YPQLWp\n",
              "0FMT1GHTBuTmWrxT+JHTs6mZeQTLaBy1WtZnzfjXzSU1QwyfA6tQrb2Iuuv/vDO8pJVzeGO7mDuL\n",
              "1JkYrAE2SwTMBmzH1BqbYpSS17BByE3xlULnyH0R8Oli4XMzQ7aNO6beWzeETOOOErdQVfW9dpGY\n",
              "KjEHitJR1WqJKFtCRk/pQzyaxpg8/HBekDx1sj3LmMyknd0BAkqFJaJmHIRcKfXD86jTEpEqkVBc\n",
              "SlXmo9+9F632PHJt44HVyYKoQkNPfYIYzze1IZ0Zx0c8sGNh+FBNqRLyzZT44XI5zQA8bhaLiM5Q\n",
              "NE13bDTDiQC3ScXjK1Y1BSMZK0a7Eac5ModjS7Izi+kuc/GP5kkYepkuLX2PSJburqs5bpXYZOfC\n",
              "yo+qm4FcwKH++iD0dhaBTDTgevNm39/MKWeDt2K8EbAH1uSp3+90a5ns/bRaloy9sJRNMIISWnFW\n",
              "fRas4NJZSuYrAQYKE/g0BfNeAWtdhrvaf4PfjEi0yItXwvZPKfBM8yL14uBjl2+1cSTNdh53pVy0\n",
              "GQxN4+hXzkwnMlwjAXQE7hIoTxQIVYkVQcqj4YsJEixt/1nw/gbNziPQ1QEtr2aZpAUeTQGQxOg7\n",
              "syny4Ge6+ol4ceBFxFQlhvWmlNZngNh0p4zMy08fxpMTKj2I6zjtsMrcgTXtT0s2G2vmqcoQzIGU\n",
              "CKagRJ9xKTpXXjzbhbZw8gfjLVwAjqBOH4Rlr4WC7+eMHO/S4GBiyQVzJR/w5Kw10XO/KLfDgsVz\n",
              "k+h+4J242xR7tPIH/wjj37kvrlYyDGFHm2tlkdYCLRbnjHV4fhlJyEirUJ46cZRqmGuilMj7zBp5\n",
              "MxSzrxU02jEIAixR9Lg2g66nfQk5IU5yFH8T0cAsBUtYGJFUXiaqDH79gb/O5K8noSylnJ6hb/xV\n",
              "wWTXpcP7euac4c8qI96ysm307Aybz7ms0TtdVL0QXOLAUJjdderUZGk0oIpaihtkJl0ybnM+IObZ\n",
              "1PXOrQwCZFkMmH92G7FuZGyw3G+mmoZg0vNM49x8+r2okPHQj/pTNJiGOnQ9nIIAi7OKSPQjV9S0\n",
              "BI5WOEjtkkfXhjqiulV8tlSh+FTdBR1i+R7i9sW7z+AqEtYlA8S4rS6pERPGkD2WOeh4EHx3hhoz\n",
              "VxO2NquOFrujZdw8x90aIKT0eFv64m0pO8b2mK78hRDJasNMdmoQX9UNuLvGibtvTa8dZsuVLMvs\n",
              "XiXgZPNjcCF9OwfCWUEBWC3nMp5PuIrA+qpoNNRtOQM9lTzBfxcn+YxxEvdypviLQ+sKjJxzjoph\n",
              "BbihTMu/yhHw4/nnev8sj772JUXuhs5/AJln5KW2jZD7j6XFLRKPS1SfX+ic6FbH1LBiREZ4shR4\n",
              "LG/Qv4wYNIzE56ZzkDhHjahpR6tclc62B49Ft79anXFA0y3jU6/kPr/dAjbGGDOvuNwQ20zeIm0O\n",
              "0CKVdtiRgfjWIE66iyhLtn4DO2HReHUKYcTAYmxTBaOOgSVOabBSMET6aecmnDYS8YEBBBb3MllK\n",
              "Uy3sR64ufvSEJZSXH7DtdAcw/60en4oXC4+zmPSUuPFuZ7LtL8VfXTXebgYNijn1LP1RMHn78quB\n",
              "+JwkiQT2rqM0JZsgJ2+GebEf+tA2SYUCJakp+KVi7658IYe+9WYTe5kKLhNIXH4wnnRq1wXSI738\n",
              "CpKHJ7aYfD6oAAHueEN04pwMusaUzlvtltvmFs+XStB2UcR2Npm+RzbTjddxrMtrx5bKvoyo5Yec\n",
              "W0Y206aivP8g19ftgnmzOMl3MuqE/Aiun7v40cfMLuNSxMECLMc6MKMCuqPSrUM+6mBO0ldU8jU0\n",
              "/FpxXgr8M76WOGIKsP3eCS1Uv2SbOmK8uaUPNfKBm7QtYVq9mvMhLMtefnEeM/BsuNXR57ahr+Js\n",
              "Um47O7QaVhEnBE++8COCT9DATcxykJKYnkAqbf6gV3rjZI1R6FVsnrAvxUTZMLYPXcjtAjMfTgmK\n",
              "sK/Cs3/5C4hwm6LXzQkI0rAfKkNfPusBkpc4um5r8KDdTuHxKkzFvYFilkUK8p7aOy46OoxZm9kf\n",
              "8T4cUbOOHv2Zyl8v2QHYokSMOHQLG6J9nZXyg94b38w/v4H6Fw//vnd2yVjlIb+SEfD2UCjPHF9V\n",
              "/2CSNWTG0ngAVm0oFaeAGN/r55vsMcB736oiHsagN9YyhZEIyxbW0EMD2Af4+KWHCyUobzGaBbA2\n",
              "WiBqETC9EQxhLeZ9PdY9PLbWZpmhWc+ekAHMIp2HZRal5u74NPlwLXGf/DfBANYlYbzU7ZyKiEgL\n",
              "wMU0a6Nn0bt4Ennh569ZIX3kJMhym25M9Pb7o7tUiOTLj7/WQkD7HSauTVMKlpESHddsAS/tH94/\n",
              "VplTkvjIDK9k/JrjO9kF0obLVG7xcTmYOKoRpYC0nDNOwyaFqV+BdwxSlRsxYUsbHV8jbqenm42o\n",
              "/Vm9p66h298SIKdnWZveNXniu7Gb3+yNNhHvd35DlHbYDCXc3h/Ma4oOwK1x6ugS3WLd3ySEznUp\n",
              "8UqRbZPd7TfIs/3HQnyoJwc0tVJ4IscrO6LpJa+0wVN/A+OJAmd/sxbv1Q/kMkvVsjala/b35IjL\n",
              "LdvblPi3l6gJpUO+et1srcPdz0g0di6wVl5mdO68CVEb+iSOegIRnou59/eS/slZGcoTZ3I2tIqt\n",
              "ialA7mgur6Qhb8nsPdEmQmC7vX6U+DK/nzYbdigS6RPyiVGg8UiYp24QumwtxDifxqdLLrAhvsqj\n",
              "v3J/iSWtwH995/ctLjdIypSc/rZv8yy82Ul5DT3JYAuBRxn88PAfq+NhIUf0ypwx7B/2yJcHzv85\n",
              "lH/gqUBHfwyS9KQsq+sZKPKTMb++47EqjIOnHGz5KblDtI0600rnoaRM8ZX1HXqO9f7plcr6ZVyY\n",
              "MMvBUXLwgcEAAAkeAZ7GakN/ABNahHaH2/O0/vcDEB924ooP3rwAEGFpt8EZ2V8Pb5zFOBUe6MiH\n",
              "GkU7cfXzvD3+n+vQnIZ1VplrugdkatrrIUozIcR/yNRL2YXoroiCe5SzYQnxnLjKjQuvkL2e4UT5\n",
              "dNAOWLiji/FJUmtGg2NpTveaHudw5IplI3qlP9rttiEMej8AuPGoEDoN3ZljEw0L6KliQYUYKXJY\n",
              "HNvo5KEFXEjI4CP7jtw3rSJy1HL6JhHciWgCd0GzrqsiaDwrmxREkwKkVZILnGCIKLw5Iiiv9wq3\n",
              "GAyxuIvde0cs0kPPB8cApErNe3mnXtLXhGAVe4CfQou/lCbH2Q6Mwj3YFQRhjCCokKtwv8XaE1xR\n",
              "cQV9atgijApYgRo7Z1oYNC9SOuehRPSdtWWkcNgi5ENfnp+CbbyYpz44Rx9SdMpfnxLV8MYC3y3A\n",
              "omFE9SYFvHo6XOsSP4IeNy01evMnxXPaKHtOJpOayqeoUabv2FvHh3afSHUR+qaFHuhEkXGbAxwv\n",
              "6Kgm1rx6yETPNoyRmw0HOsp4VN/6FIhfTW6FORt9VKfmfdOqt6GVQTUtMrMdSKJN+/nTpDHNiciD\n",
              "B3c4Rh5Thb1NTJKGqvJT1D7eYODSWcwgzgi5oQ87Gspiys4mZY5iHtUOh1N69pBBaPdn7AlKAZRH\n",
              "V1PdAD/ywebzKdK+cEs/kXZO8ZCU5cLjJWX14pevtP0elbEbS8baggSvRoI09VacGWZbOpyZ0aI+\n",
              "O39yJxuo3TpL+4aQvYeQPQ1/bumZ+yEccGerY6MM21A+3sGPSaH8je1plQM0kG4S19DC6G1PtKcl\n",
              "osfaST2r+QUjSj0MmXk0PSnsvwqsf37WWF1/2UOXDicxB2OqhlzcqHXqBfpvQDxmKcxsadLuNnE4\n",
              "2T/2BwwVHvw1NejzIu4roVfmFWtFkBFLzcqLSAISJd3BmBVbdZPb1KYpwvKgs5LYzP28ZPWv4Kmv\n",
              "rgeUWJrfnSOsKpePm3ys21VjkKFn+aBY2wVI4b5QQbd3H75eHfqSfFOBXNtsOkwZwWATs5hfqEmJ\n",
              "YWCLoCtecbXk148dAtLLH8mUpr41bl6qf7LO8NyEbS6afPoEArqXp30bXedwyKTl572MPvSr/4WG\n",
              "ln4JepFcz4Sk1JymHqvmJT+Y9FM+DIdPUzXFzphP10SPVf8ZA1XkH3ya8XlhIPGw4McD90CXgFG4\n",
              "lChdO71bWtAkdzCnIs6YzrFIfspX3wsYQw/GhuIgO76/2p6zau6MeYbKzde+x+j5Ls17GasGAJvd\n",
              "pJ+bVGM9i/0USlWACxNXXuZJ6Dg+9+DOhjR2MGbeTh3RNt+N5/v5e1Vfc1QK/15yx1sLoGfo6Nwb\n",
              "Zjpa4dfP2eL8ziUj/XGv0R+WlF3jzOCVeaKJuCFCLk+Htse6tyTHlCFtmBBz1SagGTZSIxHSKG7y\n",
              "CSs8Jr0AP+39EAcsFuP1QTydzhIbhdfli3nIJVYE6bsgtMOWT+gHGnC40kOHUD4/8f1NyQwnJbh5\n",
              "7H+cwbznP6XSZeQSOgayUOlflUMnv6sriw4EgUBie4HVmrZXe62CBpPGgY7BkS7qwiRMov+JMfLQ\n",
              "DIJ7LbRDWjttN5KYnnU5q2laswFcM9CnZHSJVdg2SjT/DqfZhF0t0WpOp3bBllFl4v7GLzkmP2te\n",
              "OEsGsz9r4DaW/+Mu5mmvEkZHeFkqKT9FBirbkZfuIZyiEptC7w1ZsJYnqZvZdnSAaWoJ5bVhzlCf\n",
              "GwKD5wO9JHpgrbWa01wKof33FaQlgVKX2PMi43EqP4+pxThT3CCtiPEK4S1pr8U3CrY0dhu4licR\n",
              "okAa/6J1tMw2QDGoMp/H3X+ePTyl7AG8pbst4nzrZMn+ILGTK4g/JjlKkGiXHREDauXQE5jpkt1L\n",
              "xoo3Lnro3ezLJBch1xIZyPsGV6e3HlQj2aED4OAmbl3WwcOkhioziwHFtOYp6hjrLAAHAyXrnaEh\n",
              "I6VoTBx2SI2SNmDg9Gqd4keYFb9R/QrXgIN1IvHifFKjoYgA7v+iFzENMaZeh4D0RwDTQUHMgt4x\n",
              "1whK8NjfpIYud9un3qXcXNdEouVzEcJ7AKWMCz8zFNJ12WVzQ4F059Q1hbgxIGWT1NEIz0qs8odw\n",
              "hxU1dZT2cHqIKrWITqkvk2u7LVrDII4mJHu0vECYomBKirnNDVwJLHWvAm/watBW38HZFYH9/UPm\n",
              "TXfisHvsnT/LSYhEmB9L5IMWZgLRwFhh8A0LJGHbt11tBtx3KYtWOKB2xJzCGDVaJnfx93hhC6Yf\n",
              "+9XfVD9BSkOTS6VE958ITgF8eG+UnPYyQBheGspevFYacGzry/3ixD9h3Hdohd0Z93CN1fTpbdkg\n",
              "NRHc9da9wVTeJBHw//aast7FF/7V0N0XaqMUPz79p0zildJsXAGnYBTs6q74lofJW9dN3ua8gPp5\n",
              "pOCA/PBBfmC1wX4ZCKESR08UnaCitoQyp27sgdVsAvIYZ8u6IGgMeLSOv5WbyW+lIvOo0tlfQ/JL\n",
              "e+Yrq16p3U09kpCfVhrTVooROGGCojt5h9K3NU2fQpNBg6gY249VCbpVc7gQS1lkEQdHQqdW1KTn\n",
              "G9KqVytAlrF2R426ozG5tmQaRVFc9j5nhpggDeL3wWfta9FAs/g196PHDULc/dFUKX99EHmzNybl\n",
              "fflnek/0I0Pcq40DfQmz8m9UxOnlQFtR2v8ntk4WQe/vKCyScEBU5uDGSa3b146pqj2oy6PdjToX\n",
              "p8UFPRghmjHZAYXT8ddT9sZwRdNilYUw1uDQgqc7jClzG9bbUp3MraXsaFs/DAs/CrQdL3XRJ3tb\n",
              "UX5gtgZD8OSt+mi2e+horOqMEyjW6HnxsfWqZ+NEaV5+pANPbGvm0jS3bMSzEFYnjWAkf3h8azp+\n",
              "WFmgRs3enUcJDs9EWVTeXB5nBFnrG78oXm2/TZJFFGZ+sjLLXMjnXmz5sBZ/psV0rYOie3HOw9Dj\n",
              "w8kxEmpAH1Wl0/SXqBUBtl3nwb+0pDIFoO+jS+P6JAqNBKDBTYFVHxqUcOpYfLQMPKDP+zE3XMj4\n",
              "YZQ2gIxjTW7Uu6RT9iSh0ezsNWcdJRdTgIywzOENV8LaOVPvJB3RtNU/6Qi7zs+wtxAhQ+L8VuLn\n",
              "9LZEp1ku8kzBAAADfm1vb3YAAABsbXZoZAAAAAAAAAAAAAAAAAAAA+gAAAMgAAEAAAEAAAAAAAAA\n",
              "AAAAAAABAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAAAAAAAA\n",
              "AAAAAAAAAAAAAAIAAAKodHJhawAAAFx0a2hkAAAAAwAAAAAAAAAAAAAAAQAAAAAAAAMgAAAAAAAA\n",
              "AAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAQAAAAAKAAAAB4AAAAAAA\n",
              "JGVkdHMAAAAcZWxzdAAAAAAAAAABAAADIAAACAAAAQAAAAACIG1kaWEAAAAgbWRoZAAAAAAAAAAA\n",
              "AAAAAAAAKAAAACAAVcQAAAAAAC1oZGxyAAAAAAAAAAB2aWRlAAAAAAAAAAAAAAAAVmlkZW9IYW5k\n",
              "bGVyAAAAActtaW5mAAAAFHZtaGQAAAABAAAAAAAAAAAAAAAkZGluZgAAABxkcmVmAAAAAAAAAAEA\n",
              "AAAMdXJsIAAAAAEAAAGLc3RibAAAALNzdHNkAAAAAAAAAAEAAACjYXZjMQAAAAAAAAABAAAAAAAA\n",
              "AAAAAAAAAAAAAAKAAeAASAAAAEgAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\n",
              "AAAAABj//wAAADFhdmNDAWQAFv/hABhnZAAWrNlAoD2hAAADAAEAAAMAFA8WLZYBAAZo6+PLIsAA\n",
              "AAAcdXVpZGtoQPJfJE/FujmlG88DI/MAAAAAAAAAGHN0dHMAAAAAAAAAAQAAAAgAAAQAAAAAFHN0\n",
              "c3MAAAAAAAAAAQAAAAEAAABAY3R0cwAAAAAAAAAGAAAAAQAACAAAAAABAAAQAAAAAAIAAAQAAAAA\n",
              "AQAACAAAAAABAAAQAAAAAAIAAAQAAAAAHHN0c2MAAAAAAAAAAQAAAAEAAAAIAAAAAQAAADRzdHN6\n",
              "AAAAAAAAAAAAAAAIAAA0cwAAF64AAAsHAAAI5wAAF4AAAAwZAAAJJQAACSIAAAAUc3RjbwAAAAAA\n",
              "AAABAAAALAAAAGJ1ZHRhAAAAWm1ldGEAAAAAAAAAIWhkbHIAAAAAAAAAAG1kaXJhcHBsAAAAAAAA\n",
              "AAAAAAAALWlsc3QAAAAlqXRvbwAAAB1kYXRhAAAAAQAAAABMYXZmNTguMjkuMTAw\n",
              "\">\n",
              "  Your browser does not support the video tag.\n",
              "</video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example = test_dataset[0]\n",
        "\n",
        "# convert to image from proceessed tensors\n",
        "clip = example[\"pixel_values_videos\"][0] * 255\n",
        "clip = clip.permute(0, 2, 3, 1).clamp(0, 255)\n",
        "\n",
        "# np array with shape (frames, height, width, channels)\n",
        "video = np.array(clip).astype(np.uint8)\n",
        "\n",
        "fig = plt.figure()\n",
        "im = plt.imshow(video[0,:,:,:])\n",
        "\n",
        "plt.close() # this is required to not display the generated image\n",
        "\n",
        "def init():\n",
        "    im.set_data(video[0,:,:,:])\n",
        "\n",
        "def animate(i):\n",
        "    im.set_data(video[i,:,:,:])\n",
        "    return im\n",
        "\n",
        "anim = animation.FuncAnimation(fig, animate, init_func=init, frames=video.shape[0],\n",
        "                               interval=100)\n",
        "HTML(anim.to_html5_video())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b644b2b-edf2-420e-9b11-c7c5f87eb09a",
      "metadata": {
        "id": "1b644b2b-edf2-420e-9b11-c7c5f87eb09a",
        "outputId": "31f4b52c-a83a-467f-d6fe-f0c4a13a6af4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[\"<s> USER:  <video> \\nProvide a detailed caption for this video. ASSISTANT: The video captures a serene and contemplative sequence featuring an individual seated on a wicker chair beside a window, within an indoor setting highlighted by a white wall and decorative framed pictures. Dressed casually in a red top and rolled-up blue jeans, revealing bare feet, the person begins with a relaxed posture, hugging a white cushion to their chest, their chin resting on it while bathed in the soft, natural light of daytime, setting a mood of introspection.\\n\\nAs the video progresses, the individual shifts slightly in their chair., displaying a subtle change in emotional state or focus; their head tilts forward, eyes cast downward, and the grip on the cushion tightens a bit, which might suggest a deepening of their reflection or a shift in their feelings.\\n\\nFurther into the video, the person's facial expression changes as they close their eyes, possibly indicating a moment of deeper reflection or rest. Throughout these transitions, the surroundings including the white\"]"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "processor.batch_decode(example[\"input_ids\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85ad57e3-bfee-4099-8725-286220c8d52e",
      "metadata": {
        "id": "85ad57e3-bfee-4099-8725-286220c8d52e"
      },
      "outputs": [],
      "source": [
        "def run_inference(video_clip, model):\n",
        "    # Let's use chat template to format the prompt correctly, this time without the caption\n",
        "    conversation = [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\"type\": \"text\", \"text\": \"Provide a detailed caption for this video.\"},\n",
        "                    {\"type\": \"video\"},\n",
        "                    ],\n",
        "            },\n",
        "        ]\n",
        "\n",
        "    # Set add_generation_prompt to add the \"ASSISTANT: \" at the end\n",
        "    prompt = processor.apply_chat_template(conversation, add_generation_prompt=True)\n",
        "\n",
        "    batch = processor(\n",
        "        text=prompt,\n",
        "        videos=None, # we have a processed video, passing it again to processor causes errors\n",
        "        return_tensors=\"pt\"\n",
        "    ).to(model.device)\n",
        "    video_clip = video_clip.to(model.device)\n",
        "\n",
        "    out = model.generate(**batch, pixel_values_videos=video_clip, max_length=MAX_LENGTH, do_sample=True)\n",
        "    generated_text = processor.batch_decode(out, skip_special_tokens=True)\n",
        "    return generated_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fb9b7f7-e1bb-4e2d-ab41-5ecd841efb54",
      "metadata": {
        "id": "1fb9b7f7-e1bb-4e2d-ab41-5ecd841efb54",
        "outputId": "5fc121d0-0267-43d2-ce4e-9464da628cb8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['USER:  <video> \\nProvide a detailed caption for this video. ASSISTANT: This is a video capturing a serene and introspective moment of an individual sitting next to a woven basket, facing slightly to the left of the frame, suggesting a focused gaze towards the distance. The person is elegantly dressed in a red blouse and faded green jeans, evoking a simple and understated aesthetic. A white wool material is wrapped around the legs of the chair, potentially indicating an interest in outdoor or vintage textures. The background is muted, providing a calm and unobtrusive setting that does not distract from the individual. Throughout the video, there is a gradual transition of light, with the shadows becoming less pronounced and the lighting more even and warm, suggesting either a change in time of day, a movement in the light source, or an indoor setting transitioning to an outdoor one. The person shifts slightly into a more natural pose, with their right foot raised, indicating a moment of relaxation or conversation. This subtle action, along with the progression of light, results in a softer overall appearance against']"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "run_inference(example[\"pixel_values_videos\"], model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95f6e968-affd-488f-a7f4-26e57a22993e",
      "metadata": {
        "id": "95f6e968-affd-488f-a7f4-26e57a22993e"
      },
      "source": [
        "#### For the sake of comparison, let's load the old model and compare the generations\n",
        "\n",
        "We can see that the tuned model started to get the ShareGPTVideo dataset style where the captions are more detailed and longer in length. The tuned model generates a more descriptive text of each scene and pays attention to the changes that happened as the video evolved (e.g. \"there is a gradual transition of light\")."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e262ecd1-2d26-4011-b05a-ddf14936d8ea",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "135fcebf7d064b4ab77cfcb059e98e1a"
          ]
        },
        "id": "e262ecd1-2d26-4011-b05a-ddf14936d8ea",
        "outputId": "9ccf1fe1-83ea-4ba8-d6bb-bdd13aca101b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You are using a model of type llava_next to instantiate a model of type llava_next_video. This is not supported for all configurations of models and can yield errors.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "135fcebf7d064b4ab77cfcb059e98e1a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "old_model = LlavaNextVideoForConditionalGeneration.from_pretrained(\n",
        "    MODEL_ID,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8c2ea6a-0633-42db-b7a2-ebc3406c473e",
      "metadata": {
        "id": "a8c2ea6a-0633-42db-b7a2-ebc3406c473e",
        "outputId": "92c6539c-0cdd-4d62-8bb6-3c42aa49d3f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[\"USER:  <video> \\nProvide a detailed caption for this video. ASSISTANT: In this cozy scene, a young woman finds solace while sitting comfortably in a wicker chair. She's snuggled up in casual clothing, her legs bent and her foot resting on her other leg. Her gaze is directed off-camera, suggesting she may be lost in thought or perhaps engrossed in a book she's holding in her hands. The room is softly lit, casting a gentle glow over the scene and enhancing the overall sense of relaxation.\"]"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "run_inference(example[\"pixel_values_videos\"], old_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cae77b34-05e6-44e1-9d1f-9cdda5883ffc",
      "metadata": {
        "id": "cae77b34-05e6-44e1-9d1f-9cdda5883ffc"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "molmo",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
